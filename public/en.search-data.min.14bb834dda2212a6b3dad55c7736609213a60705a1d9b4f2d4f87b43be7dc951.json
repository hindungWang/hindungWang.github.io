[{"id":0,"href":"/posts/26/","title":"K8s client-go初始化的几种方法","section":"Posts","content":" 简介 # client-go是k8s的一个基础组件库，是用于与API-Server交互的http客户端。K8s中大部分组件都使用了这个库实现与API-Server的通信功能。除了能够对资源对象的增删改查，还可Watch一个对象、升级成websocket链接等等功能。\nclient-go支持四种客户端：RESTClient、ClientSet、DynamicClient、DiscoveryClient。这几个client可以相互转换。\nRESTClient # RESTClient是最基础的客户端，相当于最底层的基础结构，可以直接通过RESTClient提供的RESTful方法如Get()、Put()、Post()、Delete()进行交互。\n一般而言，为了更为优雅的处理，需要进一步封装，通过Clientset封装RESTClient，然后再对外提供接口和服务。\n可以通过ClientSet客户端获得：\nclient := cli.CoreV1().RESTClient().(*rest.RESTClient) ClientSet # Clientset是调用Kubernetes资源对象最常用的client，可以操作所有的资源对象，包含RESTClient。需要制定Group、Version，然后根据Resource获取。\nclientset,err := kubernetes.NewForConfig(config) sa, err := clientset.CoreV1().ServiceAccounts(\u0026#34;kube-system\u0026#34;).Get(\u0026#34;kube-shell-admin\u0026#34;, metav1.GetOptions{}) DynamicClient # Dynamic client是一种动态的client，它能处理kubernetes所有的资源。不同于clientset，dynamic client返回的对象是一个map[string]interface{}。\ndynamicClient,err := dynamic.NewForConfig(config) gvr := schema.GroupVersionResource{Version: \u0026#34;v1\u0026#34;,Resource: \u0026#34;pods\u0026#34;} unstructObjList,err := dynamicClient.Resource(gvr).Namespace(\u0026#34;dev\u0026#34;).List(context.TODO(),metav1.ListOptions{Limit: 100}) DiscoveryClient # DiscoveryClient是发现客户端，主要用于发现kubernetes API Server所支持的资源组、资源版本、资源信息。除此之外，还可以将这些信息存储到本地，用户本地缓存，以减轻对Kubernetes API Server访问的压力。 kubectl的api-versions和api-resources命令输出也是通过DisconversyClient实现的。\ndiscoveryClient,err := discovery.NewDiscoveryClientForConfig(config) APIGroup,APIResourceListSlice,err := discoveryClient.ServerGroupsAndResources() 这几种客户端的初始化都涉及到了入参config，即*rest.Config，这个是用于初始化客户端的所有配置信息。\nrest.Config初始化 # 创建client前，需要先从初始化*rest.Config，这个*rest.Config可以从集群外的kubeconfig文件或者集群内部的 tokenFile 和 CAFile初始化（通过ServiceAcount自动挂载）。有以下几种方式：\n集群外通过kubeconfig初始化 # BuildConfigFromFlags方法从给定的url或者kubeconfig文件的文件夹路径去初始化config，如果不成功则会使用集群内部方法初始化config，如果不成功则返回一个默认的config。\n// \u0026#34;k8s.io/client-go/tools/clientcmd\u0026#34; config, err := clientcmd.BuildConfigFromFlags(\u0026#34;\u0026#34;, *kubeconfig) if err != nil { panic(err.Error()) } 内存中通过kubeconfig字符串或者byte数组初始化 # 通过读取kubeconfig文件内容进行初始化一个config：\nconfig, err := clientcmd.NewClientConfigFromBytes([]byte(string(Data[\u0026#34;kubeConfig\u0026#34;]))) if err != nil { return nil, err } restConfig, err := config.ClientConfig() if err != nil { return nil, err } 集群中通过ServiceAcount初始化 # 通过集群内部配置创建 k8s 配置信息，通过 KUBERNETES_SERVICE_HOST 和 KUBERNETES_SERVICE_PORT 环境变量方式获取。\n若集群使用 TLS 认证方式，则默认读取集群内部 tokenFile 和 CAFile：\ntokenFile = \u0026quot;/var/run/secrets/kubernetes.io/serviceaccount/token\u0026quot;\nrootCAFile = \u0026quot;/var/run/secrets/kubernetes.io/serviceaccount/ca.crt\u0026quot;\n// \u0026#34;k8s.io/client-go/rest\u0026#34; config, err := rest.InClusterConfig() if err != nil { panic(err.Error()) } operator-sdk中初始化config # 一般来说，我们使用operator-sdk开发CRDs都会用到在本地调试或者在集群中调试的方法，在低版本operator-sdk中可以使用以下方法：\n// \u0026#34;sigs.k8s.io/controller-runtime/pkg/client/config\u0026#34; cfg, err := config.GetConfig() if err != nil { log.Error(err, \u0026#34;\u0026#34;) os.Exit(1) } 该方法初始化kubeconfig的顺序是\u0026ndash;kubeconfig标签，KUBECONFIG环境变量，In-cluster集群内SA，$HOME/.kube/config文件。\n在初始化的config的同时，设置了请求的QPS，默认20 QPS, 30 burst。\n在某些高版本sdk中，可以用以下方法初始化：\n//ctrl \u0026#34;sigs.k8s.io/controller-runtime\u0026#34; ctrl.GetConfigOrDie() 原理同上。\n"},{"id":1,"href":"/about/","title":"About Me","section":"Hindung Blogs","content":" Hi there 👋 This is hindung\u0026rsquo;s space # 🌱 I’m currently learning K8s Docker Go etc.\n💬 Ask me about K8s Docker Go\n📫 回电我: tangtione@qq.com\n"},{"id":2,"href":"/posts/post/","title":"Hello World","section":"Posts","content":" 欢迎来到hindung的部落格 Copy from @ 马克飞象 # @(示例笔记本)[飞驰|人生|Markdown]\n马克飞象是一款专为印象笔记（Evernote）打造的Markdown编辑器，通过精心的设计与技术实现，配合印象笔记强大的存储和同步功能，带来前所未有的书写体验。特点概述：\n功能丰富 ：支持高亮代码块、LaTeX 公式、流程图，本地图片以及附件上传，甚至截图粘贴，工作学习好帮手； 得心应手 ：简洁高效的编辑器，提供桌面客户端以及离线Chrome App，支持移动端 Web； 深度整合 ：支持选择笔记本和添加标签，支持从印象笔记跳转编辑，轻松管理。 [TOC]\nMarkdown简介 # Markdown 是一种轻量级标记语言，它允许人们使用易读易写的纯文本格式编写文档，然后转换成格式丰富的HTML页面。 —— 维基百科\n正如您在阅读的这份文档，它使用简单的符号标识不同的标题，将某些文字标记为粗体或者斜体，创建一个链接或一个脚注1。下面列举了几个高级功能，更多语法请按Ctrl + /查看帮助。\n代码块 # @requires_authorization def somefunc(param1=\u0026#39;\u0026#39;, param2=0): \u0026#39;\u0026#39;\u0026#39;A docstring\u0026#39;\u0026#39;\u0026#39; if param1 \u0026gt; param2: # interesting print \u0026#39;Greater\u0026#39; return (param2 - param1 + 1) or None class SomeClass: pass \u0026gt;\u0026gt;\u0026gt; message = \u0026#39;\u0026#39;\u0026#39;interpreter ... prompt\u0026#39;\u0026#39;\u0026#39; LaTeX 公式 # 可以创建行内公式，例如 $\\Gamma(n) = (n-1)!\\quad\\forall n\\in\\mathbb N$。或者块级公式：\n$$\tx = \\dfrac{-b \\pm \\sqrt{b^2 - 4ac}}{2a} $$\n表格 # Item Value Qty Computer 1600 USD 5 Phone 12 USD 12 Pipe 1 USD 234 流程图 # st=\u0026gt;start: Start e=\u0026gt;end op=\u0026gt;operation: My Operation cond=\u0026gt;condition: Yes or No? st-\u0026gt;op-\u0026gt;cond cond(yes)-\u0026gt;e cond(no)-\u0026gt;op 以及时序图:\nAlice-\u0026gt;Bob: Hello Bob, how are you? Note right of Bob: Bob thinks Bob--\u0026gt;Alice: I am good thanks! 提示：想了解更多，请查看流程图语法以及时序图语法。\n复选框 # 使用 - [ ] 和 - [x] 语法可以创建复选框，实现 todo-list 等功能。例如：\n已完成事项 待办事项1 待办事项2 注意：目前支持尚不完全，在印象笔记中勾选复选框是无效、不能同步的，所以必须在马克飞象中修改 Markdown 原文才可生效。下个版本将会全面支持。\n印象笔记相关 # 笔记本和标签 # 马克飞象增加了@(笔记本)[标签A|标签B]语法, 以选择笔记本和添加标签。 绑定账号后， 输入(自动会出现笔记本列表，请从中选择。\n笔记标题 # 马克飞象会自动使用文档内出现的第一个标题作为笔记标题。例如本文，就是第一行的 欢迎使用马克飞象。\n快捷编辑 # 保存在印象笔记中的笔记，右上角会有一个红色的编辑按钮，点击后会回到马克飞象中打开并编辑该笔记。\n**注意：**目前用户在印象笔记中单方面做的任何修改，马克飞象是无法自动感知和更新的。所以请务必回到马克飞象编辑。\n数据同步 # 马克飞象通过将Markdown原文以隐藏内容保存在笔记中的精妙设计，实现了对Markdown的存储和再次编辑。既解决了其他产品只是单向导出HTML的单薄，又规避了服务端存储Markdown带来的隐私安全问题。这样，服务端仅作为对印象笔记 API调用和数据转换之用。\n隐私声明：用户所有的笔记数据，均保存在印象笔记中。马克飞象不存储用户的任何笔记数据。\n离线存储 # 马克飞象使用浏览器离线存储将内容实时保存在本地，不必担心网络断掉或浏览器崩溃。为了节省空间和避免冲突，已同步至印象笔记并且不再修改的笔记将删除部分本地缓存，不过依然可以随时通过文档管理打开。\n**注意：**虽然浏览器存储大部分时候都比较可靠，但印象笔记作为专业云存储，更值得信赖。以防万一，请务必经常及时同步到印象笔记。\n编辑器相关 # 设置 # 右侧系统菜单（快捷键Ctrl + M）的设置中，提供了界面字体、字号、自定义CSS、vim/emacs 键盘模式等高级选项。\n快捷键 # 帮助 Ctrl + / 同步文档 Ctrl + S 创建文档 Ctrl + Alt + N 最大化编辑器 Ctrl + Enter 预览文档 Ctrl + Alt + Enter 文档管理 Ctrl + O 系统菜单 Ctrl + M\n加粗 Ctrl + B 插入图片 Ctrl + G 插入链接 Ctrl + L 提升标题 Ctrl + H\n关于收费 # 马克飞象为新用户提供 10 天的试用期，试用期过后需要续费才能继续使用。未购买或者未及时续费，将不能同步新的笔记。之前保存过的笔记依然可以编辑。\n反馈与建议 # 微博：@马克飞象，@GGock 邮箱：hustgock@gmail.com 感谢阅读这份帮助文档。请点击右上角，绑定印象笔记账号，开启全新的记录与分享体验吧。\n这是一个示例脚注。请查阅 MultiMarkdown 文档 关于脚注的说明。 限制： 印象笔记的笔记内容使用 ENML 格式，基于 HTML，但是不支持某些标签和属性，例如id，这就导致脚注和TOC无法正常点击。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n"},{"id":3,"href":"/posts/20/","title":"容器技术之我见","section":"Posts","content":" 容器技术 # 什么是容器呢？\n印象中第一次接触“容器”这个词，是在化学课上，不就是一装东西的瓶子嘛有啥特别的。\n仔细想想，“装”东西即在某种程度上与其他物体隔离开来了。所以称这个「装东西的东西」为容器。\n是吧！那现在所说的“容器”到底是啥概念，他能装什么东西，又把什么东西在某种程度上隔离开？\n我的理解就是：「把资源隔离开的东西」。\n资源泛指OS上的资源，如CPU、内存、设备、文件系统等等。如何进行隔离呢？Linux内核提供了某种机制能让上诉所说的“资源”隔离开来，即Namespace和CGroups。\n容器技术就是基于这两个内核特性进行设计和开发。\nNamespace # 命名空间在维基百科上的广义解释是：\n“在计算机中，命名空间是一组用于标识和引用各种对象的符号（名称）。命名空间可确保所有给定的对象集都具有唯一的名称，以便可以轻松识别它们。”\n根据这个定义，Linux内核提供的命名空间定义为：\n“命名空间是Linux内核的一项功能，该功能对内核资源进行分区，以使一组进程看到一组资源，而另一组进程看到另一组资源。该功能通过为一组资源和进程具有相同的名称空间而起作用，但是这些名称空间引用了不同的资源。资源可能存在于多个空间中。这样的资源有进程ID、主机名、用户ID、文件名以及一些与网络访问和进程间通信相关。”\n从内核版本5.6开始，存在8种名称空间。命名空间功能在所有类型上都是相同的：每个进程都与一个命名空间相关联并且只能查看或使用与该命名空间以及后代命名空间相关联的资源。 这样，每个进程（或其进程组）可以在资源上拥有唯一的视图。隔离哪个资源取决于已为给定进程组创建的名称空间的类型。\nMount (mnt) # 挂载命名空间控制隔离挂载点。即隔离文件系统目录结构。\n比如你在每个容器里都有/usr目录，你们都可以访问这个目录，但他们是不一样的。\nProcess ID (pid) # PID命名空间为进程提供了一套独立于其他命名空间的进程ID（PID）。\nPID命名空间是嵌套的，这意味着当一个新的进程被创建时，它将有一个从其当前命名空间到初始PID命名空间的每个命名空间的PID。因此，初始PID命名空间能够看到所有进程，尽管其PID与其他命名空间看到的进程不同。\n比如用于创建容器的Runc Daemon进程。\nNetwork (net) # 网络名称空间可虚拟化网络堆栈。由于每个容器有不同的网络接口，每个地址信息，包括IP地址，都可以分开。\nInterprocess Communication (ipc) # IPC命名空间将进程与SysV风格的进程间通信隔离。\nUTS # UTS（UNIX时间共享）命名空间允许一个系统在不同的进程中出现不同的主机名和域名。\nUser ID (user) # 用户命名空间是一个提供权限隔离和用户识别隔离的功能，跨越多组进程，从内核3.8开始可用。\n在管理员的协助下，有可能建立一个看起来有管理权限的容器，而实际上没有给用户进程提升权限。像PID命名空间一样，用户命名空间是嵌套的，每个新的用户命名空间都被认为是创建它的用户命名空间的子空间。\nControl group (cgroup) Namespace # 控制组命名空间，隐藏了进程作为成员的控制组的身份。\n在这样的命名空间中的进程，在检查任何进程属于哪个控制组时，会看到一个实际上是相对于创建时设置的控制组的路径，隐藏其真实的控制组位置和身份。\nTime Namespace # 时间命名空间允许进程以类似于UTS命名空间的方式看到不同的系统时间。 它在2018年被提出，并在2020年3月发布的Linux 5.6上登陆。\n规划中的命名空间 # syslog namespace、Syscalls、Destruction，具体信息请参阅维基百科\nCGroup # 控制组cgroups是Linux内核提供的一个功能，用于从硬件和相关方面限制一组特定的分组进程。\n如隔离CPU、内存、设备、磁盘io、网络io等。\n有两个版本的cgroup。Cgroups最初由Paul Menage和Rohit Seth编写，并于2007年进入Linux内核主线。此后称为cgroups版本1。\n然后由Tejun Heo接管了cgroup的开发和维护。Tejun Heo重新设计并重写了cgroup。这种重写现在称为版本2，cgroups-v2的文档首次出现在2016年3月14日发布的Linux内核4.5中。\n与v1不同，cgroup v2仅具有单个进程层次结构，并且在进程之间进行区分，而不对线程进行区分。\n控制组的核心功能：\n资源限制：可以将组设置为不超过配置的内存限制，该限制还包括文件系统缓存 优先级：一些组可能会在CPU利用率或磁盘I / O吞吐量中获得更大份额 可统计：衡量组的资源使用情况 可控制：冻结/复活进程组 控制组具有分层概念，这意味着每个组都从其父组继承限制。内核通过cgroup接口提供对多个控制器（也称为子系统）的访问。例如，“内存”控制器限制内存使用，“ cpuacct”账户CPU使用率等。\n使用控制组的方式：\n通过手动访问cgroup虚拟文件系统。 通过使用cgcreate，cgexec和cgclassify（来自libcgroup）之类的工具动态创建和管理组。 通过“引擎守护程序规则”，可以按照配置中的指定自动将某些用户，组或命令的进程移至cgroup。 间接通过其它软件使用的cgroup，如docker systemd-cgtop命令可用于按资源使用情况显示顶级控制组。\n可以通过命令 $ ll /sys/fs/cgroup/ 查看控制组中有哪些资源被控制。\nLinux Kernel 4.19（2018年10月）引入了cgroup对OOMKiller实现的认识，该功能增加了将cgroup作为单个单元杀死的能力，从而保证了工作负载的完整性。\n容器镜像 # 容器镜像是就是容器的快照。\n对于docker 镜像来说，他可以通过Dockerfile构建。\n镜像的实现原理是UnionFs（联合文件系统）：\n“Union文件系统（UnionFs）是一种分层、轻量级并且高性能的文件系统，他支持对文件系统的修改作为一次提交来一层层的叠加，同时可以将不同目录挂载到同一个虚拟文件系统下（ unite several directories into a single virtual filesystem”\nUnionFS采用写时复制（COW）的方法，层层叠加到文件系统。\n可以同时加载多个文件系统，但是联合加载会把他们文件系统叠加起来，合并复制被定向到一个特定的实际文件系统。这样可以使文件系统看起来可写，但实际上不允许写操作更改文件系统，这样最终的文件系统会包含所有底层的文件和目录。\nDocker在镜像层叠上也采用了COW技术。容器与镜像的区别就是：容器=镜像+可写层。\n什么是Docker # Docker是容器技术的一种实现。\nDocker分为客户端和Daemon进程，Docker客户端是命令行工具，用于跟Daemon程序沟通并发送指令。\nDocker Daemon进程会与Containerd进程通讯并创建容器。\n而Containerd核心是通过runc进行创建容器。该部分属于容器运行时接口的内容。\n与虚拟机的区别 # 传统虚拟机实现虚拟化的方法是，在裸金属上安装虚拟机管理程序，并且在各个虚拟机上需要安装操作系统，因此在虚拟上存在大量资源开销。\n而容器则像是操作系统的一个个进程，他们通过容器进行隔离。\n容器技术就像是一个「对在Linux上运行的相关进程进行分组，让每个进程都在独立的用户空间中运行」的技术。\n原则上，从安全性的角度来看，容器方法对执行环境的控制比虚拟服务器更容易受到攻击。\n除非操作系统或虚拟机监控程序中存在某些漏洞，否则虚拟服务器不太可能影响其他虚拟环境，但是由于容器之间的关系只是一个进程，因此它将影响其他容器（进程）。环境。\n参考文章：\n原理原則で理解するDocker\nBuild Your Own Container Using Less than 100 Lines of Go\ncgroups\nLinux_namespaces\nUnionFS\n"},{"id":4,"href":"/posts/22/","title":"Iptable规则初探","section":"Posts","content":" iptable是啥 # 参考维基百科：iptables是运行在用户空间的应用软件，通过控制Linux内核netfilter模块，来管理网络数据包的处理和转发。\niptables规则 # iptables主要有raw、mangle、filter、nat这几个表，对应几个规则：PREROUTING 、INPUT 、FORWARD 、OUTPUT、POSTROUTING 。\nNAT 包括 SNAT （源地址转换）和 DNAT （目的地址转换）。两者的区别在于做地址转换是在路由前还是路由后，SNAT和DNAT总是成对出现的。\n对应的含义可以简单理解为：\n表名 用途 包含的规则 表名 用途 包含的规则 raw 关闭nat表上启用的连接追踪机制 PREROUTING，OUTPUT mangle 拆解报文，做出修改，并重新封装的功能 PREROUTING，INPUT，FORWARD，OUTPUT，POSTROUTING nat 网络地址转换功能 PREROUTING，OUTPUT，POSTROUTING（centos7中还有INPUT，centos6中没有） filter 负责过滤功能，防火墙 INPUT，FORWARD，OUTPUT 规则的意义：\n规则 意义 PREROUTING 报文刚刚到达主机，还没经过路由 INPUT 报文已经经过路由，判断是发送给本机的报文 FORWARD 报文已经经过路由，判断不是本机的报文，如果内核开启转发功能则转发出去，否则丢弃 OUTPUT 报文从应用发出报文已经经过路由 POSTROUTING 报文从应用发出已经经过路由，准备从网卡发出 数据从网络到达主机，再从主机到达应用的过程，以集群中traefik部署的Ingress为例，可以理解为： iptable相关命令 # 查看iptables规则：\niptables -L, --list [chain] 列出链 chain 上面的所有规则，如果没有指定链，列出表上所有链的所有规则 参考https://wangchujiang.com/linux-command/c/iptables.html\n"},{"id":5,"href":"/posts/25/","title":"K8s之calico网络插件东西南北流量","section":"Posts","content":" 前言 # 环境采用了calico＋ebgp/ibgp＋交换机组成了一个扁平化网络，使用calico宣告POD IP，做到了POD与其他虚拟机和开发网落处在同一个平面的效果。\n具体组网信息可以参考calico网站。\n东西流量 # Pod到Service流量 # 一般的应用大多数是以Pod到Service的形式去请求服务，从而出现东西方向的流量，目前集群的网络采用Calico作为网络插件，POD的IP由Calico进行统一分配，Service IP由集群K8s分配，并且配合Kube-proxy操作Iptable创建对应的规则。\n首先，创建一个POD时，calico会同时在POD对应的主机生成对应的calico网桥calixxx，并且分配IP，并且通过calico组件路由宣告出去：\n发送到calixxx的流量会转发至POD的eth0网卡，而从POD发出来的报文则是通过ARP 代理的方式转发至calixxx网桥。\n而当一个Service创建之后，会根据选择器与POD标签配对，对应上POD IP并且被Kube-Proxy监控到，K8s会随即生成对应的DNS记录service.namespace.local.cluster:serviceclusterIP，然后在Iptables添加相应的规则记录，如(10.88.145.173为ServiceIP，10.90.1.127为POD IP)：\n一般的，在集群中从POD访问Service，再从Service到达对应的POD流程为（正向请求用①表示，回复报文用(1)表示）：\n下面梳理一下请求的主要过程：\n①POD向domian发送请求 ②由于没有IP，POD先向CoreDNS查询域名对应的IP地址 ③CoreDNS返回对应的Service IP ④POD拿到IP之后，向该IP发送数据，对应的报文从calixxx网桥出来 ⑤从calixxx网桥出来后，进入Host Iptables链，进入IP tables之后，进入对应的链路如上图规则，最后得到Service对应的POD IP，并转发到此IP，此时会经过路由，分为两种情况，目标IP在同一节点上（路由表有记录）或者不在同一节点上（路由表无记录） ⑥如果在同一节点上，根据路由表则会路由到目标IP对应的calixxx网桥 ⑦如果不在同一节点上，则根据路由表规则，会从bond1口出去 ⑧到达交换机，交换机有对应的路由条目，则会走到（3）和（4）过程进入Host，并且走到Iptables，通过路由，转到⑥过程 ⑨到达calixxx网桥之后会转发至POD eth0网卡，到达POD 应答过程：\n(1)POD以传过来的源POD IP作为目的IP从eth0发出，通过ARP代理转发到calixxx网桥 (2)达到calixxx网桥之后会经过POD所在的节点的Host路由表，同样分为两种情况 (3)如果不在同一节点上，则会走bond1到交换机 (4)再从交换机到达对应的节点，之后便到达过程（5） (5)经过路由表，到达目的IP 对应calixxx网桥 (6)再从网桥到达POD eth0 Pod到Pod流量 # 由于网络平面化，POD IP可以直通，所以会存在POD相互访问的场景，如隐私号应用等：\n主要过程：\n①POD以目标POD的IP作为目的IP，从eth0发出，到达calixxx ②到达calixxx网桥之后会进入Host内核Iptables链到达PREROUTING（路由前） ③之后进入路由模块进行路由，路由判断该报文是否是发给本机的，如果是则往上收将进入INPUT链，此过程不在讨论范围，由于报文目的地址是POD IP，所以会转发出去 ④到达FORWARD链后进入POSTROUTING（路由后） ⑤进入POSTROUTING会进行一些地址转换等操作后发往对应网卡或者网桥，如果路由结果表明该报文要通过网卡Bond1出去则会走到⑧过程，否则会走到⑥ ⑥表明目的IP在本机网桥上（即POD在同一节点上），则进入目的地址对应的calixxx网桥 ⑦再转发至POD eth0网卡到达目的地 ⑧报文从内核出来进入网卡，准备向外发出 ⑨到达交换机，由于交换机有所有POD的路由信息，所以他能正确处理经过的报文 ⑩经过路由后到达POD所在节点的入口网卡Bond1 11.到达网卡之后会进入内核Linux协议栈进行Iptables规则链匹配（可能的路径为到③-\u0026gt;④-\u0026gt;⑤-\u0026gt;⑥-\u0026gt;⑦到达对应的POD） 回复过程：\n(1)到达目的POD之后，应用根据源IP进行回应，转发至calixxx网桥 (2)到达网桥之后进入Linux协议栈，其过程会从③-\u0026gt;④-\u0026gt;⑤-\u0026gt;（3）到达源POD (3)到达源POD对应的网桥 (4)从网桥转发至POD eth0网卡，此时会经过Linux协议栈，最终报文从内核到用户空间送到应用。 南北流量 # 外部流量从Ingress(越过service)到Pod # client客户端请求POD应用，首先要创建对应的Service，并且创建Ingress路由。集群中采用Traefik作为Ingres Controller，以DeamonSet的方式部署，并且开启hostNetwork模式，与主机公用网络协议栈。并且接管所有到达主机的80端口、8080端口的报文。Traefik的原理主要是通过监控APIserver来监控Service、POD的变化，并维护路由，而且接管80端口的流量，转发到对应路由的POD IP上。\n具体过程为：\n简单解释一下过程：\n①（客户端首先向DNS服务器获取域名对应的IP）向目标IP发送请求，到达交换机 ②经过路由之后定向到目标IP所在的主机，由于设置了HA-proxy，请求会先到VIP对应的网卡bond1:1 ③从外联口进来之后进入内核程序处理 ④到达路由模块，判断报文是发送给本机的，则往上收 ⑤到达INPUT链，之后会根据端口号，发至对应的应用程序，由于是HA-proxy提供的代理，从而进入HA程序，程序代理到Hots3 IP上，所以从POSTROUTING出来之后会到达(15)过程，在到达⑤，往上到达Traefik程序 ⑥Traefik接管80端口的流量，进行路由匹配之后（拿到请求对应的POD IP），代理至POD IP ⑦进入路由 ⑧进入OUTPUT链 ⑨进入POSTROUTING，通过路由之后，如果目的IP地址位于同一节点，则会路由到calixxx网桥，否则会走到(12)过程，到达交换机路由之后达到对应主机上(12-\u0026gt;13-\u0026gt;14-\u0026gt;15-\u0026gt;④-\u0026gt;FORWARD-\u0026gt;⑨-\u0026gt;⑩) ⑩到达calixxx网桥，然后到达POD eth0网卡 回复过程：\n(1)到达calixxx网桥 (2)进入主机网络栈，返回Traefik代理： 之后从Traefik即主机网络栈出来到达外联口\n(3)从外联口出来（SNAT），到达交换机 (4)到达客户端（DNAT） 外部流量直接到Pod # 由于POD IP直接通过calico BGP路由宣告出去，因此POD网段与虚机、本地电脑处在同一平面，请求POD IP与请求虚拟机情况一致：\n具体流程：\n①客户端请求到达交换机 ②交换机路由到目的地址对应的主机上 ③进入主机网络栈进行路由（简画） ④可能会经过此过程（就是目标POD不在该节点上） ⑤重新到达交换机 ⑥再次路由到达目标节点 ⑦进入主机网络栈 ⑧路由到calixxx网桥 ⑨到达POD eth0网卡 回复过程：\n(1)发送至calixxx网桥 (2)进入到主机网络栈，进行路由 (3)发送至外联口bond1 (4)到达交换机，路由 (5)到达客户端（可能会经过NAT） 外部流量直接访问ServiceIP（特性） # 将Service IP通过calico BGP协议路由宣告出去，从而实现了Service IP可以直通的场景：\n具体流程：\n①被路由宣告的ServiceIP会出现在交换机路由表条目上，请求到达交换机 ②交换机进行路由，到达目的IP所在的对应节点（进群内任何一个节点） ③从网卡接收报文，经过网络栈路由到达calixxx网桥（与访问service过程一至） ④进入calixxx网桥 ⑤进入eth0 回复过程：\n(1)从应用发出到达calixxx (2)到达主机网络栈 (3)到达外联口网卡 (4)到达交换机 (5)到达客户端 总结 # 集群目前采用Iptables部署方式，依赖Iptables规则。如果集群Service过多会导致经常对Iptables频繁操作，并且如果表变得很大，更新表就会变得困难。\n因此Iptables这块将来可能会遇到瓶颈。\ncalico网桥与容器网桥这段映射的具体实现是怎样，包括性能如何等还没有深入了解。\n参考：\nl2-interconnect-fabric\ncalico学习\nCalico网络的原理、组网方式与使用\n"},{"id":6,"href":"/posts/24/","title":"Kubectl命令行","section":"Posts","content":"注：基于Kubenetes 版本：Server v1.17.2、Client v1.17.9\nkubectl命令行全景图 # kubectl🔗\n有趣的kubectl命令 # 获取正在Running的Pod # kubectl get pods -A --field-selector=status.phase==Running NAMESPACE NAME READY STATUS RESTARTS AGE kelu cka2-75dbf7c54-gm4r4 1/1 Running 0 23h kube-system calico-kube-controllers-ccf66db4-cpvqp 1/1 Running 0 3d20h kube-system calico-node-8d4th 1/1 Running 0 3d2h kube-system calico-node-szmzb 1/1 Running 0 3d20h 查看节点内存容量 # kubectl get no -o json | jq -r \u0026#39;.items | sort_by(.status.capacity.memory)[]|[.metadata.name,.status.capacity.memory]| @tsv\u0026#39; rq-bjptest01 3848040Ki rqinterntest2 7986060Ki 查看各个节点上的Pod数量 # kubectl get po -o json --all-namespaces | jq \u0026#39;.items | group_by(.spec.nodeName) | map({\u0026#34;nodeName\u0026#34;: .[0].spec.nodeName, \u0026#34;count\u0026#34;: length}) | sort_by(.count)\u0026#39; [ { \u0026#34;nodeName\u0026#34;: \u0026#34;rq-bjptest01\u0026#34;, \u0026#34;count\u0026#34;: 3 }, { \u0026#34;nodeName\u0026#34;: \u0026#34;rqinterntest2\u0026#34;, \u0026#34;count\u0026#34;: 8 } ] kubectl get pods --all-namespaces -o json | jq \u0026#39;.items[] | .spec.nodeName\u0026#39; -r | sort | uniq -c 17 rqkubedev03 30 rqkubedev04 23 rqkubedev05 查看POD以及镜像 # kubectl get pods -o custom-columns=\u0026#39;NAME:metadata.name,IMAGES:spec.containers[*].image\u0026#39; NAME IMAGES details-v1-5974b67c8-gqz94 docker.io/istio/examples-bookinfo-details-v1:1.16.2,docker.io/istio/proxyv2:1.7.2 gitea-5bb577b964-w64gg harbor.caih.local/gitea/gitea:1.10.1 productpage-v1-64794f5db4-hw2fl docker.io/istio/examples-bookinfo-productpage-v1:1.16.2,docker.io/istio/proxyv2:1.7.2 查看各个节点上的POD # kubectl get pods --all-namespaces -o json | jq \u0026#39;.items | map({podName: .metadata.name, nodeName: .spec.nodeName}) | group_by(.nodeName) | map({nodeName: .[0].nodeName, pods: map(.podName)})\u0026#39; [ { \u0026#34;nodeName\u0026#34;: \u0026#34;rqkubedev03\u0026#34;, \u0026#34;pods\u0026#34;: [ \u0026#34;123-84654b5d8f-sm2dt\u0026#34;, \u0026#34;reviews-v2-6cb6ccd848-ndsqq\u0026#34;, \u0026#34;fleet-agent-6cc4bd5c67-b877w\u0026#34;, \u0026#34;jaeger-es-index-cleaner-1602806100-5ngzz\u0026#34;, \u0026#34;jaeger-es-index-cleaner-1602806100-b47gk\u0026#34;, \u0026#34;jaeger-es-index-cleaner-1602806100-kkx2z\u0026#34;, \u0026#34;jaeger-es-index-cleaner-1602806100-rg6z8\u0026#34;, \u0026#34;jaeger-es-index-cleaner-1602806100-s47n4\u0026#34;, 查看Pod占用的内存和CPU并按内存或者CPU排序 # # 内存 kubectl top pods -A | sort --reverse --key 4 --numeric caihcloud jenkinsm-6fc5d7fc46-2tl6q 29m 1995Mi istio-system prometheus-788c945c9c-mdrjf 97m 1424Mi kube-system kube-apiserver-rqkubedev04 149m 957Mi kube-system kube-apiserver-rqkubedev03 69m 476Mi caihcloud jenkinsslaveswarm-6c6f5d8d9b-8ns5w 2m 464Mi # CPU kubectl top pods -A | sort --reverse --key 3 --numeric kube-system kube-apiserver-rqkubedev04 150m 964Mi istio-system prometheus-788c945c9c-mdrjf 89m 1426Mi kube-system kube-apiserver-rqkubedev03 42m 532Mi kube-system calico-node-6n65m 42m 46Mi kube-system calico-node-fg6tk 34m 49Mi 获取重启次数降序排序的Pod # kubectl get pods -A --sort-by=.status.containerStatuses[0].restartCount | tac kube-system kube-scheduler-rqkubedev03 0/1 CrashLoopBackOff 593 2d2h traefik-v2 traefik-gfnw5 1/1 Running 27 23d kube-system kube-controller-manager-rqkubedev03 1/1 Running 24 23d kube-system kube-controller-manager-rqkubedev04 1/1 Running 22 23d kube-system kube-apiserver-rqkubedev03 1/1 Running 21 23d NAMESPACE NAME READY STATUS RESTARTS AGE 获得所有POD的request和limits # kubectl get pods -A -o custom-columns=\u0026#39;NAME:metadata.name,MEM_REQUEST:spec.containers[*].resources.requests.memory,MEM_LIMIT:spec.containers[*].resources.limits.memory,CPU_REQUEST:spec.containers[*].resources.requests.cpu,CPU_LIMIT:spec.containers[*].resources.limits.cpu\u0026#39; NAME MEM_REQUEST MEM_LIMIT CPU_REQUEST CPU_LIMIT 123-84654b5d8f-sm2dt \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; backend-c56f64647-grql6 10Mi 1Gi 10m \u0026lt;none\u0026gt; caihcloud-67ffdf9fc9-wzmts 10Mi 1Gi 10m \u0026lt;none\u0026gt; caihcloud-ui-9fbb954dc-trtn7 10Mi 1Gi 10m \u0026lt;none\u0026gt; caihcloudm-caihcloudm-api-5cfffcc96-mz6pt 10Mi 1Gi 10m 200m caihcloudm-caihcloudm-api-5cfffcc96-xdwsb 10Mi 1Gi 10m 200m 获取节点的IP # kubectl get nodes -o jsonpath=\u0026#39;{range .items[*]}{.metadata.name} {.status.addresses[?(@.type==\u0026#34;InternalIP\u0026#34;)].address}{\u0026#34;\\n\u0026#34;}{end}\u0026#39; rqkubedev03 10.19.0.57 rqkubedev04 10.19.0.58 rqkubedev05 10.19.0.59 获取Service的Nodeport信息 # kubectl get -A svc -o json | jq -r \u0026#39;.items[] | [.metadata.name,([.spec.ports[].nodePort | tostring ] | join(\u0026#34;|\u0026#34;))]| @tsv\u0026#39; backend 23168|20675 caihcloud 37386 caihcloud-ui 26105 caihcloudm-caihcloudm-api 36236 caihcloudm-caihcloudm-prerender 31964 获取POD网段 # kubectl get nodes -o jsonpath=\u0026#39;{.items[*].spec.podCIDR}\u0026#39; | tr \u0026#34; \u0026#34; \u0026#34;\\n\u0026#34; 10.193.0.0/24 10.193.1.0/24 10.193.2.0/24 输出一个POD中所有的容器的日志 # kubectl logs caihcloudm-caihcloudm-api-5cfffcc96-mz6pt -n caihcloud —all-containers 按标签输出POD的日志 # kubectl -n caihcloud logs -f -l app=caihcloudm-caihcloudm-api 获取前一个容器的日志（容器异常挂掉的场景） # kubectl logs caihcloud-67ffdf9fc9-wzmts -n caihcloud --previous "},{"id":7,"href":"/posts/21/","title":"Kubernetes组件","section":"Posts","content":" 总体架构 # Kubernetes系统采用C/S架构，分为Master和Node两个部分，Master作为Server端，Node作为Client端。\n多Master的方式可以实现集群的高可用。\nMaster也叫做主控节点，它主要负责：\n管理所有的节点 调度POD 控制集群运行过程中的所有状态 包含了以下几个组件： API-Server：集群的HTTP REST接口，统一入口 Controller-Manager：所有资源的自动化控制中心 Scheduler：POD调度 Node也叫做工作节点，主要负责：\n管理所有容器 监控、上报所有POD的运行状态 包含了以下几个组件： Kubelet：管理节点上容器的生命，与Master节点通信 Kube-Proxy：服务通信、负载均衡 CRI容器运行时：接收kubelet的容器相关的指令并执行 Master节点也拥有Node相关的组件，即该Master也可以作为工作节点进行计算。\n除此之外，k8s内部的存储采用ETCD作为唯一存储，一般采用集群高可用的方式部署。\nEtcd集群是分布式K/V存储集群，提供了可靠的强一致性服务发现。Etcd集群存储Kubernetes系统的集群状态和元数据，其中包括所有Kubernetes资源对象信息、资源对象状态、集群节点信息等。Kubernetes将所有数据存储至Etcd集群前缀为/registry的目录下。\n各个组件的功能 # 在k8s集群中主要有以下几种组件：\nkubectl # kubectl是K8s官方提供的命令行工具，它主要与API-Server交互，通信协议采用HTTP/Json。\nclient-go # 除了有命令行工具对K8s进行管理之外，还提供了编程方式。client-go用golang进行开发，它最初是K8s的部分代码，现在抽成了独立的仓库。\nK8s任何组件与API-Server通信都是基于client-go。\nAPI-Server # 负责将K8s “资源组/资源版本/资源” 以RESTful形式对外提供服务。API-Server是集群中唯一与ETCD交互的组件。并且实现了集群的安全访问机制以及认证、授权、准入控制等。\nController-Manager # 管理控制器负责管理、维护集群内的状态，如维护POD的副本个数为期望的状态值等。\n包含了多个控制器：\nDeploymentControllers控制器 StatefulSet控制器 Namespace控制器 PersistentVolume控制器 等等 每个控制器通过kube-apiserver组件提供的接口实时监控整个集群每个资源对象的当前状态，当因发生各种故障而导致系统状态出现变化时，会尝试将系统状态修复到“期望状态”。 Scheduler # 负责调度POD在某个节点上运行。Kubelet上报节点信息，Scheduler通过监控这些信息，当有新的POD需要调度时，会根据这些节点信息进行调度算法计算最有节点。\n调度算法分为两种，分别为预选调度算法和优选调度算法。除调度策略外，Kubernetes还支持优先级调度、抢占机制及亲和性调度等功能。\nkube-scheduler组件支持高可用性（即多实例同时运行），即基于Etcd集群上的分布式锁实现领导者选举机制，多实例同时运行，通过kube-apiserver提供的资源锁进行选举竞争。抢先获取锁的实例被称为Leader节点（即领导者节点），并运行kube-scheduler组件的主逻辑；而未获取锁的实例被称为Candidate节点（即候选节点），运行时处于阻塞状态。在Leader节点因某些原因退出后，Candidate节点则通过领导者选举机制参与竞选，成为Leader节点后接替kube-scheduler的工作。\nKubelet # kubelet组件用来接收、处理、上报kube-apiserver组件下发的任务。kubelet进程启动时会向kube-apiserver注册节点自身信息。它主要负责所在节点（Node）上的Pod资源对象的管理，例如Pod资源对象的创建、修改、监控、删除、驱逐及Pod生命周期管理等。\nkubelet组件实现了3种开放接口：\nContainer Runtime Interface：简称CRI（容器运行时接口），提供容器运行时通用插件接口服务。CRI定义了容器和镜像服务的接口。CRI将kubelet组件与容器运行时进行解耦，将原来完全面向Pod级别的内部接口拆分成面向Sandbox和Container的gRPC接口，并将镜像管理和容器管理分离给不同的服务。\nContainer Network Interface：简称CNI（容器网络接口），提供网络通用插件接口服务。CNI定义了Kubernetes网络插件的基础，容器创建时通过CNI插件配置网络。\nContainer Storage Interface：简称CSI（容器存储接口），提供存储通用插件接口服务。CSI定义了容器存储卷标准规范，容器创建时通过CSI插件配置存储卷。\nKube-Proxy # kube-proxy组件，作为节点上的网络代理，运行在每个Kubernetes节点上。它监控kube-apiserver的服务和端点资源变化，并通过iptables/ipvs等配置负载均衡器，为一组Pod提供统一的TCP/UDP流量转发和负载均衡功能。\nKube-Proxy有几个工作模式：\nuserspace iptables 模式 ipvs 模式 具体可以参考：services-networking\nCRI容器运行时组件 # CRI 在 Kubernetes 1.5 中引入，充当kubelet和容器运行时之间的桥梁。\n即kubelet需要跟Contaner Runtime交互去管理容器的生命周期。\n"},{"id":8,"href":"/posts/23/","title":"容器运行时","section":"Posts","content":" OCI \u0026amp;\u0026amp; CRI # 使用容器经常会听到容器运行时的概念、OCI以及CRI等，这些有什么区别和联系呢？\nCR，即Container Runtime，容器运行时 CRI，即Container Runtime Interface，容器运行时接口，实现该系列接口以实现容器功能 OCI，即Open Container Initiative：开口容器倡议，是建立围绕容器格式和运行时的开放式行业标准的明确目的的开放式的治理结构。 OCI 目前包含两个规范：运行时规范（runtime-spec）和镜像规范（image-spec）。运行时规范概述了如何运行在磁盘上解压缩的“文件系统包”。\n现在清楚了，OCI定义了一种规范，即怎么做如何做。而CR是这个规范的实践并定义了一系列接口CRI，只要实现了该接口就能使用这个CR。\n比如CR有很多种，如runc、lxc等，但他们都提供了统一的CRI，其他实现了这个CRI的组件如kubelet在runc和lxc间切换是无感的。\n低级（low-level）容器运行时 # 我理解的low-level是一系列操作容器的行为在很底层，比如通过Linux内核接口创建各个Namespace以及生成Cgroup等操作。把这些行为打包就是一个低级的运行时的内容。或者说低级容器运行时干了啥。\n高级（high-level）容器运行时 # 高级容器运行时又干了啥事情呢？镜像管理、镜像传输、镜像解压缩等技术都可以归为高级的容器运行时。\n比如docker提供的镜像构建、拉取等。docker可以分为以下几层：\n+----------+ | | | docker | | | +-----+----+ | socket/API | +-----v----+ | | | dockerd | | | +-----+----+ | socket/API | +-----v----+ | | |contanerd | | | +-----+----+ | | OCI +-----v----+ | | | runc | +----------+ K8s 与 CRI # k8s 1.5 中自己实现了 docker CRI shim，通过这个组件与docker交互。管理容器的过程还是通过docker那套，在containerd 1.1版本中containerd直接实现了CRI，kubelet可以直接通过这个CRI实现与containerd的交互，从而绕过了docker。\nCRI 定义了几种远程过程调用 (RPC) 和消息类型。RPC 用于：\n拉取镜像 ImageService.PullImage 创建pod RuntimeService.RunPodSandbox 创建容器RuntimeService.CreateContainer 启动容器RuntimeService.StartContainer 停止容器RuntimeService.StopContainer 等操作。\n实现一个容器运行时 # 参考链接 # Container Runtimes Part 1: An Introduction to Container Runtimes\nopencontainers.org\nruntime-spec\nBuilding a container from scratch in Go - Liz Rice (Microscaling Systems) "},{"id":9,"href":"/posts/19/","title":"Go源码解读之sync.Cond","section":"Posts","content":" 前言 # 前面🔗说过，Cond实现了一个条件变量，是等待或宣布一个事件发生的goroutines的汇合点。\n就是说，使用sync.Cond可以做到多个协程等待某个协程通知的场景。\n使用channel可以实现一读一写的场景，而Cond则实现多读一写的场景。\n源码解析 # 简化版方法签名：\n// Cond结构体 type Cond struct {} // NewCond 返回带Locker的Cond，这个Locker可以是 // *Mutex 或 *RWMutex func NewCond(l Locker) *Cond {} // 等待L的解锁并挂起goroutine func (c *Cond) Wait() {} // 唤醒1个因c阻塞的goroutine， // 如果在Signal之后才Wait会导致all goroutines are asleep - deadlock func (c *Cond) Signal() {} // 唤醒所有因c阻塞的goroutine // 如果在Broadcast之后才Wait会导致all goroutines are asleep - deadlock func (c *Cond) Broadcast() {} 因此，在Signal或者Broadcast前要先保证目标的协程已经进入了Wait状态，否则会导致死锁。因为Signal或者Broadcast只唤醒当前正在被Wait阻塞的协程。\nCond的定义：\n// Copyright 2011 The Go Authors. All rights reserved. // Use of this source code is governed by a BSD-style // license that can be found in the LICENSE file. package sync import ( \u0026#34;sync/atomic\u0026#34; \u0026#34;unsafe\u0026#34; ) // Cond implements a condition variable, a rendezvous point // for goroutines waiting for or announcing the occurrence // of an event. // Cond实现了一个条件变量，它是goroutines等待或宣布事件发生的集合点。 // Each Cond has an associated Locker L (often a *Mutex or *RWMutex), // which must be held when changing the condition and // when calling the Wait method. // 每个Cond都有一个相关的Locker L（通常是一个*Mutex或*RWMutex）， // 在改变条件和调用Wait方法时，必须持有这个L。 // A Cond must not be copied after first use. type Cond struct { noCopy noCopy // L is held while observing or changing the condition L Locker // notifyList是用于实现sync.Cond的基于票证的通知列表 // 参考： // https://go.googlesource.com/go/+/go1.16.4/src/runtime/sema.go#446 notify notifyList checker copyChecker } // NewCond returns a new Cond with Locker l. func NewCond(l Locker) *Cond { return \u0026amp;Cond{L: l} } // Wait atomically unlocks c.L and suspends execution // of the calling goroutine. After later resuming execution, // Wait locks c.L before returning. Unlike in other systems, // Wait cannot return unless awoken by Broadcast or Signal. // // Because c.L is not locked when Wait first resumes, the caller // typically cannot assume that the condition is true when // Wait returns. Instead, the caller should Wait in a loop: // // c.L.Lock() // for !condition() { // c.Wait() // } // ... make use of condition ... // c.L.Unlock() // // Wait会先把加入到待唤醒队列，再释放锁，然后执行等待， // 当其他goroutine调用Broadcast或者Signal来通知其恢复执行后， // 会重新上锁 func (c *Cond) Wait() { c.checker.check() // notifyListAdd将调用者添加到通知列表中，以便它可以接收通知。 // 调用者必须最终调用notifyListWait来等待这样的通知，并显式传参。 // 参考： // https://go.googlesource.com/go/+/go1.16.4/src/sync/runtime.go#31 // https://go.googlesource.com/go/+/go1.16.4/src/runtime/sema.go#475 t := runtime_notifyListAdd(\u0026amp;c.notify) c.L.Unlock() // notifyListWait等待通知。如果自那以后已发送， // 调用notifyListAdd，它立即返回。否则，它将阻塞。 // 参考： // https://go.googlesource.com/go/+/go1.16.4/src/sync/runtime.go#34 // https://go.googlesource.com/go/+/go1.16.4/src/runtime/sema.go#485 runtime_notifyListWait(\u0026amp;c.notify, t) c.L.Lock() } // Signal wakes one goroutine waiting on c, if there is any. // // It is allowed but not required for the caller to hold c.L // during the call. func (c *Cond) Signal() { c.checker.check() runtime_notifyListNotifyOne(\u0026amp;c.notify) } // Broadcast wakes all goroutines waiting on c. // // It is allowed but not required for the caller to hold c.L // during the call. func (c *Cond) Broadcast() { c.checker.check() runtime_notifyListNotifyAll(\u0026amp;c.notify) } // copyChecker holds back pointer to itself to detect object copying. type copyChecker uintptr func (c *copyChecker) check() { if uintptr(*c) != uintptr(unsafe.Pointer(c)) \u0026amp;\u0026amp; !atomic.CompareAndSwapUintptr((*uintptr)(c), 0, uintptr(unsafe.Pointer(c))) \u0026amp;\u0026amp; uintptr(*c) != uintptr(unsafe.Pointer(c)) { panic(\u0026#34;sync.Cond is copied\u0026#34;) } } // noCopy may be embedded into structs which must not be copied // after the first use. // // See https://golang.org/issues/8005#issuecomment-190753527 // for details. type noCopy struct{} // Lock is a no-op used by -copylocks checker from `go vet`. func (*noCopy) Lock() {} func (*noCopy) Unlock() {} 使用例子 # 可以按照官方给的使用例子：\n// c.L.Lock() // 某个条件满足才进行Wait，否则可能会导致Wait发生在 // 唤醒之后，从而导致死锁 // for !condition() { // c.Wait() // } // ... make use of condition ... // c.L.Unlock() 如：\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; \u0026#34;time\u0026#34; ) var locker = new(sync.Mutex) var cond = sync.NewCond(locker) var condition = false func main() { var wg sync.WaitGroup wg.Add(10) for i := 0; i \u0026lt; 10; i++ { go func(x int) { cond.L.Lock() //获取锁 defer cond.L.Unlock() //释放锁 for !condition { cond.Wait() } fmt.Println(x) wg.Done() }(i) } time.Sleep(time.Second * 3) cond.L.Lock() condition = true cond.Broadcast() cond.L.Unlock() wg.Wait() } 注意：sync.Cond需要开发人员把握锁以及condition()的条件，比较容易发生死锁。\n其他代码中的应用 # k8s中的client-go代码中的DeltaFIFO队列实现就是用了sync.Cond来实现：\ntype DeltaFIFO struct { // lock/cond protects access to \u0026#39;items\u0026#39; and \u0026#39;queue\u0026#39;. lock sync.RWMutex cond sync.Cond // 其他字段省略 } 初始化：\nfunc NewDeltaFIFO(keyFunc KeyFunc, knownObjects KeyListerGetter) *DeltaFIFO { return NewDeltaFIFOWithOptions(DeltaFIFOOptions{ KeyFunction: keyFunc, KnownObjects: knownObjects, }) } func NewDeltaFIFOWithOptions(opts DeltaFIFOOptions) *DeltaFIFO { if opts.KeyFunction == nil { opts.KeyFunction = MetaNamespaceKeyFunc } f := \u0026amp;DeltaFIFO{ items: map[string]Deltas{}, queue: []string{}, keyFunc: opts.KeyFunction, knownObjects: opts.KnownObjects, emitDeltaTypeReplaced: opts.EmitDeltaTypeReplaced, } // f.lock 与 f.cond 结合使用 f.cond.L = \u0026amp;f.lock return f } 再来看看Pop方法，何时调用Wait：\n// Pop阻塞，直到队列中有一些项目，然后返回一个。 // 如果多个项目准备就绪，它们将按照它们被添加/更新的顺序返回。 func (f *DeltaFIFO) Pop(process PopProcessFunc) (interface{}, error) { f.lock.Lock() defer f.lock.Unlock() for { // 有数据就不用Wait for len(f.queue) == 0 { // When the queue is empty, invocation of Pop() is blocked until new item is enqueued. // 当队列为空时，将阻止Pop（）的调用，直到新项目入队。 // When Close() is called, the f.closed is set and the condition is broadcasted. // 当Close()被调用时，f.closed被设置，条件被广播。 // Which causes this loop to continue and return from the Pop(). if f.closed { return nil, ErrFIFOClosed } // 阻塞直到被广播（说明有数据） f.cond.Wait() } id := f.queue[0] f.queue = f.queue[1:] if f.initialPopulationCount \u0026gt; 0 { f.initialPopulationCount-- } item, ok := f.items[id] if !ok { // This should never happen klog.Errorf(\u0026#34;Inconceivable! %q was in f.queue but not f.items; ignoring.\u0026#34;, id) continue } delete(f.items, id) err := process(item) if e, ok := err.(ErrRequeue); ok { f.addIfNotPresent(id, item) err = e.Err } // Don\u0026#39;t need to copyDeltas here, because we\u0026#39;re transferring // ownership to the caller. return item, err } } 何时调用Broadcast：\n// Close the queue. func (f *DeltaFIFO) Close() { f.lock.Lock() defer f.lock.Unlock() f.closed = true f.cond.Broadcast() } // addIfNotPresent inserts deltas under id if it does not exist, and assumes the caller // already holds the fifo lock. func (f *DeltaFIFO) addIfNotPresent(id string, deltas Deltas) { f.populated = true if _, exists := f.items[id]; exists { return } f.queue = append(f.queue, id) f.items[id] = deltas // 有数据，则广播 f.cond.Broadcast() } // queueActionLocked appends to the delta list for the object. // queueActionLocked追加到该对象的delta列表。 // Caller must lock first. func (f *DeltaFIFO) queueActionLocked(actionType DeltaType, obj interface{}) error { id, err := f.KeyOf(obj) if err != nil { return KeyError{obj, err} } oldDeltas := f.items[id] newDeltas := append(oldDeltas, Delta{actionType, obj}) newDeltas = dedupDeltas(newDeltas) if len(newDeltas) \u0026gt; 0 { if _, exists := f.items[id]; !exists { f.queue = append(f.queue, id) } f.items[id] = newDeltas f.cond.Broadcast() } else { // This never happens, because dedupDeltas never returns an empty list // when given a non-empty list (as it is here). // If somehow it happens anyway, deal with it but complain. if oldDeltas == nil { klog.Errorf(\u0026#34;Impossible dedupDeltas for id=%q: oldDeltas=%#+v, obj=%#+v; ignoring\u0026#34;, id, oldDeltas, obj) return nil } klog.Errorf(\u0026#34;Impossible dedupDeltas for id=%q: oldDeltas=%#+v, obj=%#+v; breaking invariant by storing empty Deltas\u0026#34;, id, oldDeltas, obj) f.items[id] = newDeltas return fmt.Errorf(\u0026#34;Impossible dedupDeltas for id=%q: oldDeltas=%#+v, obj=%#+v; broke DeltaFIFO invariant by storing empty Deltas\u0026#34;, id, oldDeltas, obj) } return nil } 更新于 2021/05/16 23:53\n"},{"id":10,"href":"/posts/18/","title":"Go源码解读之sync中的基本类型和使用场景","section":"Posts","content":" Overview # 包链接🔗\nsync包提供基本的同步原语，例如互斥锁。\n除了Once和WaitGroup类型外，大多数都是供低级库例程使用的。\n更高层次的同步最好通过channels和通信来完成。\n从代码看，sync提供了几种类型：\nCond：条件变量 Locker：锁的接口定义 Map：协程并发安全的Map Mutex：互斥锁 Once：单次执行 Pool：池 RWMutex：读写锁 WaitGroup：等待组 几个类型分别对应不同的使用场景。\nsync.Cond # Cond实现了一个条件变量，是等待或宣布一个事件发生的goroutines的汇合点。\n通俗的说，sync.Cond用来协调那些访问共享资源的goroutine，当共享资源发生变化时，通知被阻塞goroutine。\nsync.Cond 经常用在多个 goroutine 等待一个 goroutine 通知（事件发生）的场景。\nsync.Map # Map就像Go中的map[interface{}]interface{}，但对于多个goroutine的并发使用是安全的，不需要额外的锁或协调。\n使用map + sync.Mutex或者sync.RWMutex的方式也可以实现与sync.Map类似的功能，但是在某些场景下，sync.Map具有更高的性能：\nMap类型针对两种常见用例进行了优化：\n当给定key的条目仅被写入一次却被读取多次时，例如在仅增长的高速缓存中 当多个goroutine读取，写入和覆盖的key都不相关时 在这两种情况下，与与单独的Mutex或RWMutex + map 相比，使用Map可以显着减少锁争用。\nsync.Mutex # Mutex是一个相互排斥的锁。Mutex的零值是一个解锁的Mutex。\n当调用Lock方法进行加锁时，如果锁已在使用中，则goroutine会阻塞，直到锁可用为止。 当调用UnLock方法进行解锁时，如果锁没有在使用，则会出现运行时错误。\n锁定的互斥锁与特定的goroutine没有关联。允许一个goroutine锁定Mutex，然后安排另一个goroutine对其进行解锁。\nsync.RWMutex # RWMutex是一个读写器相互排斥的锁。 该锁可以由任意数量的读者或单一的写者持有。RWMutex的零值是一个解锁的mutex。\n读读不互斥，读写互斥，写写互斥。\nsync.Once # Once的Do(f)方法保证只运行一次，即使f发生panic。 这常用在单例模式，配置文件加载，初始化这些场景下。\nsync.Pool # Pool是一组可以单独保存和检索的临时对象。 储存在池子里的任何对象都可能在任何时候被自动删除，而无需通知。 池可以安全地同时被多个goroutine使用。\nPool的作用是缓存已分配但未使用的项目，以便以后再使用，减轻垃圾收集器的压力。也就是说，它使建立高效、线程安全的自由列表变得容易。\n池的一个适当的用途是管理一组临时项目，这些临时项目在包的独立客户端之间默默地共享，并可能被重复使用。Pool提供了一种在许多客户端之间分摊分配开销的方法。\n当然，Pool并不适用于一些短命的对象池化。\n相当于拿出来，做操作，再放回去，操作过的东西放回去的时候是啥样，拿出来的时候就是啥样的。也就是说，拿出来用的时候需要初始化数据或者清空。 如Gin的源码：https://github.com/gin-gonic/gin/blob/v1.7.1/gin.go#L439\n// ServeHTTP conforms to the http.Handler interface. func (engine *Engine) ServeHTTP(w http.ResponseWriter, req *http.Request) { // get Context from pool c := engine.pool.Get().(*Context) // reset c.writermem.reset(w) c.Request = req c.reset() // use c engine.handleHTTPRequest(c) // put back engine.pool.Put(c) } sync.WaitGroup # 一个WaitGroup等待一个goroutine的集合完成。 主的goroutine调用Add来设置要等待的goroutine的数量。 然后每个goroutine运行，完成后调用Done。\n同时，可以用Wait来阻塞，直到所有的goroutine都完成。\n更新于2021/05/12 23:45\n"},{"id":11,"href":"/posts/16/","title":"深拷贝之循环引用","section":"Posts","content":" 题目 # 实现如下结构体的深拷贝。\ntype Node struct { Data int Fields []*Node } 即指针指向的内存也需要Copy一份。\n解析 # 观察结构体，由于Fields字段里存放的是指向Node结构体的指针切片，深拷贝时要考虑循环引用的问题，如：\nstruct a : data: 1 fields: b, c struct b: data: 2 fields: c struct c: data: 3 fields: a // 这里循环引用了a， c-\u0026gt;a-\u0026gt;b, c-\u0026gt;a 可以考虑使用map[*Node]*Node来判断是否有环的情况，即用map[src] = dst来保存拷贝过的节点。\n代码 # 代码如下：\npackage main import ( \u0026#34;go/ast\u0026#34; \u0026#34;go/token\u0026#34; ) type Node struct { Data int Fields []*Node } // deep copy var M map[*Node]*Node func Dup(src *Node) *Node { if src == nil { return nil } node := \u0026amp;Node{ Data: src.Data, Fields: nil, } M[src] = node fields := []*Node{}//make([]*Node, len(src.Fields)) for i:=0;i\u0026lt;len(src.Fields);i++ { var tmp *Node if src.Fields[i] != nil { // if exist, is loop if addr, ok := M[src.Fields[i]]; ok { tmp = addr } else { tmp = Dup(src.Fields[i]) } } if tmp != nil { fields = append(fields, tmp) } } node.Fields = fields return node } func main() { M = make(map[*Node]*Node) a1 := \u0026amp;Node{ Data: 1, Fields: nil, } a2 := \u0026amp;Node{ Data: 2, Fields: nil, } a3 := \u0026amp;Node{ Data: 3, Fields: []*Node{a1, a2}, } a1.Fields = append(a1.Fields, a3) da3 := Dup(a3) // print ast tree _ = ast.Print(token.NewFileSet(),a3) _ = ast.Print(token.NewFileSet(),da3) } 输出如下：\n// a3 0 *main.Node { 1 . Data: 3 2 . Fields: []*main.Node (len = 2) { 3 . . 0: *main.Node { 4 . . . Data: 1 5 . . . Fields: []*main.Node (len = 1) { 6 . . . . 0: *(obj @ 0) // 指向了0行的obj 7 . . . } 8 . . } 9 . . 1: *main.Node { 10 . . . Data: 2 11 . . } 12 . } 13 } // da3 0 *main.Node { 1 . Data: 3 2 . Fields: []*main.Node (len = 2) { 3 . . 0: *main.Node { 4 . . . Data: 1 5 . . . Fields: []*main.Node (len = 1) { 6 . . . . 0: *(obj @ 0) // 同样指向了0行的obj 7 . . . } 8 . . } 9 . . 1: *main.Node { 10 . . . Data: 2 11 . . . Fields: []*main.Node (len = 0) {} 12 . . } 13 . } 14 } 再来调试看看运行时的地址情况： a3的信息如下： da3的信息如下：\n可以看到，da3里面的地址与a3均不一样，但是值信息是一样的。\n"},{"id":12,"href":"/posts/15/","title":"LRU 缓存机制","section":"Posts","content":" 题目 # 146. LRU 缓存机制\n解析 # 由于要求要用O(1)的时间复杂度，所以要采用双向链表＋map的数据结构解答。\n具体源码如下：\npackage main import \u0026#34;fmt\u0026#34; type LRUCache struct { M map[int]*Node Cap int Size int Head, Tail *Node } type Node struct { Key, Value int Pre, Next *Node } // init LRUCache func Constructor(capacity int) LRUCache { l := LRUCache{ M: map[int]*Node{}, Cap: capacity, Size: 0, Head: \u0026amp;Node{ Key: 0, Value: 0, Pre: nil, Next: nil, }, Tail: \u0026amp;Node{ Key: 0, Value: 0, Pre: nil, Next: nil, }, } // nil\u0026lt;-head\u0026lt;-\u0026gt;tail-\u0026gt; l.Head.Next = l.Tail l.Tail.Pre = l.Head return l } func (this *LRUCache) Get(key int) int { // get node and move to head next if node, ok := this.M[key]; ok { res := node.Value if node == this.Head.Next { return res } pre := node.Pre next := node.Next pre.Next = node.Next next.Pre = node.Pre node.Next = this.Head.Next this.Head.Next.Pre = node node.Pre = this.Head this.Head.Next = node return res } return -1 } func (this *LRUCache) Put(key int, value int) { // if exist, do update, and move to head next if this.Get(key) != -1 { this.Head.Next.Value = value return } // if not exist, move to head next node := \u0026amp;Node{ Key: key, Value: value, } next := this.Head.Next node.Next = next node.Pre = this.Head next.Pre = node this.Head.Next = node if this.Size == 0 { this.Tail.Pre = node } // size++ this.Size++ // insert to map this.M[key] = node // if size \u0026gt; cap, tail move to pre,and size-- if this.Size \u0026gt; this.Cap { rm := this.Tail.Pre this.Tail.Pre = rm.Pre rm.Pre.Next = this.Tail // delete from map delete(this.M, rm.Key) // clean value *rm = Node{} this.Size-- } } /** * Your LRUCache object will be instantiated and called as such: * obj := Constructor(capacity); * param_1 := obj.Get(key); * obj.Put(key,value); */ func main() { lRUCache := Constructor(2) lRUCache.Put(1, 1) // 缓存是 {1=1} lRUCache.Put(2, 2) // 缓存是 {1=1, 2=2} fmt.Println(lRUCache.Get(1)) // 返回 1 lRUCache.Put(3, 3) // 该操作会使得关键字 2 作废，缓存是 {1=1, 3=3} fmt.Println(lRUCache.Get(2)) // 返回 -1 (未找到) lRUCache.Put(4, 4) // 该操作会使得关键字 1 作废，缓存是 {4=4, 3=3} fmt.Println(lRUCache.Get(1)) // 返回 -1 (未找到) fmt.Println(lRUCache.Get(3)) // 返回 3 fmt.Println(lRUCache.Get(4)) // 返回 4 } "},{"id":13,"href":"/posts/14/","title":"Go源码解读之sync/atomic","section":"Posts","content":"注：go version 1.16.x\nOverview # 从网站pkg.go.dev上可以看到，对应的解释。\natomic包提供了用于实现同步算法的低级原子内存原语。\n可以分为几类操作：\nAdd操作：加减操作 CAS操作：先比较后赋值操作 Swap操作：赋值操作 Load操作：从某个地址中取值 Store操作：往某个地址赋值 Value类型：对任意类型的Load/Store操作封装 操作分类 # Add操作 # 由AddT函数实现的加法操作在原子上等效于：\n*addr += delta \\\\ 加上步长 正负数都可以 return *addr \\\\ 反回加后的结果 相关的方法有：\nfunc AddInt32(addr *int32, delta int32) (new int32) func AddUint32(addr *uint32, delta uint32) (new uint32) func AddInt64(addr *int64, delta int64) (new int64) func AddUint64(addr *uint64, delta uint64) (new uint64) func AddUintptr(addr *uintptr, delta uintptr) (new uintptr) CAS操作 # CAS即CompareAndSwap，这个函数主要就是先比较一下当前传入的地址的值是否和 old 值相等，如果相等，就赋值新值返回 true，如果不相等就返回 false.\n利用这个方法可以实现锁机制。\n相关的方法有：\nfunc CompareAndSwapInt32(addr *int32, old, new int32) (swapped bool) func CompareAndSwapInt64(addr *int64, old, new int64) (swapped bool) func CompareAndSwapUint32(addr *uint32, old, new uint32) (swapped bool) func CompareAndSwapUint64(addr *uint64, old, new uint64) (swapped bool) func CompareAndSwapUintptr(addr *uintptr, old, new uintptr) (swapped bool) func CompareAndSwapPointer(addr *unsafe.Pointer, old, new unsafe.Pointer) (swapped bool) 从源码runtime/internal/atomic/asm_amd64.s中可以看到CAS对应的汇编指令实现。 如CompareAndSwapInt32方法的实现：\n// bool Cas(int32 *val, int32 old, int32 new) // Atomically: //\tif(*val == old){ //\t*val = new; //\treturn 1; //\t} else //\treturn 0; TEXT runtime∕internal∕atomic·Cas(SB),NOSPLIT,$0-17 MOVQ\tptr+0(FP), BX MOVL\told+8(FP), AX MOVL\tnew+12(FP), CX LOCK CMPXCHGL\tCX, 0(BX) SETEQ\tret+16(FP) RET 从汇编指令可以看出，使用了CPU的LOCK指令来保证原子的操作，而CMPXCHGL指令则是CPU级别实现的CAS操作。\n关于LOCK指令，可以发散到CPU指令的锁总线、锁缓存等内容，而CPU会有多级缓存，这就需要通过缓存一致性去保证原子性。而MESI是缓存一致性协议的一种实现方法。\nCAS不能解决的问题 # CAS在共享资源竞争比较激烈的时候，每个goroutine会容易处于自旋状态，影响效率，在竞争激烈的时候推荐使用锁。 无法解决ABA问题 ABA问题是无锁结构实现中常见的一种问题，可基本表述为： 进程P1读取了一个数值A P1被挂起(时间片耗尽、中断等)，进程P2开始执行 P2修改数值A为数值B，然后又修改回A P1被唤醒，比较后发现数值A没有变化，程序继续执行。\nSwap操作 # Swap操作会执行交换操作，并且返回原来的值。\nold = *addr // 复制原来的值 *addr = new // 赋值为新的值 return old // 返回原来的值 func SwapInt32(addr *int32, new int32) (old int32) func SwapInt64(addr *int64, new int64) (old int64) func SwapPointer(addr *unsafe.Pointer, new unsafe.Pointer) (old unsafe.Pointer) func SwapUint32(addr *uint32, new uint32) (old uint32) func SwapUint64(addr *uint64, new uint64) (old uint64) func SwapUintptr(addr *uintptr, new uintptr) (old uintptr) Load操作 # 从某个地址里获取对应的值：\nreturn *addr 方法签名：\nfunc LoadInt32(addr *int32) (val int32) func LoadInt64(addr *int64) (val int64) func LoadPointer(addr *unsafe.Pointer) (val unsafe.Pointer) func LoadUint32(addr *uint32) (val uint32) func LoadUint64(addr *uint64) (val uint64) func LoadUintptr(addr *uintptr) (val uintptr) Store操作 # 往某个地址里赋值：\n*addr = val 方法签名：\nfunc StoreInt32(addr *int32, val int32) func StoreInt64(addr *int64, val int64) func StorePointer(addr *unsafe.Pointer, val unsafe.Pointer) func StoreUint32(addr *uint32, val uint32) func StoreUint64(addr *uint64, val uint64) func StoreUintptr(addr *uintptr, val uintptr) Value类型 # 从源码https://go.googlesource.com/go/+/go1.16.3/src/sync/atomic/value.go#16可以看到：\n定义：\ntype Value struct { v interface{} } func (v *Value) Load() (x interface{}) func (v *Value) Store(x interface{}) 源码如下：\n// Copyright 2014 The Go Authors. All rights reserved. // Use of this source code is governed by a BSD-style // license that can be found in the LICENSE file. package atomic import ( \u0026#34;unsafe\u0026#34; ) // A Value provides an atomic load and store of a consistently typed value. // The zero value for a Value returns nil from Load. // Once Store has been called, a Value must not be copied. // // A Value must not be copied after first use. type Value struct { v interface{} } // ifaceWords is interface{} internal representation. type ifaceWords struct { typ unsafe.Pointer data unsafe.Pointer } // Load returns the value set by the most recent Store. // It returns nil if there has been no call to Store for this Value. func (v *Value) Load() (x interface{}) { vp := (*ifaceWords)(unsafe.Pointer(v)) typ := LoadPointer(\u0026amp;vp.typ) if typ == nil || uintptr(typ) == ^uintptr(0) { // First store not yet completed. return nil } data := LoadPointer(\u0026amp;vp.data) xp := (*ifaceWords)(unsafe.Pointer(\u0026amp;x)) xp.typ = typ xp.data = data return } // Store sets the value of the Value to x. // All calls to Store for a given Value must use values of the same concrete type. // Store of an inconsistent type panics, as does Store(nil). func (v *Value) Store(x interface{}) { if x == nil { panic(\u0026#34;sync/atomic: store of nil value into Value\u0026#34;) } vp := (*ifaceWords)(unsafe.Pointer(v)) xp := (*ifaceWords)(unsafe.Pointer(\u0026amp;x)) for { typ := LoadPointer(\u0026amp;vp.typ) if typ == nil { // Attempt to start first store. // Disable preemption so that other goroutines can use // active spin wait to wait for completion; and so that // GC does not see the fake type accidentally. runtime_procPin() if !CompareAndSwapPointer(\u0026amp;vp.typ, nil, unsafe.Pointer(^uintptr(0))) { runtime_procUnpin() continue } // Complete first store. StorePointer(\u0026amp;vp.data, xp.data) StorePointer(\u0026amp;vp.typ, xp.typ) runtime_procUnpin() return } if uintptr(typ) == ^uintptr(0) { // First store in progress. Wait. // Since we disable preemption around the first store, // we can wait with active spinning. continue } // First store completed. Check type and overwrite data. if typ != xp.typ { panic(\u0026#34;sync/atomic: store of inconsistently typed value into Value\u0026#34;) } StorePointer(\u0026amp;vp.data, xp.data) return } } // Disable/enable preemption, implemented in runtime. func runtime_procPin() func runtime_procUnpin() 应用 # atomic.Value这种类型常用于读多写少的场景，比如配置结构体的热更新等。\n例子COW(Copy On Write) # 写时复制：（英语：Copy-on-write，简称 COW）是一种计算机程序设计领域的优化策略。其核心思想是，如果有多个调用者（callers）同时请求相同资源（如内存或磁盘上的数据存储），他们会共同获取相同的指针指向相同的资源，直到某个调用者试图修改资源的内容时，系统才会真正复制一份专用副本（private copy）给该调用者，而其他调用者所见到的最初的资源仍然保持不变。这过程对其他的调用者都是透明的。此作法主要的优点是如果调用者没有修改该资源，就不会有副本（private copy）被创建，因此多个调用者只是读取操作时可以共享同一份资源。\n维基百科\n通俗的讲就是，需要写入的时候我先把老的数据复制一份到一个新的对象，然后再写入新的值。\n存在的问题：老的对象可能会被其他goroutine使用而导致不回立即被垃圾回收，对于多写的场景会产生大量副本，从而导致性能下降。\n优点：无锁（或者说很轻量的锁），所以也不会有 goroutine 的上下文切换，并且在读取的时候大家都读取的相同的副本所以性能上回好一些。\nCOW 策略在 linux， redis 中都有很多的实践。\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;sync/atomic\u0026#34; ) type Map struct { v atomic.Value //writeMu sync.Mutex } func NewMap() *Map { res := \u0026amp;Map{ v: atomic.Value{}, //writeMu: sync.Mutex{}, } res.v.Store(make(map[string]string)) return res } func (m *Map) Get(key string) string { m1 := m.v.Load().(map[string]string) return m1[key] } func (m *Map) Put(key, val string) { //m.writeMu.Lock() // synchronize with other potential writers //defer m.writeMu.Unlock() m1 := m.v.Load().(map[string]string) // load current value of the data structure m2 := make(map[string]string) // create a new value for k, v := range m1 { m2[k] = v // copy all data from the current object to the new one } m2[key] = val // do the update that we need m.v.Store(m2) // atomically replace the current object with the new one // At this point all new readers start working with the new version. // The old version will be garbage collected once the existing readers // (if any) are done with it. } // COW func main() { m := NewMap() m.Put(\u0026#34;key\u0026#34;, \u0026#34;value\u0026#34;) fmt.Println(m.Get(\u0026#34;key\u0026#34;)) } "},{"id":14,"href":"/posts/13/","title":"使用Go遇到的坑","section":"Posts","content":" for range 语句中的值传递问题 # package main import \u0026#34;fmt\u0026#34; var pow = []int{1, 2, 4} func main() { for _, v := range pow { v++ } for _, v := range pow { fmt.Println(v) } } //out put : 1 2 4 原因：for range创建了每个元素的副本，而不是直接返回每个元素的引用。\nIPv4与IPv6格式问题 # Go中IPv4的长度和IPv6的长度是一样的，都是16Byte存储，故不能使用len()函数去区别:\nconn, err := net.Dial(\u0026#34;udp\u0026#34;, \u0026#34;8.9.10.11:2342\u0026#34;) if err != nil { fmt.Println(\u0026#34;Error\u0026#34;, err) } localaddr := conn.LocalAddr() addr, _ := net.ResolveUDPAddr(\u0026#34;udp\u0026#34;, localaddr.String()) ip := addr.IP fmt.Println(ip) fmt.Println(len(ip)) 详情请点击链接：golang-distinguish-ipv4-ipv6\ntransport使用不当导致不能共享tcp连接池，进而导致tcp连接过多 # // 初始化一个 http.Client func getClient() *http.Client { return \u0026amp;http.Client{ Transport: \u0026amp;http.Transport{ // 自定义 Transport TLSClientConfig: \u0026amp;tls.Config{InsecureSkipVerify: true}, }, Timeout: 5 * time.Second, } } func Post(url string) ([]byte, error) { client := getClient() req, err := http.NewRequest(\u0026#34;POST\u0026#34;, url, strings.NewReader(\u0026#34;test\u0026#34;)) if err != nil { return nil, err } httpRet, err := client.Do(req) if err != nil { return nil, err } defer httpRet.Body.Close() var body []byte body, err = ioutil.ReadAll(httpRet.Body) if err != nil { return nil, err } return body, nil } 代码存在问题：1、每次发请求都会创建一次连接；2、请求结束后没有及时释放连接；3、导致tcp连接暴涨\n原因：实例化transport时没有处理连接池问题，导致每次初始化都会使用新的连接。如果没有默认transport，实例化的client会使用一个default的transport，并且已经实现了池化。\n此外，如果请求的body没有完全读出，将会导致tcp连接不能服用。\n野生goroutine没有recover导致整个程序退出 # 使用gin时虽然会有上层的recover会对panic异常做兜底，但是对于自己定义的goroutine如果没有做recover就会导致整个程序垮掉：\nr.GET(\u0026#34;/panic1\u0026#34;, func (c *gin.Context) { var s *int fmt.Println(*s) // 制造空指针panic，这里会被gin上层的recover兜住，不会整个程序退出 }) r.GET(\u0026#34;/panic2\u0026#34;, func (c *gin.Context) { // 野生 goroutine go func() { var s *int fmt.Println(*s) // 这里会导致panic，整个程序退出 }() }) // 应该这样 r.GET(\u0026#34;/panic3\u0026#34;, func (c *gin.Context) { // 野生 goroutine go func() { // 定义recover兜住panic defer func() { if err := recover(); err != nil { fmt.Println(\u0026#34;recover success\u0026#34;) } } var s *int fmt.Println(*s) // 这里会导致panic，不会整个程序退出 }() }) 内存复用导致Map Key重复 # package main import ( \u0026#34;fmt\u0026#34; \u0026#34;unsafe\u0026#34; ) func main(){ m := make(map[string]int) for i := 0; i \u0026lt; 10; i++{ //fmt.Printf(\u0026#34;i=%d\\n\u0026#34;, i) b := []byte(\u0026#34;id2\u0026#34;) // 字面值为 id2，map计算 hash 时使用该字面值，即 b 的内容 \u0026#34;id2\u0026#34; // 从而 ，每次计算的是 hash(\u0026#34;id2\u0026#34;)，但实际内存中的值是 \u0026#34;id1\u0026#34;， // 从而每次 hash都会分配不同的桶存储 k/v，但实际 k 的值为 \u0026#34;id1\u0026#34; // *str 直接指向 b 的内存，再转成 *string，再取值 str := *(*string)(unsafe.Pointer(\u0026amp;b)) m[str]++ b[2] = \u0026#39;1\u0026#39; // 修改指向的内存的值，变为 id1 } b := []byte(\u0026#34;id2\u0026#34;) str := *(*string)(unsafe.Pointer(\u0026amp;b)) fmt.Println(m, len(m), m[\u0026#34;id2\u0026#34;], m[\u0026#34;id1\u0026#34;], m[str]) // out put // map[id1:1 id1:1 id1:1 id1:1 id1:1 id1:1 id1:1 id1:1 id1:1 id1:1] 10 0 0 0 } 在一些高性能的http服务框架中，如fasthttp，由于为了性能，减少重复的内存分配，很多地方会用到内存的复用，即采用了unsafe.Pointer来实现指向相同的内存空间，从而导致以上的问题。\ntime.AddDate()方法加减月份 # 在使用go官方包获取上个月份获取下个月份时，可能会直接这样获取：\nfunc TestXxx(t *testing.T) { this, err := time.Parse(time.RFC3339, \u0026#34;2023-03-30T15:04:05Z\u0026#34;) if err != nil { t.Fatal(err) } t.Log(this.AddDate(0, -1, 0)) // output: 2023-03-02 15:04:05 +0000 UTC } 由于day没有改变，所以month-1后得到2月30号，规范化成了3月2号。具体可以看AddDate源码。\n一个可行的解决办法是：\nt.Log(this.AddDate(0, 0, -this.Day())) // output: 2023-02-28 15:04:05 +0000 UTC 建议：\n不要直接使用AddDate(0, +-x, 0)方法计算加减月份 更新于: 2023/04/04 09:24:00\n"},{"id":15,"href":"/posts/12/","title":"构建属于你自己的核心力量","section":"Posts","content":" 前言 # Bridging the Gap Between Junior and Senior Engineers这篇文章是偶然在公众号看到的，觉得里面说的从Junior如何向Senior Engineers发展以及所需要掌握的技能，我觉得说的挺好的，这里就翻译过来，做为以后反省的清单吧，向大佬靠齐！\n部分原文译文 # 从Junior向Senior Engineers发展应该关注的一些问题：\n编码硬实力是基本的能力。\n你的代码的可维护性如何？是否有其他工程师不停地轻敲你的肩膀，让你解释你代码的每一行都是如何工作的？你的变量名具有描述性吗？你的方法是直观、易理解的吗？当你发现自己在复制粘贴很多行代码时，你是否能将这些代码的功能写入可重用的服务中？\n别人能够从你在拉取请求(PR)中留下的评论中受益吗？你的反馈意见是有建设性，还是太过粗糙？当你发现别人的知识存在缺口时，你只是告诉他们“把这条线从 ABC 更改为 XYZ”，还是有能力引导他们认识到自己的方法可能不是最佳方法，让他们成长为更优秀的开发者？毕竟，同样是学习新东西，授人以鱼不如授之以渔。\n你知道如何基准化你的更改并进行证明、测试吗？如果今天有 100,000 个用户创建帐户，你的代码是否会开始引发大量超时和 500 个错误？你能保证你的PR（合并请求）能够解决这些问题吗？\n你如何将非常技术的问题分解为公司其他部门可以理解的简单语言？向市场解释为什么一个功能实际上不可行时，你是否会让大量的工程术语从嘴里溜出来？\n你对面向对象的编程有深刻的了解吗？你提出的系统架构是不是“顶多算说得通”？\n你的写作能力如何？在回复电子邮件时，你是能把自己的意思表达清楚，还是发完邮件后同事仍然需要走到你的办公桌旁，来询问你更多的背景信息？\n你是否会主动提出想法，使你的团队效率更高？当需要改动现有进程时，你是否能够向所有参与方说明收益？你能使所有人都对这一变化感到兴奋吗？你是否可以持续跟进，并确保新流程确实有效？\n你尊重别人的时间吗？当你要求别人帮助你解决问题时，你能否准确描述你遇到问题的代码库的确切定位（如抛出异常的行号、你在问别人之前已经尝试过的 debug 方法，免得别人再浪费时间重复你已经做过的工作）？别人是否必须反复问你，才能从你嘴里撬出这些信息？在别人走到你办公桌前，你已经整理好要问的问题并在 MacBook 上打开了吗？\n在与其他部门一起确定大型项目的范围时，你对要开发的新功能的问题了解得有多深入？在开始编码之前，你是否能够考虑到每个边缘情况？你是否能够及早识别范围蔓延并尽早制止，从而使团队免于周六加班？\n你的多任务处理能力如何？你的大脑会超负荷吗？同样，在处理大型功能时，比如涉及 50 个文件的功能……你可以一次将它们全部保存在脑海中吗？你有养成扎实的记笔记习惯吗？你打算如何计划跟踪今天下班前弹出的 500 万件事？\n当你编写的一段代码导致帐单页面出错，搞得团队首席工程师不得不取消他们的晚餐计划、熬夜帮你解决问题时，你会如何应对？你会情绪激动吗？你还能理性思考吗？你是否能够摆脱这种情绪，并提醒自己，地球上的每个开发人员每两天就会发布错误代码？\n你了解业务运作方式吗？你了解为什么即使失业人数达到两位数，软件工程师也可以要求如此疯狂的薪水吗？为什么编程是如此宝贵的技能？为什么客户愿意为某些超级基本的 Web 表单向你的公司每年支付 50,000 美元？你是否觉得他们被骗了？\n领导可以放心地让你去负责面试候选人吗？你是否擅长通过有限的信息来对人员进行分类，并可视化他们和团队的适合程度？你能识别出在什么情况下，在工程方面优秀的候选人却不能很好地融入公司文化吗？这种候选人你会建议录取吗？同样，即使你和候选人在 Zoom 里聊了 5 分钟就知道他不可能被录取，你是否还可以确保他仍然可以从你们的聊天中学到东西？毕竟，语言在网络上的传播速度是很快的。\n假如今天是 12 月 28 日，你被困在办公室。你今年有点疯狂，在 9 月中旬就把今年所有的带薪休假糟蹋完了。此时此刻，同事们都休假出去 high 了。你还能按时上班吗？领导不在身边惩罚你，你是否打算半途而废？这种情形下，是否需要领导强迫你你才能尽全力工作？\n机会成本是一件必须考虑的事。你在平衡技术债务和推动业务发展方面做得如何？你是否会重构发现的每个微小的编码样式问题？毕竟大家都很难承认“这段代码很烦人，但它确实有效，需要花费四个小时的清理时间，这段时间可以花在构建其他功能上，而这是很多客户都在请求的”。\n你知道如何向你的下属反馈 他们 的绩效吗？你和他们有良好的工作关系吗？你是否将他们视为敌人？你是否正在积极尝试减轻他们的压力，使他们的生活更轻松？你是否曾经说过“你们那边有什么烦人的任务我可以帮忙削减吗”？公司雇人都是有原因的，你的下属可能比你想象的更有经验和资格。\n你有能力扑灭生产大火吗？你是否会在遇到 大麻烦 时惊慌、不知所措（比如 AWS 中断使网站瘫痪、不小心搞丢了 customer_invoices 表单、某些错误导致了不同用户帐户之间的数据泄漏等）？你是会在压力之下崩溃，还是会在解决问题的同时保持镇静，并与其他部门进行有效的沟通？\n如更好的向管理者方向发展？\n改进我们进行技术面试的方式，保证我们与候选人之间的沟通信噪比更高（如改善我们的面试问题、重新考虑我们的电子邮件模板、考虑是否要给面试者布置线下笔试题、反思我们对工作的描述是否准确、我们向哪里投放招聘广告、换位思考如果我正在寻找工作会如何回复该招聘信息、如何在候选人做出决定之前使其更深入地了解我们的公司文化和发展历程等等）\n与产品团队合作，以更细致的方式对即将开展的工作进行分类，从而使产品团队和最终要去接收 JIRA tickets 的工程师之间的沟通更加顺畅，而不需要磨叽好几个来回\n组织团建活动和团队聚餐\n当 CEO/CTO 为即将到来的季度制定的目标听起来有点过于乐观时，向他们提出提醒和意见，以免团队其他成员受不了过分辛苦的工作而逃离你们公司\n最好能每周与所有大的客户进行一次确认电话（亲自回答他们所有的技术问题，并确保双方之间的关系保持健康）\n用 6 个月的时间进行积极的安全审核，不断提醒客户我们会认真对待他们的隐私，并在公司发展的每个检查点努力完善我们的流程\n找出其他开发人员在知识上的不足之处，然后让他们查缺补漏（使用能激发他们学习兴趣的方式）：如使用 vim 宏处理 CSV 文件、Linux 终端中实用的短命令、高级 SQL 命令、如何使 PR 描述更具描述性、解释负载平衡器如何工作、讨论合并和重新定基之间的区别等\n帮助设计团队在花数小时将线框转换为高保真模型 之前，先弄清楚哪些功能易于开发\n改进我们的流程，让其他部门知道何时会增加新功能（编写更好的发行说明、在每周的内部产品演示中回答他们的问题、帮助他们编写客户能理解的外部文档），因为没人知道的功能不会解决任何实际问题\n“几年后，许多高级工程师走的路都是类似的。你可能在不知不觉中就变成了小领导，每天有 6 个人向你汇报工作。”\n参考文章：\nBridging the Gap Between Junior and Senior Engineers\n从初级工程师发展到高级工程师，需要跨越的鸿沟\n"},{"id":16,"href":"/posts/11/","title":"Golang实现优先队列","section":"Posts","content":" 前言 # 由于刷题时偶尔会用到队列以及优先队列等数据结构，其他语言都有现成的实现，如C++的priority_queue等，使用非常方便，但是由于个人比较喜欢使用golang语言进行答题，但是go对队列以及优先队列的实现只提供了一个接口，即container/heap包中的heap数据结构，故实现还是要自己去码，这里做一个笔记。实现了heap接口来实现priority_queue，并且提供了其他方法的实现。\nheap原理 # go的container/heap包实现的是数据结构是数组构成的二叉树（完全二叉树），如下所示：\n// 树中某个节点的值总是不大于或不小于其孩子节点的值； // 树中每个节点的子树都是堆树 // index 0 1 2 3 4 5 6 7 8 9 // index 1 2 3 4 5 6 7 8 9 10 // a[] = {4, 1, 3, 2, 16, 9, 10, 14, 8, 7} // 4 // / \\ // 1 3 // / \\ / \\ // 2 16 9 10 // /\\ / // 14 8 7 // 若取a[1]为堆顶最大或最小，a[i]的左子节点为a[2i],右子节点为a[2i+1],父节点为a[i/2]: // a[i] // / \\ // a[2i] a[2i+1] // 若取a[0]为堆顶最大或最小，a[i]的左子节点为a[2i+1],右子节点为a[2i+2],父节点为a[(i-1)/2] // a[i] // / \\ // a[2i+1] a[2i+2] 而container/heap包采用的是a[0]作为对顶，故左子、右子节点以及父节点表示为a[2i+1]、a[2i+2]、a[(i-1)/2]。\ncontainer/heap源码 # container/heap包是Go内置的接口，如下所示：\n// The Interface type describes the requirements // for a type using the routines in this package. // Any type that implements it may be used as a // min-heap with the following invariants (established after // Init has been called or if the data is empty or sorted): // //\t!h.Less(j, i) for 0 \u0026lt;= i \u0026lt; h.Len() and 2*i+1 \u0026lt;= j \u0026lt;= 2*i+2 and j \u0026lt; h.Len() // // Note that Push and Pop in this interface are for package heap\u0026#39;s // implementation to call. To add and remove things from the heap, // use heap.Push and heap.Pop. type Interface interface { sort.Interface Push(x interface{}) // add x as element Len() Pop() interface{} // remove and return element Len() - 1. } // Init establishes the heap invariants required by the other routines in this package. // Init is idempotent with respect to the heap invariants // and may be called whenever the heap invariants may have been invalidated. // The complexity is O(n) where n = h.Len(). func Init(h Interface) { // heapify n := h.Len() for i := n/2 - 1; i \u0026gt;= 0; i-- { down(h, i, n) } } // Push pushes the element x onto the heap. // The complexity is O(log n) where n = h.Len(). func Push(h Interface, x interface{}) { h.Push(x) up(h, h.Len()-1) } // Pop removes and returns the minimum element (according to Less) from the heap. // The complexity is O(log n) where n = h.Len(). // Pop is equivalent to Remove(h, 0). func Pop(h Interface) interface{} { n := h.Len() - 1 h.Swap(0, n) down(h, 0, n) return h.Pop() } // Remove removes and returns the element at index i from the heap. // The complexity is O(log n) where n = h.Len(). func Remove(h Interface, i int) interface{} { n := h.Len() - 1 if n != i { h.Swap(i, n) if !down(h, i, n) { up(h, i) } } return h.Pop() } // Fix re-establishes the heap ordering after the element at index i has changed its value. // Changing the value of the element at index i and then calling Fix is equivalent to, // but less expensive than, calling Remove(h, i) followed by a Push of the new value. // The complexity is O(log n) where n = h.Len(). func Fix(h Interface, i int) { if !down(h, i, h.Len()) { up(h, i) } } func up(h Interface, j int) { for { i := (j - 1) / 2 // parent if i == j || !h.Less(j, i) { break } h.Swap(i, j) j = i } } func down(h Interface, i0, n int) bool { i := i0 for { j1 := 2*i + 1 if j1 \u0026gt;= n || j1 \u0026lt; 0 { // j1 \u0026lt; 0 after int overflow break } j := j1 // left child if j2 := j1 + 1; j2 \u0026lt; n \u0026amp;\u0026amp; h.Less(j2, j1) { j = j2 // = 2*i + 2 // right child } if !h.Less(j, i) { break } h.Swap(i, j) i = j } return i \u0026gt; i0 } 简单使用 # 由以上源码可知，要实现一个heap数据结构，需要实现Len()、Less()（根据这里控制大顶堆还是小顶堆）、Swap()、Push()、Pop()、Fix()(或Update())方法，其中Fix方法是可选的。Fix方法主要是传入元素和元素所在数组的index，并且下沉该元素。\n下面实现一个简单的[]int数组构成的heap。\npackage heap type IntHeap []int func (h IntHeap) Len() int { return len(h) } func (h IntHeap) Less(i, j int) bool { return h[i] \u0026lt; h[j] } func (h IntHeap) Swap(i, j int) { h[i], h[j] = h[j], h[i] } func (h *IntHeap) Push(x interface{}) { *h = append(*h, x.(int)) } func (h *IntHeap) Pop() interface{} { old := *h n := len(old) x := old[n-1] *h = old[0 : n-1] return x } /** * test file **/ package heap import ( \u0026#34;container/heap\u0026#34; \u0026#34;log\u0026#34; \u0026#34;testing\u0026#34; ) func TestHeap(t *testing.T) { h := \u0026amp;IntHeap{1,2,4,5,6} heap.Init(h) heap.Push(h, -1) for h.Len() \u0026gt; 0 { log.Println(heap.Pop(h)) } } /** * output **/ === RUN TestHeap 2020/09/24 21:59:59 -1 2020/09/24 21:59:59 1 2020/09/24 21:59:59 2 2020/09/24 21:59:59 4 2020/09/24 21:59:59 5 2020/09/24 21:59:59 6 这样就可以实现int数组的小顶堆，如果需要实现更加复杂的数据结构的heap，可以参考[]int的方法来实现，如：\npackage heap type Data struct { key int value int wight int } type DataHeap []Data func (h DataHeap) Len() int { return len(h) } func (h DataHeap) Less(i, j int) bool { return h[i].wight \u0026lt; h[j].wight } func (h DataHeap) Swap(i, j int) { h[i], h[j] = h[j], h[i] } func (h *DataHeap) Push(x interface{}) { *h = append(*h, x.(Data)) } func (h *DataHeap) Pop() interface{} { old := *h n := len(old) x := old[n-1] *h = old[0 : n-1] return x } /** * test file **/ package heap import ( \u0026#34;container/heap\u0026#34; \u0026#34;log\u0026#34; \u0026#34;testing\u0026#34; ) func TestDataHeap(t *testing.T) { h := \u0026amp;DataHeap{Data{1,2,3},Data{1,4,5}, Data{1,4,0},Data{1,4,2}} heap.Init(h) heap.Push(h, Data{1,4,-340}) for h.Len() \u0026gt; 0 { log.Println(heap.Pop(h)) } } /** * output **/ === RUN TestDataHeap 2020/09/24 21:59:59 {1 4 -340} 2020/09/24 21:59:59 {1 4 0} 2020/09/24 21:59:59 {1 4 2} 2020/09/24 21:59:59 {1 2 3} 2020/09/24 21:59:59 {1 4 5} 其他方法实现heap # package main import ( \u0026#34;fmt\u0026#34; \u0026#34;math/rand\u0026#34; \u0026#34;time\u0026#34; ) // 堆实现最小优先队列，即最小堆 // 数据结构是数组构成的二叉树（完全二叉树） // 树中某个节点的值总是不大于或不小于其孩子节点的值； // 树中每个节点的子树都是堆树 // 1 2 3 4 5 6 7 8 9 10 // a[] = {4, 1, 3, 2, 16, 9, 10, 14, 8, 7} // 4 // / \\ // 1 3 // / \\ / \\ // 2 16 9 10 // /\\ / // 14 8 7 // 若取a[1]为堆顶最大或最小，a[i]的左子节点为a[2i],右子节点为a[2i+1],父节点为a[i/2] // 若取a[0]为堆顶最大或最小，a[i]的左子节点为a[2i+1],右子节点为a[2i+2],父节点为a[(i-1)/2] type PriorityHeap struct { arr []int } func (p *PriorityHeap) push(pri int) { p.arr = append(p.arr, pri) /*if len(p.arr) == 0 { return }*/ // fixup 比父节点小的就上浮 end := len(p.arr) - 1 father := (end - 1 ) / 2 for father \u0026gt;= 0 { if p.arr[father] \u0026lt;= p.arr[end] { break } p.arr[father], p.arr[end] = p.arr[end], p.arr[father] end = father father = (end - 1 ) / 2 } } func (p *PriorityHeap) pop() int { length := len(p.arr) if length == 0 { return -1 } res := p.arr[0] if length == 1 { p.arr = []int{} return res } p.arr[0] = p.arr[length-1] p.arr = p.arr[:length-1] length = len(p.arr) // fix down 比左、右节点小的越小越往哪边下沉 farther := 0 min := 2 * farther + 1 for min \u0026lt; length { if min+1 \u0026lt; length { // 右节点存在？ if p.arr[min] \u0026gt; p.arr[min+1] { // 左节点比右节点大？ min++ // 那就用右节点，否则往左子节点下沉 } } if p.arr[farther] \u0026lt;= p.arr[min] { break } p.arr[farther], p.arr[min] = p.arr[min], p.arr[farther] farther = min min = 2 * farther + 1 } return res } func initHeap() *PriorityHeap { p := \u0026amp;PriorityHeap{ arr: []int{}, } return p } func main() { p := initHeap() rand.Seed(time.Now().Unix()) for i:=0;i\u0026lt;10;i++ { p.push(rand.Int() % 100) } for i:=0;i\u0026lt;10;i++ { fmt.Println(p.pop(), i) } fmt.Println(p.pop()) /* output: 17 0 47 1 49 2 52 3 55 4 55 5 71 6 74 7 93 8 98 9 -1*/ } "},{"id":17,"href":"/posts/6/","title":"雪花算法","section":"Posts","content":" 前言 # 工作项目中有使用到雪花算法(snowflake)，觉得很有意思，所以想深入了解一下实现的原理并做记录。\n算法简介 # 什么是雪花算法 # snowflake，雪花。所以snowflake算法就叫做雪花算法。最早是Twitter内部使用的分布式环境唯一ID生成算法。\n解决了什么问题 # 那么，该算法主要解决了：\n高并发分布式系统环境下ID不重复 基于时间戳，可以保证有序递增 不依赖第三方库或中间件 生成效率高 算法原理 # 使用统一不重复系统编号的服务器+毫秒级时间戳+递增序列化生成64bit长整型数字：\n+-\u0026gt;1bit not use + 000000000000000000000000000000000000000000000000000000000000000 = 64 bit \u0026lt;--------------------------------------\u0026gt;\u0026lt;---+----\u0026gt;\u0026lt;----------\u0026gt; 41bit millisecond timestamp = 69 years | 12bit Inc num = 4096 v 10bit machine ID= 1024 64bit整数由以下部分组成：\n第一位置零，1为负数，故不用； 41位表示毫秒级时间戳； 10位表示机器ID，最多可以部署在1024台服务器上； 12位表示1毫秒的内递增序列，从0开始，到4095； 也就是说同一毫秒内最多能生成4096个id，超出的话需要等待下一毫秒，雪花算法最多冲突等待1ms。\n机器ID保证了系统内的机器唯一性，时间戳和递增序列号保证了时序递增。\n实现思路 # 了解了唯一ID的结构之后就可以简单实现雪花算法（伪代码）：\nmachineID # 机器ID n # 递增序列 now := time().now().Unix() if now == last { # 如果是同1毫秒内 n++ # 自增1 if n \u0026gt; 4095 { # 超过4095，则等待下一毫秒 now = nexttime() n = 0 } } else { n = 0 last = now } ID = now \u0026lt;\u0026lt; 22 | mashineID \u0026lt;\u0026lt; 12 | n # 将结果拼接为64bit之后转换成十进制 深入源代码 # 雪花生成算法见：snowflake\n代码主要生成部分:\n// Generate creates and returns a unique snowflake ID // To help guarantee uniqueness // - Make sure your system is keeping accurate system time // - Make sure you never have multiple nodes running with the same node ID func (n *Node) Generate() ID { n.mu.Lock() now := time.Since(n.epoch).Nanoseconds() / 1000000 if now == n.time { // 如果是同一毫秒内 n.step = (n.step + 1) \u0026amp; n.stepMask // 自增1并校验是否超过4095 if n.step == 0 { for now \u0026lt;= n.time { now = time.Since(n.epoch).Nanoseconds() / 1000000 } } } else { // 不在同一ms n.step = 0 } n.time = now // 拼接64bit r := ID((now)\u0026lt;\u0026lt;n.timeShift | (n.node \u0026lt;\u0026lt; n.nodeShift) | (n.step), ) n.mu.Unlock() return r } 总结 # 雪花算法不难理解并且简单能够自己实现，这大概是这个算法被广泛使用的一个原因吧，此外，雪花算法对系统的时钟依赖性很高，如果有某个系统时钟不同步，可能会生成同一时间戳的ID值。\n参考\nhttp://www.machengyu.net/tech/2019/12/04/snowflake.html https://www.bilibili.com/video/BV1Xa4y1i7Ax https://github.com/bwmarrin/snowflake\n"},{"id":18,"href":"/posts/5/","title":"Golang-channel","section":"Posts","content":" 前言 # 本文主要记录平时使用Golang的channel对象是如何在内存中存储和实现的，包括channel的创建、发送、接收、实现和关闭，最佳实践等，有时还应该更加关注channel的阻塞问题，以及select底层实现与channel的选择执行。\nchannel与goroutine # goroutine, to execute tasks independently, potentially in parallel. channels, for communication, synchronization between goroutine.\n正如上面说的，goroutine是独立地，可能并行地执行任务。channel是服务与goroutine之间的通讯，同步等。\nGo语言的并发模型是基于CSP的， Golang从CSP中吸收了Process/Channel。\nchannel是一种：\n协程安全 可以在协程之间存储和传输值 先进先出 能够导致协程阻塞或不阻塞（block or unblock） 关于goroutine的内容以后在深入，本文就重点了解一下channel。\nDo not communicate by sharing memory; instead, share memory by communicating.\n这是Go语言的并发哲学。\n下面就来详细了解一下golang是如何实现channel这个对象，并且如何实现goroutine之间的数据通信的。\nchannel的基本使用 # var ch chan int //声明一个int类型的channel，注意，该语句仅声明，不初始化channel ch := make(chan int) //创建一个无缓冲的int型的channel，无缓冲的channel当放入1个元素后，后续的输入便会阻塞 ch := make(chan int, 10) //创建一个缓冲区大小为10的int型的channel ch \u0026lt;- x //将x发送到channel中，如果channel缓冲区满，则阻塞当前goroutine \u0026lt;- ch //从channel中接收一个值，如果缓冲区为空，则阻塞 x = \u0026lt;- ch //从channel中接收一个值并存到x中，如果缓冲区为空，则阻塞 x, ok = \u0026lt;- ch //从channel中接收一个值，如果channel关闭了，那么ok为false（在没有defaultselect语句的前提下），在channel未关闭且为空的情况下，会阻塞 close(ch) //关闭channel for item := range ch {} //等待并取出channel中的值，直到channel关闭，会阻塞 无缓冲区的channel # 从无缓存的channel中读取消息会阻塞，直到goroutine向channel中发送消息；同理，向无缓存的channel 中发送消息也会阻塞，直到有goroutine从channel中读取消息。\n有缓冲区的channel # 有缓存的channe 的构造方式为指定make函数的第二个参数，该参数为channel缓存的容量。\nch := make(chan int, 10) 有缓存的channel实现了一个阻塞队列(采用环形数组实现)。当缓存未满时，向channel中发送消息时不会阻塞，当缓存满时，发送操作将被阻塞，直到有其他goroutine从中读取消息；相应的，当channel中消息不为空时，读取消息不会出现阻塞，当channel为空时，读取操作会造成阻塞，直到有goroutine向channel中写入消息。\n只读/只写的channel # //定义只读的channel read_only := make (\u0026lt;-chan int) //定义只写的channel write_only := make (chan\u0026lt;- int) //可同时读写 read_write := make (chan int) 一般来说， 只读或者只写的channel主要用在参数传递上面，比如有一个读取和发送数据的函数，那么在函数参数定义的时候可以限定channel类型，使得权限最小。\n//只能往channel里面写数据 func send(ch chan\u0026lt;- int) { for i := 0; i \u0026lt; 5; i++ { ch \u0026lt;- i } } //只能从channel里面读数据 func recv(ch \u0026lt;-chan int) { for i := range ch { fmt.Println(i) } } channel的底层实现 # 我们知道channel不能new出来，只能make出来，这是因为channel本身数据结构的复杂性。 我们本次主要重点看一下channel底层是如何实现的。（源码是基于Go 1.10.2） channel的数据结构表示\n在src/runtime/chan.go里面定义了channel的数据结构\ntype hchan struct { qcount uint // total data in the queue： channel的当前元素个数，也就是len方法的结果 dataqsiz uint // size of the circular queue：channel的容量，环形队列的大小，cap方法的结果 buf unsafe.Pointer // points to an array of dataqsiz elements :环形数组实现的缓冲区 elemsize uint16 // 每个元素的大小 closed uint32 //标志位，标识是否close elemtype *_type // element type： channel存放元素的类型 sendx uint // send index： 环形队列中下一次发送元素的索引 recvx uint // receive index： 环形队列中下一次接收元素的索引 recvq waitq // list of recv waiters ： recv的goroutinue的等待队列 sendq waitq // list of send waiters ： send的goroutinue的等待队列 // lock protects all fields in hchan, as well as several // fields in sudogs blocked on this channel. // // Do not change another G\u0026#39;s status while holding this lock // (in particular, do not ready a G), as this can deadlock // with stack shrinking. lock mutex //互斥量，保证同步安全 } 上面就是channel对象的数据结构表示，内部有一个环形队列来存放数据。并且还有两个waitq链表来实现goroutine的等待队列，用来存放哪些goroutine因为send或者recv被阻塞在了这个channel上面：\ntype waitq struct { first *sudog last *sudog } 最后sudog就是对于goroutine中的G的封装, 记录的就是因为channel读写被阻塞的goroutine。 make channel的实现\nfunc makechan(t *chantype, size int) *hchan { elem := t.elem ... // Hchan does not contain pointers interesting for GC when elements stored in buf do not contain pointers. // buf points into the same allocation, elemtype is persistent. // SudoG\u0026#39;s are referenced from their owning thread so they can\u0026#39;t be collected. // TODO(dvyukov,rlh): Rethink when collector can move allocated objects. var c *hchan switch { case size == 0 || elem.size == 0: //没有缓冲区 // Queue or element size is zero. c = (*hchan)(mallocgc(hchanSize, nil, true)) // Race detector uses this location for synchronization. c.buf = unsafe.Pointer(c) case elem.kind\u0026amp;kindNoPointers != 0: //channel不包含指针 // Elements do not contain pointers. // Allocate hchan and buf in one call. c = (*hchan)(mallocgc(hchanSize+uintptr(size)*elem.size, nil, true)) c.buf = add(unsafe.Pointer(c), hchanSize) default: // Elements contain pointers. c = new(hchan) c.buf = mallocgc(uintptr(size)*elem.size, elem, true) } c.elemsize = uint16(elem.size) c.elemtype = elem c.dataqsiz = uint(size) ... return c } 可以看得出来，make channel里面主要是要申请环形队列的内存块，也就是为什么channel不能用new来实现的原因了。\n并且make channel申请数据的堆内存，所以我们可以直接传递channel对象而不是channel的指针。\nchannel的send方法 # 我们通过上面的图来表示发送和接受的流程，刚开始的时候，缓冲区都是空的。如果开始发送，那么变成下面这种状态，并且sendx开始累加。\n缓冲区发送满了以后就是这种状态：\nchannel send的源代码：\nfunc chansend(c *hchan, ep unsafe.Pointer, block bool, callerpc uintptr) bool { //如果想一个nil的channel发送数据，会调用gopark将当前的goroutine休眠， //然后通过第一个参数唤醒，但是下面传入的第一个参数也是nil那么就会导致这个goroutine一直休眠 //如果goroutine sysmon检查到这种情况就，就会throw(\u0026#34;all goroutines are asleep - deadlock!\u0026#34;) if c == nil { if !block { return false } gopark(nil, nil, \u0026#34;chan send (nil chan)\u0026#34;, traceEvGoStop, 2) throw(\u0026#34;unreachable\u0026#34;) } ... if raceenabled { racereadpc(unsafe.Pointer(c), callerpc, funcPC(chansend)) } // Fast path: check for failed non-blocking operation without acquiring the lock. // // After observing that the channel is not closed, we observe that the channel is // not ready for sending. Each of these observations is a single word-sized read // (first c.closed and second c.recvq.first or c.qcount depending on kind of channel). // Because a closed channel cannot transition from \u0026#39;ready for sending\u0026#39; to // \u0026#39;not ready for sending\u0026#39;, even if the channel is closed between the two observations, // they imply a moment between the two when the channel was both not yet closed // and not ready for sending. We behave as if we observed the channel at that moment, // and report that the send cannot proceed. // // It is okay if the reads are reordered here: if we observe that the channel is not // ready for sending and then observe that it is not closed, that implies that the // channel wasn\u0026#39;t closed during the first observation. if !block \u0026amp;\u0026amp; c.closed == 0 \u0026amp;\u0026amp; ((c.dataqsiz == 0 \u0026amp;\u0026amp; c.recvq.first == nil) || (c.dataqsiz \u0026gt; 0 \u0026amp;\u0026amp; c.qcount == c.dataqsiz)) { return false } var t0 int64 if blockprofilerate \u0026gt; 0 { t0 = cputicks() } //获取同步锁 lock(\u0026amp;c.lock) //不能向已经close的channel发送数据，否则直接panic if c.closed != 0 { unlock(\u0026amp;c.lock) panic(plainError(\u0026#34;send on closed channel\u0026#34;)) } //如果有goroutine在这个channel上面等待，那么直接将数据发送给这个接收goroutine if sg := c.recvq.dequeue(); sg != nil { // Found a waiting receiver. We pass the value we want to send // directly to the receiver, bypassing the channel buffer (if any). send(c, sg, ep, func() { unlock(\u0026amp;c.lock) }, 3) return true } //缓冲队列还没有满，那么直接将数据复制到缓冲队列里面 if c.qcount \u0026lt; c.dataqsiz { // Space is available in the channel buffer. Enqueue the element to send. qp := chanbuf(c, c.sendx) if raceenabled { raceacquire(qp) racerelease(qp) } typedmemmove(c.elemtype, qp, ep) c.sendx++ if c.sendx == c.dataqsiz { c.sendx = 0 } c.qcount++ unlock(\u0026amp;c.lock) return true } if !block { unlock(\u0026amp;c.lock) return false } // Block on the channel. Some receiver will complete our operation for us. //如果缓冲队列满了，俺么就将当前的发送goroutine塞到发送队列中去 gp := getg() mysg := acquireSudog() mysg.releasetime = 0 if t0 != 0 { mysg.releasetime = -1 } // No stack splits between assigning elem and enqueuing mysg // on gp.waiting where copystack can find it. mysg.elem = ep mysg.waitlink = nil mysg.g = gp mysg.isSelect = false mysg.c = c gp.waiting = mysg gp.param = nil c.sendq.enqueue(mysg) //入队列 goparkunlock(\u0026amp;c.lock, \u0026#34;chan send\u0026#34;, traceEvGoBlockSend, 3) // someone woke us up. if mysg != gp.waiting { throw(\u0026#34;G waiting list is corrupted\u0026#34;) } gp.waiting = nil if gp.param == nil { if c.closed == 0 { throw(\u0026#34;chansend: spurious wakeup\u0026#34;) } panic(plainError(\u0026#34;send on closed channel\u0026#34;)) } gp.param = nil if mysg.releasetime \u0026gt; 0 { blockevent(mysg.releasetime-t0, 2) } mysg.c = nil releaseSudog(mysg) return true } 从上面的代码可以看到基本发送流程\n获取同步锁，对缓冲队列进行加锁 如果有等待的goroutinue，那么数据直接发送给这个接收goroutine，数据拷贝1次 如果缓冲队列没有满，将发送的数据拷贝到队列中，sendx加1 如果缓冲队列满了，那么将发送goroutine放到发送阻塞队列中 channel的recv方法 # 在发送的章节，我们已经把缓冲区里面存放了数据，然后就是接受的goroutinue开始接受数据了。 image.png\n直到把数据读完阻塞为止。\nchannel recv的源代码：\nfunc chanrecv(c *hchan, ep unsafe.Pointer, block bool) (selected, received bool) { // raceenabled: don\u0026#39;t need to check ep, as it is always on the stack // or is new memory allocated by reflect. ... // Fast path: check for failed non-blocking operation without acquiring the lock. // // After observing that the channel is not ready for receiving, we observe that the // channel is not closed. Each of these observations is a single word-sized read // (first c.sendq.first or c.qcount, and second c.closed). // Because a channel cannot be reopened, the later observation of the channel // being not closed implies that it was also not closed at the moment of the // first observation. We behave as if we observed the channel at that moment // and report that the receive cannot proceed. // // The order of operations is important here: reversing the operations can lead to // incorrect behavior when racing with a close. if !block \u0026amp;\u0026amp; (c.dataqsiz == 0 \u0026amp;\u0026amp; c.sendq.first == nil || c.dataqsiz \u0026gt; 0 \u0026amp;\u0026amp; atomic.Loaduint(\u0026amp;c.qcount) == 0) \u0026amp;\u0026amp; atomic.Load(\u0026amp;c.closed) == 0 { return } var t0 int64 if blockprofilerate \u0026gt; 0 { t0 = cputicks() } //加锁 lock(\u0026amp;c.lock) //如果channel已经关闭并且channel为空，那么recv的时候返回空值 if c.closed != 0 \u0026amp;\u0026amp; c.qcount == 0 { if raceenabled { raceacquire(unsafe.Pointer(c)) } unlock(\u0026amp;c.lock) if ep != nil { typedmemclr(c.elemtype, ep) } return true, false } //如果有send阻塞队列 //如果channel没有缓冲区，那么直接从send goroutine接收数据 //否则从缓冲区队列头取出数据，并且唤醒send开始写入数据到队列尾部 if sg := c.sendq.dequeue(); sg != nil { // Found a waiting sender. If buffer is size 0, receive value // directly from sender. Otherwise, receive from head of queue // and add sender\u0026#39;s value to the tail of the queue (both map to // the same buffer slot because the queue is full). recv(c, sg, ep, func() { unlock(\u0026amp;c.lock) }, 3) return true, true } //缓存队列不为空，那么从队列获取数据 if c.qcount \u0026gt; 0 { // Receive directly from queue qp := chanbuf(c, c.recvx) if raceenabled { raceacquire(qp) racerelease(qp) } if ep != nil { typedmemmove(c.elemtype, ep, qp) } typedmemclr(c.elemtype, qp) c.recvx++ if c.recvx == c.dataqsiz { c.recvx = 0 } c.qcount-- unlock(\u0026amp;c.lock) return true, true } if !block { unlock(\u0026amp;c.lock) return false, false } //缓存队列为空，那么将recv goroutine加入到recv阻塞队列中 // no sender available: block on this channel. gp := getg() mysg := acquireSudog() mysg.releasetime = 0 if t0 != 0 { mysg.releasetime = -1 } // No stack splits between assigning elem and enqueuing mysg // on gp.waiting where copystack can find it. mysg.elem = ep mysg.waitlink = nil gp.waiting = mysg mysg.g = gp mysg.isSelect = false mysg.c = c gp.param = nil c.recvq.enqueue(mysg) goparkunlock(\u0026amp;c.lock, \u0026#34;chan receive\u0026#34;, traceEvGoBlockRecv, 3) // someone woke us up if mysg != gp.waiting { throw(\u0026#34;G waiting list is corrupted\u0026#34;) } gp.waiting = nil if mysg.releasetime \u0026gt; 0 { blockevent(mysg.releasetime-t0, 2) } closed := gp.param == nil gp.param = nil mysg.c = nil releaseSudog(mysg) return true, !closed } channel的数据接收和发送比较类似：\n对于队列进行加锁 如果有send阻塞队列，那么 如果channel没有缓冲区，那么直接从send goroutine接收数据 否则从缓冲区队列头取出数据，并且唤醒send开始写入数据到队列尾部 缓存队列不为空，那么从队列获取数据，数据都是拷贝出来的。 缓存队列为空，那么将recv goroutine加入到recv阻塞队列中 关闭channel # func closechan(c *hchan) { if c == nil { panic(plainError(\u0026#34;close of nil channel\u0026#34;)) } lock(\u0026amp;c.lock) //重复close同一个channel会panic if c.closed != 0 { unlock(\u0026amp;c.lock) panic(plainError(\u0026#34;close of closed channel\u0026#34;)) } if raceenabled { callerpc := getcallerpc() racewritepc(unsafe.Pointer(c), callerpc, funcPC(closechan)) racerelease(unsafe.Pointer(c)) } c.closed = 1 var glist *g //把所有的阻塞的recvgoroutine唤醒 // release all readers for { sg := c.recvq.dequeue() if sg == nil { break } if sg.elem != nil { typedmemclr(c.elemtype, sg.elem) sg.elem = nil } if sg.releasetime != 0 { sg.releasetime = cputicks() } gp := sg.g gp.param = nil if raceenabled { raceacquireg(gp, unsafe.Pointer(c)) } gp.schedlink.set(glist) glist = gp } //唤醒所有的阻塞的send // release all writers (they will panic) for { sg := c.sendq.dequeue() if sg == nil { break } sg.elem = nil if sg.releasetime != 0 { sg.releasetime = cputicks() } gp := sg.g gp.param = nil if raceenabled { raceacquireg(gp, unsafe.Pointer(c)) } gp.schedlink.set(glist) glist = gp } unlock(\u0026amp;c.lock) // Ready all Gs now that we\u0026#39;ve dropped the channel lock. for glist != nil { gp := glist glist = glist.schedlink.ptr() gp.schedlink = 0 goready(gp, 3) } } close channel 的工作除了将 ch.closed 设置为1。还需要：\n唤醒 recvq 队列里面的阻塞 goroutine 唤醒 sendq 队列里面的阻塞 goroutine 处理方式是分别遍历 recvq 和 sendq 队列，将所有的 goroutine 放到 glist 队列中，最后唤醒 glist 队列中的 goroutine。 select与channel # select用于在多个channel上同时进行侦听并收发消息，当任何一个case满足条件时即执行，如果没有可执行的case则会执行default的case，如果没有指定defaultcase，则会阻塞程序，select的语法：\nselect { case communication clause : statement(s); case communication clause : statement(s); /*可以定义任意数量的 case */ default : /*可选 */ statement(s); } 下面来看一下golang底层是如何实现select和channel的配合的。 一个send case + default\n对于这种情况，chan.go源码中是如下实现：\n// compiler implements // // select { // case c \u0026lt;- v: // ... foo // default: // ... bar // } // // as // // if selectnbsend(c, v) { // ... foo // } else { // ... bar // } // func selectnbsend(c *hchan, elem unsafe.Pointer) (selected bool) { return chansend(c, elem, false, getcallerpc()) } 一个recv case + default // compiler implements // // select { // case v = \u0026lt;-c: // ... foo // default: // ... bar // } // // as // // if selectnbrecv(\u0026amp;v, c) { // ... foo // } else { // ... bar // } // func selectnbrecv(elem unsafe.Pointer, c *hchan) (selected bool) { selected, _ = chanrecv(c, elem, false) return } 带有ok结果的recv + default // compiler implements // // select { // case v, ok = \u0026lt;-c: // ... foo // default: // ... bar // } // // as // // if c != nil \u0026amp;\u0026amp; selectnbrecv2(\u0026amp;v, \u0026amp;ok, c) { // ... foo // } else { // ... bar // } // func selectnbrecv2(elem unsafe.Pointer, received *bool, c *hchan) (selected bool) { // TODO(khr): just return 2 values from this function, now that it is in Go. selected, *received = chanrecv(c, elem, false) return } 多种case + default混合 如果下面这种多个case混合的代码，那么select是如何工作的呢？ func main() { var ch chan int var ch2 chan int //省略初始化channel select { case \u0026lt;-ch: case v, _ := \u0026lt;-ch2: fmt.Println(v) case ch \u0026lt;- 1: default: } } 我们通过go build -gcflags -S helloworld.go 2\u0026gt; helloworld.s来反汇编上面的代码，可以看到下面的代码。\n0x0084 00132 (helloworld.go:11) CALL runtime.newselect(SB) 0x0089 00137 (helloworld.go:12) LEAQ \u0026#34;\u0026#34;..autotmp_8+88(SP), AX 0x008e 00142 (helloworld.go:12) MOVQ AX, (SP) 0x0092 00146 (helloworld.go:12) XORPS X1, X1 0x0095 00149 (helloworld.go:12) MOVUPS X1, 8(SP) 0x009a 00154 (helloworld.go:12) MOVQ $0, 24(SP) 0x00a3 00163 (helloworld.go:12) PCDATA $0, $1 0x00a3 00163 (helloworld.go:12) CALL runtime.selectrecv(SB) 0x00a8 00168 (helloworld.go:13) LEAQ \u0026#34;\u0026#34;..autotmp_8+88(SP), AX 0x00ad 00173 (helloworld.go:13) MOVQ AX, (SP) 0x00b1 00177 (helloworld.go:13) MOVQ $0, 8(SP) 0x00ba 00186 (helloworld.go:13) LEAQ \u0026#34;\u0026#34;..autotmp_3+64(SP), CX 0x00bf 00191 (helloworld.go:13) MOVQ CX, 16(SP) 0x00c4 00196 (helloworld.go:13) MOVQ $0, 24(SP) 0x00cd 00205 (helloworld.go:13) PCDATA $0, $1 0x00cd 00205 (helloworld.go:13) CALL runtime.selectrecv(SB) 0x00d2 00210 (helloworld.go:15) LEAQ \u0026#34;\u0026#34;..autotmp_8+88(SP), AX 0x00d7 00215 (helloworld.go:15) MOVQ AX, (SP) 0x00db 00219 (helloworld.go:15) MOVQ $0, 8(SP) 0x00e4 00228 (helloworld.go:15) LEAQ \u0026#34;\u0026#34;..autotmp_7+48(SP), CX 0x00e9 00233 (helloworld.go:15) MOVQ CX, 16(SP) 0x00ee 00238 (helloworld.go:15) PCDATA $0, $1 0x00ee 00238 (helloworld.go:15) CALL runtime.selectsend(SB) 0x00f3 00243 (helloworld.go:16) LEAQ \u0026#34;\u0026#34;..autotmp_8+88(SP), AX 0x00f8 00248 (helloworld.go:16) MOVQ AX, (SP) 0x00fc 00252 (helloworld.go:16) PCDATA $0, $1 0x00fc 00252 (helloworld.go:16) CALL runtime.selectdefault(SB) 0x0101 00257 (helloworld.go:11) LEAQ \u0026#34;\u0026#34;..autotmp_8+88(SP), AX 0x0106 00262 (helloworld.go:11) MOVQ AX, (SP) 0x010a 00266 (helloworld.go:11) PCDATA $0, $1 0x010a 00266 (helloworld.go:11) CALL runtime.selectgo(SB) 0x010f 00271 (helloworld.go:11) MOVQ 8(SP), AX 0x0114 00276 (helloworld.go:12) TESTQ AX, AX 其中下面这几行就是关键： 0x0084 00132 (helloworld.go:11) CALL runtime.newselect(SB) 0x00a3 00163 (helloworld.go:12) CALL runtime.selectrecv(SB) 0x00cd 00205 (helloworld.go:13) CALL runtime.selectrecv(SB) 0x00ee 00238 (helloworld.go:15) CALL runtime.selectsend(SB) 0x00fc 00252 (helloworld.go:16) CALL runtime.selectdefault(SB) 0x010a 00266 (helloworld.go:11) CALL runtime.selectgo(SB) 我们在src\\runtime\\select.go下面可以找到selectgo方法，这个是select的调度方法：\nfunc selectgo(sel *hselect) int { ... loop: // pass 1 - look for something already waiting var dfli int var dfl *scase var casi int var cas *scase for i := 0; i \u0026lt; int(sel.ncase); i++ { casi = int(pollorder[i]) cas = \u0026amp;scases[casi] c = cas.c switch cas.kind { case caseNil: continue //接收数据 case caseRecv: sg = c.sendq.dequeue() //如果有发送goroutine阻塞，那么就接收数据 if sg != nil { goto recv } //如果缓冲队列里面有数据，接收数据 if c.qcount \u0026gt; 0 { goto bufrecv } //如果channel是关闭的 if c.closed != 0 { goto rclose } case caseSend: if raceenabled { racereadpc(unsafe.Pointer(c), cas.pc, chansendpc) } if c.closed != 0 { goto sclose } //如果有接收goroutine阻塞，那么就发送数据 sg = c.recvq.dequeue() if sg != nil { goto send } //如果缓冲区不为空，那么发送数据 if c.qcount \u0026lt; c.dataqsiz { goto bufsend } //default分支 case caseDefault: dfli = casi dfl = cas } } } 其他的selectsend， selectrecv， selectdefault都是增加select的scases，将分支加入到调度列表中去。\nfunc newselect(sel *hselect, selsize int64, size int32) { if selsize != int64(selectsize(uintptr(size))) { print(\u0026#34;runtime: bad select size \u0026#34;, selsize, \u0026#34;, want \u0026#34;, selectsize(uintptr(size)), \u0026#34;\\n\u0026#34;) throw(\u0026#34;bad select size\u0026#34;) } sel.tcase = uint16(size) sel.ncase = 0 sel.lockorder = (*uint16)(add(unsafe.Pointer(\u0026amp;sel.scase), uintptr(size)*unsafe.Sizeof(hselect{}.scase[0]))) sel.pollorder = (*uint16)(add(unsafe.Pointer(sel.lockorder), uintptr(size)*unsafe.Sizeof(*hselect{}.lockorder))) } func selectsend(sel *hselect, c *hchan, elem unsafe.Pointer) { pc := getcallerpc() i := sel.ncase if i \u0026gt;= sel.tcase { throw(\u0026#34;selectsend: too many cases\u0026#34;) } sel.ncase = i + 1 if c == nil { return } cas := (*scase)(add(unsafe.Pointer(\u0026amp;sel.scase), uintptr(i)*unsafe.Sizeof(sel.scase[0]))) cas.pc = pc cas.c = c cas.kind = caseSend cas.elem = elem if debugSelect { print(\u0026#34;selectsend s=\u0026#34;, sel, \u0026#34; pc=\u0026#34;, hex(cas.pc), \u0026#34; chan=\u0026#34;, cas.c, \u0026#34;\\n\u0026#34;) } } select有自己的数据结构，包括hselect和scase，这里就不详细展开select的内部实现原理的，我们只要理解下面几点：\n如果select下面只有default语句，或者只有一个case+defaut语句，编译器会重新生成一些代码，简单处理这种情况。 selectgo函数是执行case语句的方法，主要按照下面的步骤来实施 evaluate all the involved channels and values permuting the cases slice elements (randomize) ordering elements according to cases hchan address locking all the channels starting to loop… a. checking if a channel is already waiting, so we can use it immediately (and it’s done) b. otherwise, enqueuing on all channels (and sleep) c. waiting for another goroutine to wake us up d. another goroutine wake us up (done = 1) e. dequeuing of all the other channels i. if we were waken up by a channel close operation, return to a. ii. else, we’re done :) 发送和接收的阻塞 # 我们从前面可以看到，如果发送的时候，接收端没有准备好，或者缓冲区队列是满的，那么就会将当前的goroutine阻塞，然后等待唤醒。 这个主要是涉及到了goroutine的底层模型以及调度机制，这里主要简单描述一下channel对象中sudog对象是如何工作的。\nimage.png\n这里举一个发送的例子，如果给一个缓冲区已经满了的channel发送数据，就会生成一个sudog对象，sudog对象里面封装的就是发送goroutine， 这个goroutine被阻塞。 image.png\n如果这时候recv的goroutine开始接受数据，那么找到被阻塞的send goroutine的sudog， 然后把sudog的队列的数据塞到缓冲区队列里面，并且激活这个sudog对象，让里面的goroutine成为runnable。 image.png 总结\n回到刚开始的那句话： image.png 这个需要大家好好体会一下goroutine和channel是如何实现这个思想的，并且从分析源码中，我们可以看到使用channel对象的一些常见问题：\n给一个nil channel发送数据，造成永远阻塞 从一个nil channel接收数据，造成永远阻塞 给一个已经关闭的channel发送数据，引起panic 从一个已经关闭的channel接收数据，立即返回一个零值 关闭已经已经关闭的channel，引起panic 关闭一个nil channel，引起panic 参考资料\nunderstanding-channels\n"},{"id":19,"href":"/posts/4/","title":"Golang语言模型","section":"Posts","content":" 前言 # 这篇笔记主要记录一下学习Go见到的各种数据类型，从数据类型在内存的分布上看了解其中的原理，主要包括：\n基本类型（int, string, uint, int8, int16, byte, rune, unitptr, float32, float64, complex64, complex128, bool等） 数组和slice的内存模型（string是特殊的slice） 指针的内存模型及unitptr与unsafe.Pointer、普通指针 *T的区别 map的内存模型 struct的内存模型和字节对齐 channel、goroutine的内存模型以后单独记录 interface的内存模型已经在第一篇笔记里 Go的内存模型与C语言很像，所以了解C语言应该很容易理解Go的内存模型。\n基本类型的内存模型 # Go语言有18种基本的数据结构：\nbool string rune byte int uint int8 uint8 int16 uint16 int32 uint32 int64 uint64 float32 float64 complex64 complex128 其中string和bool类型比较特殊，这个后面讨论。\n然后 byte 类型是uint8的别名，rune是int32的别名。\n平台相关的数据类型有：\nuint：int32 或者是 int64，看机子类型 uintptr：足够表示指针大小的无符号整数类型 这些基本类型在内存中的表示如：\n数组和切片 # 数组 # 对于数组来说，如：var arr = [5]byte{1,2,3,4,5}\n对于arr这个[5]byte类型，他的内存就是5个连续的字节, 一个数组的定义同时包括了长度和类型。 比如：var a [4]int，那么就表示声明了一个类型是数组，元素类型是int，长度是4。这里需要注意的是Go语言的数组和C语言的不一样，C语言的数组是一个指针，指向数组的一个元素。但是在Go语言里面数组就是一个普通的值类型。而不是一个指向数组内存起始位置的指针，也不能和同类型的指针进行转化。\n所以[4]int和[5]int表示两种完全不同的类型。\n切片 # 在之前的一些golang基础里已经有一些切片类型的简单使用方法了，这里就来探究一下切片的底层数据结构和实现。\n切片是对数组中一段数据的引用。在内存中它有三段数据组成：一个指向数据头的指针、切片的长度、切片的容量。长度是索引操作的上界，如：x[i] 。容量是切片操作的上界，如：x[i:j]。\n比如我通过s := make([]byte, 5)当容量参数被忽略时，它默认为指定的长度，创建的切片内存如下：\n如果我们通过修改切片引用的数据区域和大小，s = s[2:4], 那么就变成了如下的结构\n我们通过下面的代码可以很快弄清楚slice的内存模型\ntype sliceA struct { ptr unsafe.Pointer len int cap int } func main() { a := [5]byte{0} fmt.Println(unsafe.Pointer(\u0026amp;a)) s := a[:] ptr := *(*sliceA)(unsafe.Pointer(\u0026amp;s)) fmt.Println(ptr) s = s[2:4] ptr = *(*sliceA)(unsafe.Pointer(\u0026amp;s)) fmt.Println(ptr) } 输出结果如下： 0xc042038448 {0xc042038448 5 5} {0xc04203844a 2 3} 0xc04203844a - 0xc042038448 = 2， 刚好是偏移了两个byte。\n从上面的内存模型来看，如果两个数组相互赋值，那么将会触发数组全量拷贝的动作，但是如果是传递切片，那么将只需要永远申请固定大小的切片对象就可以了，底层的数组通过引用传递。\n切片的内存增长 # 从内存模型来看，切片就是引用了一个固定的数组， 一个切片的容量受到起始索引和底层数组容量的限制。Go语言提供了内置的copy和append函数来增长切片的容量，那么调用这些函数以后切片的内存会发生什么变化呢？\ncopy和append这两个是内置函数，是看不到go源码实现，可能使用C/C++/汇编实现的：\nfunc copy(dst, src []Type) int func append(slice []Type, elems ...Type) []Type copy方法\ncopy方法并不会修改slice的内存模型，仅仅是将某个slice的内容拷贝到另外一个slice中去。底层的实现在runtime\\slice.go中，这个方法比较简单，就不赘述了。\nfunc slicecopy(to, fm slice, width uintptr) int append方法\ntype sliceA struct { ptr unsafe.Pointer len int cap int } func main() { a := make([]int, 1) ptr := *(*sliceA)(unsafe.Pointer(\u0026amp;a)) fmt.Println(ptr) // a == []int{0} a = append(a, 1, 2, 3) // a == []int{0, 1, 2, 3} ptr = *(*sliceA)(unsafe.Pointer(\u0026amp;a)) fmt.Println(ptr) } 输出结果是： {0xc04203a448 1 1} {0xc0420369e0 4 4} 那么从上面可以看出，append方法其实重新生成了一个新的数组，然后返回的切片引用了这个新的数组，那我们来重点看一下append方法的实现，为了简单点，写出下面的代码，然后生成汇编：\nfunc main() { b := []byte{\u0026#39;a\u0026#39;} b = append(b, \u0026#39;b\u0026#39;) fmt.Println(string(b), cap(b)) // output : ab 8 } 从下面的汇编可以得到两个信息： runtime.growslice是用来实现slice增长的函数 cap函数的实现仅仅是调用b.cap这个成员\n\u0026#34;\u0026#34;.main STEXT size=348 args=0x0 locals=0x80 ... 0x0036 00054 (goslice.go:9)\tLEAQ\ttype.uint8(SB), AX 0x003d 00061 (goslice.go:9)\tPCDATA\t$2, $0 0x003d 00061 (goslice.go:9)\tMOVQ\tAX, (SP) 0x0041 00065 (goslice.go:9)\tPCDATA\t$2, $1 0x0041 00065 (goslice.go:9)\tLEAQ\t\u0026#34;\u0026#34;..autotmp_9+71(SP), AX 0x0046 00070 (goslice.go:9)\tPCDATA\t$2, $0 0x0046 00070 (goslice.go:9)\tMOVQ\tAX, 8(SP) 0x004b 00075 (goslice.go:9)\tMOVQ\t$1, 16(SP) 0x0054 00084 (goslice.go:9)\tMOVQ\t$1, 24(SP) 0x005d 00093 (goslice.go:9)\tMOVQ\t$2, 32(SP) 0x0066 00102 (goslice.go:9)\tCALL\truntime.growslice(SB) // 实现slice增长 0x006b 00107 (goslice.go:9)\tPCDATA\t$2, $1 0x006b 00107 (goslice.go:9)\tMOVQ\t40(SP), AX 0x0070 00112 (goslice.go:9)\tMOVQ\t48(SP), CX 0x0075 00117 (goslice.go:9)\tMOVQ\t56(SP), DX 0x007a 00122 (goslice.go:9)\tMOVQ\tDX, \u0026#34;\u0026#34;.b.cap+72(SP) 0x007f 00127 (goslice.go:9)\tMOVB\t$98, 1(AX) 0x0083 00131 (goslice.go:10)\tMOVQ\t$0, (SP) 0x008b 00139 (goslice.go:10)\tPCDATA\t$2, $0 0x008b 00139 (goslice.go:10)\tMOVQ\tAX, 8(SP) 0x0090 00144 (goslice.go:9)\tLEAQ\t1(CX), AX 0x0094 00148 (goslice.go:10)\tMOVQ\tAX, 16(SP) 0x0099 00153 (goslice.go:10)\tMOVQ\tDX, 24(SP) 0x009e 00158 (goslice.go:10)\tCALL\truntime.slicebytetostring(SB) 0x00a3 00163 (goslice.go:10)\tMOVQ\t40(SP), AX 0x00a8 00168 (goslice.go:10)\tPCDATA\t$2, $2 0x00a8 00168 (goslice.go:10)\tMOVQ\t32(SP), CX 0x00ad 00173 (goslice.go:10)\tPCDATA\t$2, $0 0x00ad 00173 (goslice.go:10)\tMOVQ\tCX, (SP) 0x00b1 00177 (goslice.go:10)\tMOVQ\tAX, 8(SP) 0x00b6 00182 (goslice.go:10)\tCALL\truntime.convTstring(SB) ... growslice的实现：src\\runtime\\slice.go\nfunc growslice(et *_type, old slice, cap int) slice { newcap := old.cap doublecap := newcap + newcap if cap \u0026gt; doublecap { // 如果新的大小是当前大小2倍以上，则大小增长为新大小 newcap = cap } else { if old.len \u0026lt; 1024 { // 如果当前大小小于1024，按每次2倍增长 newcap = doublecap } else { // 否则每次按当前大小1/4增长，直到增长的大小超过或等于新大小 for newcap \u0026lt; cap { newcap += newcap / 4 } } } ...... var p unsafe.Pointer if et.kind\u0026amp;kindNoPointers != 0 { p = mallocgc(capmem, nil, false) memmove(p, old.array, lenmem) // The append() that calls growslice is going to overwrite from old.len to cap (which will be the new length). // Only clear the part that will not be overwritten. memclrNoHeapPointers(add(p, newlenmem), capmem-newlenmem) } else { // Note: can\u0026#39;t use rawmem (which avoids zeroing of memory), because then GC can scan uninitialized memory. p = mallocgc(capmem, et, true) if !writeBarrier.enabled { memmove(p, old.array, lenmem) } else { for i := uintptr(0); i \u0026lt; lenmem; i += et.size { typedmemmove(et, add(p, i), add(old.array, i)) } } } return slice{p, old.len, newcap} } 具体实现的代码就不说了，其实就是判断cap，生成一个新的数组，将old的元素拷贝到新的slice中去。 扩容规则上面的代码已经说明了：\n如果新的大小是当前大小2倍以上，则大小增长为新大小， 否则循环以下操作：如果当前大小小于1024，按每次2倍增长，否则每次按当前大小1/4增长。直到增长的大小超过或等于新大小。\n在runtime\\slice.go中，我们可以看到\ntype slice struct { array unsafe.Pointer len int cap int } 这个也是Go语言内部的slice数据结构，和我们前面定义的是一致的，slice的make，copy，grow等函数都在这个文件中实现\n字符串\n字符串在内存中其实表示成了这么一个数据结构 这个定义是在runtime\\string.go中定义的\ntype stringStruct struct { str unsafe.Pointer len int } s := \u0026#34;hello\u0026#34; ptr := *(*stringStruct)(unsafe.Pointer(\u0026amp;s)) fmt.Println(ptr) t := s[:3] ptr = *(*stringStruct)(unsafe.Pointer(\u0026amp;t)) fmt.Println(ptr) t = s[2:3] ptr = *(*stringStruct)(unsafe.Pointer(\u0026amp;t)) fmt.Println(ptr) 从上面的代码可以输出如下的结果：\n{0x4b1cbe 5} {0x4b1cbe 3} {0x4b1cc0 1} 所以说，字符串也是一种特殊的切片，但是是没有容量，只有长度属性。\nmap的实现 # Go语言的map并不是像C++的map一样用二叉树实现的，而是典型Hash实现的。\n定义一个map：\nvar Map map[string]string // 只是定义，没有分配空间，不能使用 Map = make(map[string]string) // 分配空间 cMap := make(map[string]string) // 也可以这样 在src\\runtime\\map.go里面可以找到具体的实现：\ntype hmap struct { count int // count 用于记录当前哈希表元素数量，这个字段让我们不再需要去遍历整个哈希表来获取长度 flags uint8 // B uint8 // 表示了当前哈希表持有的 buckets 数量，但是因为哈希表的扩容是以 2 倍数进行的，所以这里会使用对数来存储，我们可以简单理解成 len(buckets) == 2^B noverflow uint16 // hash0 uint32 // 哈希种子，这个值会在调用哈希函数的时候作为参数传进去，它的主要作用就是为哈希函数的结果引入一定的随机性 buckets unsafe.Pointer // oldbuckets unsafe.Pointer // 哈希在扩容时用于保存之前 buckets 的字段，它的大小都是当前 buckets 的一半； nevacuate uintptr // extra *mapextra // } go语言的map其实就是一个bucket的数组，这个数组的大小永远是2的次幂。 具体的实现可以在这里看到：https://draveness.me/golang/docs/part2-foundation/ch03-datastructure/golang-hashmap/\nstruct结构体 # Go语言里面的结构体内存模型和C语言里面一样的，都是连续的内存，如果是指针，那么就通过指针跳转\ntype Point struct { X int Y int } 那么内存模型就是：\nstruct的字节对齐 # 在64位系统上面，Go语言的字节是8直接对齐，如果不足的，就补充padding。 这里有详细的描述：http://www.geeksforgeeks.org/structure-member-alignment-padding-and-data-packing/\n下面有一个简单的例子：\ntype Example struct { BoolValue bool // 1 byte IntValue int16 // 2 byte FloatValue float32 // 4 byte } func main() { example := \u0026amp;Example{ BoolValue: true, IntValue: 10, FloatValue: 3.141592, } alignmentBoundary := unsafe.Alignof(example) sizeBool := unsafe.Sizeof(example.BoolValue) offsetBool := unsafe.Offsetof(example.BoolValue) sizeInt := unsafe.Sizeof(example.IntValue) offsetInt := unsafe.Offsetof(example.IntValue) sizeFloat := unsafe.Sizeof(example.FloatValue) offsetFloat := unsafe.Offsetof(example.FloatValue) fmt.Printf(\u0026#34;size Example: %d\\n\u0026#34;, unsafe.Sizeof(example)) fmt.Printf(\u0026#34;Alignment Boundary: %d\\n\u0026#34;, alignmentBoundary) fmt.Printf(\u0026#34;BoolValue = Size: %d Offset: %d Addr: %v\\n\u0026#34;, sizeBool, offsetBool, \u0026amp;example.BoolValue) fmt.Printf(\u0026#34;IntValue = Size: %d Offset: %d Addr: %v\\n\u0026#34;, sizeInt, offsetInt, \u0026amp;example.IntValue) fmt.Printf(\u0026#34;FloatValue = Size: %d Offset: %d Addr: %v\\n\u0026#34;, sizeFloat, offsetFloat, \u0026amp;example.FloatValue) } 输出结果如下：\nsize Example: 8 Alignment Boundary: 8 BoolValue = Size: 1 Offset: 0 Addr: 0xc04200a230 IntValue = Size: 2 Offset: 2 Addr: 0xc04200a232 FloatValue = Size: 4 Offset: 4 Addr: 0xc04200a234 可以看出在64位机器是按照8字节对齐的，并且bool的后面增加了一个字节的padding\nmake和new # 在Go语言里面有两种方式来创建数据结构：new和make\n切片、map和通道，使用make， 数组、结构体和所有的值类型，使用new， 因为new仅仅是分配内存，但是make还包括了初始化， 因为slice，map和channel在底层实现的时候并不是一个简单的值，而是一个数据结构，并且这个数据结构中要初始化以后才能使用。并且make不是返回指针，而是返回一个类型。\n对于切片，使用new和make的区别：\ntype sliceA struct { ptr unsafe.Pointer len int cap int } func main() { p := new([]int) ptr := *(*sliceA)(unsafe.Pointer(p)) fmt.Println(ptr) q := make([]int, 0) ptr = *(*sliceA)(unsafe.Pointer(\u0026amp;q)) fmt.Println(ptr) } // ouput: {\u0026lt;nil\u0026gt; 0 0} {0x5811b0 0 0} 我们来看一下slice的make做了啥：\nfunc makeslice(et *_type, len, cap int) unsafe.Pointer { mem, overflow := math.MulUintptr(et.size, uintptr(cap)) if overflow || mem \u0026gt; maxAlloc || len \u0026lt; 0 || len \u0026gt; cap { // NOTE: Produce a \u0026#39;len out of range\u0026#39; error instead of a // \u0026#39;cap out of range\u0026#39; error when someone does make([]T, bignumber). // \u0026#39;cap out of range\u0026#39; is true too, but since the cap is only being // supplied implicitly, saying len is clearer. // See golang.org/issue/4085. mem, overflow := math.MulUintptr(et.size, uintptr(len)) if overflow || mem \u0026gt; maxAlloc || len \u0026lt; 0 { panicmakeslicelen() } panicmakeslicecap() } return mallocgc(mem, et, true) } 从上面来看，最重要就是通过mallocgc来申请了一个数组。\n通过查看汇编代码就可以看出make底层是调用哪个函数了:\nfunc makemap(t *maptype, hint int, h *hmap) *hmap { mem, overflow := math.MulUintptr(uintptr(hint), t.bucket.size) if overflow || mem \u0026gt; maxAlloc { hint = 0 } // initialize Hmap if h == nil { h = new(hmap) } h.hash0 = fastrand() // Find the size parameter B which will hold the requested # of elements. // For hint \u0026lt; 0 overLoadFactor returns false since hint \u0026lt; bucketCnt. B := uint8(0) for overLoadFactor(hint, B) { B++ } h.B = B // allocate initial hash table // if B == 0, the buckets field is allocated lazily later (in mapassign) // If hint is large zeroing this memory could take a while. if h.B != 0 { var nextOverflow *bmap h.buckets, nextOverflow = makeBucketArray(t, h.B, nil) if nextOverflow != nil { h.extra = new(mapextra) h.extra.nextOverflow = nextOverflow } } return h } 从上面看，map初始化最重要的就是创建buckets。\n总结 # 整体来说，Go语言的对象内存模型比C++要简单的多并且与C很像，毕竟没有继承，虚函数，多重继承等等，了解这些内存模型，对于平时使用这些类型时可以少踩坑是有帮助的。\n参考链接：\nhttps://skyao.io/learning-go/grammar/type/basic.html\nhttps://studygolang.com/articles/9169\n使用map实现set\n"},{"id":20,"href":"/posts/3/","title":"初探Gin框架","section":"Posts","content":" 入门简介 # Gin是一个高性能的HTTP web框架，用Go编写，目前托管在GitHub上：Gin 官方文档：Gin-doc 中文版：Gin-doc Gin框架的几个特性：\n路由（Routing）：将请求映射到函数，支持动态路由。如/hello/:name 鉴权：统一、分组鉴权能力 模板：统一简化的HTML机制 中间件：一个请求经过多个中间件拦截最后到达DB，如logging .etc 其中比较关键的组件是router路由组件，gin使用的算法是radix 树，是trie 树（前缀树）的一种压缩版本，他们的区别是：假如存在三个单词：hello, hat, have，trie 树得到的数据结构是：\ne - l - l - o / h - a - t \\ v - e 总共9个节点。而radix树得到的数据结构是：\n* / (ello) / * - h - * -(a) - * - (t) - * \\ (ve) \\ * 只需要5个节点，所以，radix树使用更小的内存，但是很难实现。详情请参考：what-is-the-difference-between-trie-and-radix-trie-data-structures\nGin使用的radix算法实现是：httprouter\n原理及用法 # 路由Routing # go语言本身内置了net/http库，封装了HTTP网络接口，Gin实现的web框架也是基于net/http库。\n这个库的简单用法：\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;log\u0026#34; \u0026#34;net/http\u0026#34; ) func main() { http.HandleFunc(\u0026#34;/\u0026#34;, indexHandler) log.Fatal(http.ListenAndServe(\u0026#34;:9999\u0026#34;, nil)) } // 处理请求 func indexHandler(w http.ResponseWriter, req *http.Request) { fmt.Fprintf(w, \u0026#34;URL.Path = %q\\n\u0026#34;, req.URL.Path) } //$ curl http://localhost:9999/ //URL.Path = \u0026#34;/\u0026#34; http.ListenAndServe(“:9999”, nil)这个函数表示监听本地9999端口，nil代表使用标准库中的实例去处理所有的HTTP请求，假如我们自己实现该参数类型，就可以使用我们自己设计的实例去处理所有HTTP请求了，Gin正是这么做的。\n那么第二个参数是什么类型呢？可以查看net/http的源码：\nfunc ListenAndServe(addr string, handler Handler) error { server := \u0026amp;Server{Addr: addr, Handler: handler} return server.ListenAndServe() } 是一个Handler，那么Handler是什么类型呢：\ntype Handler interface { ServeHTTP(ResponseWriter, *Request) } 是一个接口，需要实现ServeHTTP方法就行，也就是只要传入实现了该接口的实例，所有的HTTP请求都能被这个实例处理：\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;net/http\u0026#34; ) // 路由处理函数 type HandlerFunc func(http.ResponseWriter, *http.Request) // Engine 实现 ServeHTTP 接口，使用map进行静态的路由匹配 type Engine struct { router map[string]HandlerFunc } // New 创建Engine func New() *Engine { return \u0026amp;Engine{router: make(map[string]HandlerFunc)} } // 添加路由 func (engine *Engine) addRoute(method string, pattern string, handler HandlerFunc) { key := method + \u0026#34;-\u0026#34; + pattern engine.router[key] = handler } // GET 定义GET路由添加 func (engine *Engine) GET(pattern string, handler HandlerFunc) { engine.addRoute(\u0026#34;GET\u0026#34;, pattern, handler) } // Run 启动 http server func (engine *Engine) Run(addr string) (err error) { return http.ListenAndServe(addr, engine) } // 实现 ServrHTTP 方法 func (engine *Engine) ServeHTTP(w http.ResponseWriter, req *http.Request) { key := req.Method + \u0026#34;-\u0026#34; + req.URL.Path if handler, ok := engine.router[key]; ok { handler(w, req) } else { fmt.Fprintf(w, \u0026#34;404 NOT FOUND: %s\\n\u0026#34;, req.URL) } } func main() { r := New() r.GET(\u0026#34;/\u0026#34;, func(w http.ResponseWriter, req *http.Request) { fmt.Fprintf(w, \u0026#34;URL.Path = %q\\n\u0026#34;, req.URL.Path) }) r.Run(\u0026#34;:9999\u0026#34;) } //$ curl http://localhost:9999/ //URL.Path = \u0026#34;/\u0026#34; 以上是一个简单的Engine的实现方法，现在我们来看Gin的实现：\n// ServeHTTP conforms to the http.Handler interface. func (engine *Engine) ServeHTTP(w http.ResponseWriter, req *http.Request) { c := engine.pool.Get().(*Context) c.writermem.reset(w) c.Request = req c.reset() engine.handleHTTPRequest(c) engine.pool.Put(c) } Gin的Engine结构比较复杂，所以他实现的功能繁多。并且也实现动态路由，可以试试如何使用：\nget方法：\npackage main import ( \u0026#34;github.com/gin-gonic/gin\u0026#34; \u0026#34;net/http\u0026#34; ) func main() { r := gin.Default() r.GET(\u0026#34;ping\u0026#34;, func(c *gin.Context) { c.JSON(200, gin.H{ \u0026#34;message\u0026#34;:\u0026#34;pong\u0026#34;, }) }) r.GET(\u0026#34;/user/:name\u0026#34;, func(c *gin.Context) { name := c.Param(\u0026#34;name\u0026#34;) c.String(http.StatusOK, \u0026#34;Hello %s !\u0026#34;, name) }) r.GET(\u0026#34;/file/*name\u0026#34;, func(c *gin.Context) { name := c.Param(\u0026#34;name\u0026#34;) c.String(http.StatusOK, \u0026#34;Hello %s !\u0026#34;, name) }) r.Run() } 测试一下:\n$ curl http://localhost:8080/ping {\u0026#34;message\u0026#34;:\u0026#34;pong\u0026#34;} $ curl http://localhost:8080/user/kid Hello kid ! $ curl http://localhost:8080/file/assert/static/js/do.js Hello /assert/static/js/do.js ! $ curl http://localhost:8080/user 404 page not found post方法：\nr.POST(\u0026#34;/post/value\u0026#34;, func(c *gin.Context) { c.String(http.StatusOK, \u0026#34;ok!\u0026#34;) }) 测试：\n$ curl -X POST http://localhost:8080/post/value ok! 此外还有：PUT、DELETE、PATCH、HEAD、OPTION：\nrouter.GET(\u0026#34;/someGet\u0026#34;, getting) router.POST(\u0026#34;/somePost\u0026#34;, posting) router.PUT(\u0026#34;/somePut\u0026#34;, putting) router.DELETE(\u0026#34;/someDelete\u0026#34;, deleting) router.PATCH(\u0026#34;/somePatch\u0026#34;, patching) router.HEAD(\u0026#34;/someHead\u0026#34;, head) router.OPTIONS(\u0026#34;/someOptions\u0026#34;, options) 实现一个高级路由:\npackage main import ( \u0026#34;github.com/gin-gonic/gin\u0026#34; \u0026#34;net/http\u0026#34; ) func main() { r := gin.Default() r.GET(\u0026#34;/user/:name\u0026#34;, func(c *gin.Context) { name := c.Param(\u0026#34;name\u0026#34;) c.String(http.StatusOK, \u0026#34;Hit /user/:name , %s !\u0026#34;, name) }) r.GET(\u0026#34;/user/:name/*action\u0026#34;, func(c *gin.Context) { name := c.Param(\u0026#34;name\u0026#34;) action := c.Param(\u0026#34;action\u0026#34;) c.String(http.StatusOK, \u0026#34;Hit /user/:name/*action , %s %s !\u0026#34;, name, action) }) r.Run() } 测试：\n$ curl http://localhost:8080/user/kid Hit /user/:name , kid ! $ curl http://localhost:8080/user/kid/ Hit /user/:name/*action , kid / ! $ curl http://localhost:8080/user/kid/assert Hit /user/:name/*action , kid /assert ! 路由分组 # 分组控制是web框架所必须的基础功能之一，路由分组就是以相同前缀作为区分一个路由的流向，并支持分组嵌套。比如/api是一个分组，/api/v1 ，/api/v2可以是该分组下的子分组，作用在/api分组上的中间件也会作用在子分组上，子分组还可以拥有自己特有的中间件。例如/admin的分组，可以应用鉴权中间件；/分组应用日志中间件，/是默认的最顶层的分组，也就意味着给所有的路由，即整个框架增加了记录日志的能力。\n简单使用:\npackage main import ( \u0026#34;github.com/gin-gonic/gin\u0026#34; ) func main() { r := gin.Default() v1 := r.Group(\u0026#34;v1\u0026#34;) { v1.GET(\u0026#34;/login\u0026#34;, func(c *gin.Context) { c.String(200, \u0026#34;Hit %s\u0026#34;, c.FullPath()) }) } v2 := r.Group(\u0026#34;v2\u0026#34;) { v2.GET(\u0026#34;/login\u0026#34;, func(c *gin.Context) { c.String(200, \u0026#34;Hit %s \u0026#34;, c.FullPath()) }) } r.Run() } 测试：\n$ curl http://localhost:8080/v1/login Hit /v1/login $ curl http://localhost:8080/v2/login Hit /v2/login 使用中间件 # Gin使用中间很简单，只需修改gin.Default()为gin.New()，default方法使用了默认的log中间件和recover中间件。\n// Default returns an Engine instance with the Logger and Recovery middleware already attached. func Default() *Engine { debugPrintWARNINGDefault() engine := New() engine.Use(Logger(), Recovery()) return engine } 使用中间件：\nfunc main() { // 新建一个没有任何默认中间件的路由 r := gin.New() // 全局中间件 // Logger 中间件将日志写入 gin.DefaultWriter，即使你将 GIN_MODE 设置为 release。 // By default gin.DefaultWriter = os.Stdout r.Use(gin.Logger()) // Recovery 中间件会 recover 任何 panic。如果有 panic 的话，会写入 500。 r.Use(gin.Recovery()) // 你可以为每个路由添加任意数量的中间件。 r.GET(\u0026#34;/benchmark\u0026#34;, MyBenchLogger(), benchEndpoint) // 认证路由组 // authorized := r.Group(\u0026#34;/\u0026#34;, AuthRequired()) // 和使用以下两行代码的效果完全一样: authorized := r.Group(\u0026#34;/\u0026#34;) // 路由组中间件! 在此例中，我们在 \u0026#34;authorized\u0026#34; 路由组中使用自定义创建的 // AuthRequired() 中间件 authorized.Use(AuthRequired()) { authorized.POST(\u0026#34;/login\u0026#34;, loginEndpoint) authorized.POST(\u0026#34;/submit\u0026#34;, submitEndpoint) authorized.POST(\u0026#34;/read\u0026#34;, readEndpoint) // 嵌套路由组 testing := authorized.Group(\u0026#34;testing\u0026#34;) testing.GET(\u0026#34;/analytics\u0026#34;, analyticsEndpoint) } // 监听并在 0.0.0.0:8080 上启动服务 r.Run(\u0026#34;:8080\u0026#34;) } 具体中间件的实现代码可以查看源码。也可以实现一个中间件，并且使用c.Next()方法控制调用逻辑。\n实现文件上传 # package main import ( \u0026#34;github.com/gin-gonic/gin\u0026#34; \u0026#34;log\u0026#34; ) func main() { r := gin.Default() r.POST(\u0026#34;/upload\u0026#34;, func(c *gin.Context) { file , _ := c.FormFile(\u0026#34;file\u0026#34;) log.Println(file.Filename) c.String(200, \u0026#34;%s uploaded\u0026#34;, file.Filename) }) r.POST(\u0026#34;/uploads\u0026#34;, func(c *gin.Context) { from , _ := c.MultipartForm() files := from.File[\u0026#34;upload[]\u0026#34;] for _, file := range files { log.Println(file.Filename) } c.String(200, \u0026#34;%d files uploaded\u0026#34;, len(files)) }) r.Run() } 测试：\n$ curl -X POST http://localhost:8080/upload -F \u0026#34;file=@./test.txt\u0026#34; -H \u0026#34;Content-Type: multipart/form-data\u0026#34; test.txt uploaded $ curl -X POST http://localhost:8080/uploads -F \u0026#34;upload[]=@./test.txt\u0026#34; -F \u0026#34;upload[]=@./test.txt\u0026#34; -H \u0026#34;Content-Type: multipart/form-data\u0026#34; 2 files uploaded 参数 # 使用动态路由时，可以指定/:name来实现对参数name的动态解析，具体是用c.Param(\u0026quot;name\u0026quot;)来解析。但是如何解析/welcome?firstname=Jane\u0026amp;lastname=Doe这种URL参数呢？使用c.Query():\npackage main import ( \u0026#34;github.com/gin-gonic/gin\u0026#34; \u0026#34;net/http\u0026#34; ) func main() { r := gin.Default() // GET // Hit /welcome?firstName=Jane\u0026amp;lastName=Doe r.GET(\u0026#34;/welcome\u0026#34;, func(c *gin.Context) { firstName := c.DefaultQuery(\u0026#34;firstName\u0026#34;, \u0026#34;Guest\u0026#34;) lastName := c.Query(\u0026#34;lastName\u0026#34;) // 是 c.Request.URL.Query().Get(\u0026#34;lastName\u0026#34;) 的简写 c.String(http.StatusOK, \u0026#34;Hello %s %s\u0026#34;, firstName, lastName) }) // POST // Hit POST /form_post // Content-Type: application/x-www-form-urlencoded // message=hello\u0026amp;nick=jon r.POST(\u0026#34;/form_post\u0026#34;, func(c *gin.Context) { message := c.PostForm(\u0026#34;message\u0026#34;) nick := c.DefaultPostForm(\u0026#34;nick\u0026#34;, \u0026#34;anonymous\u0026#34;) // 此方法可以设置默认值 c.JSON(200, gin.H{ \u0026#34;status\u0026#34;: \u0026#34;posted\u0026#34;, \u0026#34;message\u0026#34;: message, \u0026#34;nick\u0026#34;: nick, }) }) r.Run() } 测试:\n$ curl http://localhost:8080/welcome Hello Guest $ curl \u0026#39;http://localhost:8080/welcome?firstName=h\u0026amp;lastName=xd\u0026#39; Hello h xd $ curl -X POST -d \u0026#39;message=hello\u0026amp;nick=jon\u0026#39; -H \u0026#34;Content-Type: application/x-www-form-urlencoded\u0026#34; http://localhost:8080/form_post {\u0026#34;message\u0026#34;:\u0026#34;hello\u0026#34;,\u0026#34;nick\u0026#34;:\u0026#34;jon\u0026#34;,\u0026#34;status\u0026#34;:\u0026#34;posted\u0026#34;} GET和POST混合：\npackage main import ( \u0026#34;github.com/gin-gonic/gin\u0026#34; \u0026#34;net/http\u0026#34; ) func main() { r := gin.Default() // POST // Hit /post?id=1234\u0026amp;page=1 // Content-Type: application/x-www-form-urlencoded // name=hxd\u0026amp;message=hello r.POST(\u0026#34;/post\u0026#34;, func(c *gin.Context) { id := c.Query(\u0026#34;id\u0026#34;) page := c.DefaultQuery(\u0026#34;page\u0026#34;, \u0026#34;0\u0026#34;) name := c.PostForm(\u0026#34;name\u0026#34;) message := c.PostForm(\u0026#34;message\u0026#34;) c.String(200, \u0026#34;id: %s; page: %s; name: %s; message: %s\u0026#34;, id, page, name, message) }) r.Run() } 测试：\n$ curl -X POST -d \u0026#39;message=hello\u0026amp;name=jon\u0026#39; -H \u0026#34;Content-Type: application/x-www-form-urlencoded\u0026#34; \u0026#39;http://localhost:8080/post?id=1\u0026amp;page=2\u0026#39; id: 1; page: 2; name: jon; message: hello 输出响应 # Gin有多种相应HTTP请求的格式：\nc.JSON(code int, obj interface{}) c.JSONP(code int, obj interface{}) c.XML(code int, obj interface{}) c.YAML(code int, obj interface{}) c.String(code int, format string, values ...interface{}) c.Redirect(code int, location string) c.Data(code int, contentType string, data []byte) c.File(filepath string) ..etc. 比如：\n// gin.H 是 map[string]interface{} 的一种快捷方式 r.GET(\u0026#34;/someJSON\u0026#34;, func(c *gin.Context) { c.JSON(http.StatusOK, gin.H{\u0026#34;message\u0026#34;: \u0026#34;hey\u0026#34;, \u0026#34;status\u0026#34;: http.StatusOK}) }) 参考链接：\nGin中文文档\n7天用Go从零实现Web框架Gee教程\n中文文档\nGin框架使用详解\n"},{"id":21,"href":"/posts/2/","title":"Docker镜像优化","section":"Posts","content":"注：本文章基于docker-ce版本：Client 19.03.8，Server 19.03.8\nDockerfile简介 # Dockerfile主要有这几个指令，每个指令都会添加新的层，但是镜像大小不一定增长：\n指令 用途 用法 简单示例 FROM 指定基础镜像 FROM \u0026lt;image\u0026gt; 或 FROM \u0026lt;image\u0026gt;:\u0026lt;tag\u0026gt; FROM ubuntu:16.04 MAINTAINER 维护者信息 MAINTAINER \u0026lt;name\u0026gt; MAINTAINER HuangXianDong ADD 复制指定的文件到容器中包括tar，URL等 ADD \u0026lt;src\u0026gt; \u0026lt;dest\u0026gt; ADD conf/jail.local /etc/fail2ban/jail.local COPY 复制host上下文环境的文件或者前一阶段镜像的文件到容器 COPY \u0026lt;src\u0026gt; \u0026lt;dest\u0026gt;有两个标志 –from= –chown= COPY /usr/local/app /usr/local/app USER 指定用户 USER \u0026lt;username\u0026gt; USER root WORKDIR 指定工作目录 WORKDIR /path/to/workdir WORKDIR /root RUN 终端执行sh或者可执行程序 RUN \u0026lt;command\u0026gt; 或 RUN [“executable”, “param1”, “param2”] RUN apt-get update ENV 指定一个环境变量 ENV \u0026lt;key\u0026gt; \u0026lt;value\u0026gt;或ENV \u0026lt;key\u0026gt;=\u0026lt;value\u0026gt; ENV TZ=Asia/Shanghai ONBUILD 配置当所创建的镜像作为其它新创建镜像的基础镜像时，所执行的操作指令 ONBUILD [INSTRUCTION] ONBUILD ADD . /app/src VOLUME 创建一个挂载点 VOLUME [“/data”] VOLUME [“/data”] EXPOSE 打算暴露的端口号 EXPOSE \u0026lt;port\u0026gt; [\u0026lt;port\u0026gt;…] EXPOSE 5060/tcp 5060/udp ENTRYPOINT 容器入口点，不可被docker run覆盖 ENTRYPOINT [“executable”, “param1”, “param2”]或ENTRYPOINT command param1 param2 ENTRYPOINT entrypoint.sh CMD 指定启动容器时执行的命令，可以被docker run覆盖 CMD [“executable”,”param1″,”param2″]或CMD command param1 param2或CMD [“param1″,”param2”]提供给 ENTRYPOINT 的默认参数 CMD python /app/app.py 常用镜像缩小方法 # 在哪层引入，就在哪层清理 # 众所周知，Dockerfile每个指令都会叠加新的一层文件系统，由于docker镜像这种叠加的文件系统，也就是说在构建镜像时，前面一层的文件对于本层来说是只读的，从而不能够在本层文件系统去清理上一层引入的文件，虽然可以删除掉对应的文件或文件夹，但是镜像体积并没有减少：\nWORKDIR /usr/src RUN git clone http://xxx.git \\ \u0026amp;\u0026amp; cd ./xxx \\ \u0026amp;\u0026amp; ./bootstrap.sh \\ \u0026amp;\u0026amp; ./configure --enable-core-pgsql-support \\ \u0026amp;\u0026amp; make \\ \u0026amp;\u0026amp; make install #这一层引入文件 RUN rm -rf /usr/src/* #在这一层清理，达不到体积减小的目的，反而增加层数 应该这样：\nWORKDIR /usr/src RUN git clone http://xxx.git \\ \u0026amp;\u0026amp; cd ./xxx \\ \u0026amp;\u0026amp; ./bootstrap.sh \\ \u0026amp;\u0026amp; ./configure --enable-core-pgsql-support \\ \u0026amp;\u0026amp; make \\ \u0026amp;\u0026amp; make install \\ \u0026amp;\u0026amp; rm -rf /usr/src/* # 在哪层引入，就在哪层清理 此外，如果在ADD，COPY指令中添加了多余的文件，此后在其他层删除掉改文件或文件夹虽然文件删除了，但是镜像大小是不变或增加的：\nFROM busybox ADD . /root # busytest0 157MB RUN rm -rf /root # busytest1 157MB 另外，在使用包管理工具的时候经常要安装各种工具，安装时应该将所有要安装的工具写在一起并且加以清理，甚至可以卸载掉：\nRUN apt-get update \u0026amp;\u0026amp; apt-get install -y autoconf automake bison \\ build-essential fail2ban gawk git-core groff groff-base \\ \u0026amp;\u0026amp; apt-get autoclean \\ \u0026amp;\u0026amp; rm -rf /var/lib/apt/lists/* 合并RUN中的命令 # 多个RUN指令会增加很多层镜像，应该尽量把能合在一起写的shell写在同一个RUN指令里：\nRUN apt-get update \\ \u0026amp;\u0026amp; ln -snf /usr/share/zoneinfo/$TZ /etc/localtime \u0026amp;\u0026amp; echo $TZ \u0026gt; /etc/timezone \\ \u0026amp;\u0026amp; apt-get install tzdata \\ \u0026amp;\u0026amp; apt-get clean \\ \u0026amp;\u0026amp; apt-get autoclean \\ \u0026amp;\u0026amp; rm -rf /var/lib/apt/lists/* /tmp/* /var/tmp/* 而不是：\nRUN apt-get update RUN ln -snf /usr/share/zoneinfo/$TZ /etc/localtime RUN echo $TZ \u0026gt; /etc/timezone RUN apt-get install tzdata RUN apt-get clean RUN apt-get autoclean 分阶段构建 # 有些应用，如go构建的可执行文件，可以不需要依赖构建他的系统而运行的程序，就适合进行分步构建，也就是一个阶段编译，一个阶段用于执行程序。分步构建很大程度上能减少镜像的体积。\nFROM golang COPY hello.go . RUN go build hello.go FROM scratch COPY --from=0 /go/hello . CMD [\u0026#34;./hello\u0026#34;] 分阶段构建有时候对一些C程序和大型的Go程序来说，凡是有依赖动态运行库的程序进行分阶段构建就很头疼，因为复制过来的可执行文件可能需要某个动态库的支持。\n与之相对的解决办法是：静态编译或者复制动态库。\n静态编译是一个不错的方法，但是如果某种原因不适合静态编译，比如分阶段编译等等，这就需要拷贝库文件了。\n就像某些程序，编译出来的可执行文件只有十几kb，其他的都是以动态库的形势存在，那么怎么寻找应用对应的依赖库呢？\n使用ldd命令，该命令可以查询对应的库文件：\n# ldd /usr/local/freeswitch/bin/freeswitch linux-vdso.so.1 =\u0026gt; (0x00007ffd0bb61000) libfreeswitch.so.1 =\u0026gt; /usr/local/freeswitch/lib/libfreeswitch.so.1 (0x00007f0fa2a1d000) libpthread.so.0 =\u0026gt; /lib/x86_64-linux-gnu/libpthread.so.0 (0x00007f0fa27f3000) libc.so.6 =\u0026gt; /lib/x86_64-linux-gnu/libc.so.6 (0x00007f0fa2429000) libuuid.so.1 =\u0026gt; /lib/x86_64-linux-gnu/libuuid.so.1 (0x00007f0fa2223000) ... 将这些对应的库文件复制到镜像之后需要执行ldconfig命令，任何改动库文件的操作都应该执行该命令。\n复制动态库文件可能会导致后续维护变得困难，并且可能存在未知的隐患。\n制作基础镜像包 # 构建镜像时有些主要是下载依赖包导致的时间变长，可以考虑专门做一个环境编译的基础镜像，后续编译就可以基于该镜像编译，大大减少构建时间。\n一些容易增大镜像体积的操作 # 慎用chown命令：chown命令在有些文件系统在实现多层联合文件系统的原理不同，可能会导致无端增加文件夹的体积。\n原因是在docker实现的某些文件系统如overlayfs2，chown 只更改 metadata 数据, 而 metadata 是作用在 inode 节点上的, 一个硬链接文件的属性被修改, 同步的, 所有指向这个 inode节点的文件的属性都会变化，而overlayfs2每层都是独立的，即使文件属性的变化，也会导致整个文件被拷贝, 所以在 overlayfs2 下, 会产生多余的空间浪费。\n常用的工具 # docker history命令 # docker自带了简单的镜像分析命令，直接执行docker history \u0026lt;IMAGE ID\u0026gt; 或者 docker history REPOSITORY:TAG就行：\n[root@RqInternTest3 freeswitch-container]# docker history dda43e8b9e21 IMAGE CREATED CREATED BY SIZE COMMENT dda43e8b9e21 9 hours ago /bin/sh -c #(nop) CMD [\u0026#34;/usr/local/freeswit… 0B 76f11898568d 9 hours ago /bin/sh -c #(nop) EXPOSE 64535-65535/udp 0B 124e52a5fdb8 9 hours ago /bin/sh -c #(nop) EXPOSE 8021/tcp 0B d05fa7854fa3 9 hours ago /bin/sh -c #(nop) EXPOSE 5066/tcp 7443/tcp 0B fae9a2737d1b 9 hours ago /bin/sh -c #(nop) EXPOSE 5060/tcp 5060/udp … 0B d817769a9e83 9 hours ago /bin/sh -c ldconfig 81.5kB e4347f4a3f7f 9 hours ago /bin/sh -c #(nop) ADD file:305fb1821e6c9f4f7… 19.5kB 7fa9aac435b0 9 hours ago /bin/sh -c #(nop) ADD file:ef5aa87255557ffc9… 340B 2872fc32f715 9 hours ago /bin/sh -c #(nop) ADD file:aa24cd419ee5ea6ca… 249B 681ea1a83b9b 9 hours ago /bin/sh -c chmod +x /etc/init.d/freeswitch … 7.28kB b3af584e7595 9 hours ago /bin/sh -c #(nop) ADD file:e450d50f8d60a1861… 5.76kB 8c2e2a5f2de4 9 hours ago /bin/sh -c #(nop) COPY dir:8ecfbdecc9f674459… 417MB 9a2938106462 9 hours ago /bin/sh -c #(nop) COPY dir:1ddadc455338c149f… 112MB d03606f65563 9 hours ago /bin/sh -c #(nop) COPY dir:cd305b7f15031b530… 20.4MB 3e21911eea87 9 hours ago /bin/sh -c #(nop) COPY --chown=freeswitch:da… 410MB 6ce315566979 9 hours ago /bin/sh -c useradd -r -g daemon freeswitch 329kB b7c170867677 9 hours ago /bin/sh -c apt-get update \u0026amp;\u0026amp; ln -snf /us… 2.76MB 9a800e72f239 10 hours ago /bin/sh -c #(nop) ENV TZ=Asia/Shanghai 0B 77be327e4b63 4 weeks ago /bin/sh -c #(nop) CMD [\u0026#34;/bin/bash\u0026#34;] 0B \u0026lt;missing\u0026gt; 4 weeks ago /bin/sh -c mkdir -p /run/systemd \u0026amp;\u0026amp; echo \u0026#39;do… 7B \u0026lt;missing\u0026gt; 4 weeks ago /bin/sh -c set -xe \u0026amp;\u0026amp; echo \u0026#39;#!/bin/sh\u0026#39; \u0026gt; /… 745B \u0026lt;missing\u0026gt; 4 weeks ago /bin/sh -c rm -rf /var/lib/apt/lists/* 0B \u0026lt;missing\u0026gt; 4 weeks ago /bin/sh -c #(nop) ADD file:1f70668251e2e58ce… 124MB dive分析镜像工具 # 可以看出每一层所添加的大小，并针对大的层进行优化。\n分析镜像还有一个很有用的工具dive：\n下载安装dive：\n# wget https://github.com/wagoodman/dive/releases/download/v0.9.2/dive_0.9.2_linux_amd64.tar.gz # tar -zvxf dive_0.9.2_linux_amd64.tar.gz # cp dive /usr/bin 使用：dive \u0026lt;IMAGE ID\u0026gt; 或者 dive REPOSITORY:TAG\n┃ ● Layers ┣━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ │ Current Layer Contents ├────────────────────────────────── Cmp Size Command Permission UID:GID Size Filetree 5.2 MB FROM d970df9dd8bab4b drwxr-xr-x 0:0 1.0 MB ├── bin -rwxr-xr-x 0:0 1.0 MB │ ├── [ │ Layer Details ├─────────────────────────────────────────── -rwxr-xr-x 0:0 0 B │ ├── [[ → bin/[ -rwxr-xr-x 0:0 0 B │ ├── acpid → bin/[ Tags: (unavailable) -rwxr-xr-x 0:0 0 B │ ├── add-shell → bin/[ Id: d970df9dd8bab4b7a604d73763aee9e732d107cf3b02000ca193 -rwxr-xr-x 0:0 0 B │ ├── addgroup → bin/[ 712fe48a460f -rwxr-xr-x 0:0 0 B │ ├── adduser → bin/[ Digest: sha256:8a9aa5c55905476e9412fcf0e18942123b239333aafc4 -rwxr-xr-x 0:0 0 B │ ├── adjtimex → bin/[ d7b3656faf67b980b41 -rwxr-xr-x 0:0 0 B │ ├── ar → bin/[ Command: -rwxr-xr-x 0:0 0 B │ ├── arch → bin/[ #(nop) ADD file:d5fc1686f667af49c2cb01970701b62eeb9c818d2d4e -rwxr-xr-x 0:0 0 B │ ├── arp → bin/[ 8f967993dab1de737f28 in / -rwxr-xr-x 0:0 0 B │ ├── arping → bin/[ -rwxr-xr-x 0:0 0 B │ ├── ash → bin/[ │ Image Details ├─────────────────────────────────────────── -rwxr-xr-x 0:0 0 B │ ├── awk → bin/[ -rwxr-xr-x 0:0 0 B │ ├── base64 → bin/[ -rwxr-xr-x 0:0 0 B │ ├── basename → bin/[ Total Image size: 5.2 MB -rwxr-xr-x 0:0 0 B │ ├── bc → bin/[ Potential wasted space: 0 B -rwxr-xr-x 0:0 0 B │ ├── beep → bin/[ Image efficiency score: 100 % -rwxr-xr-x 0:0 0 B │ ├── blkdiscard → bin/ -rwxr-xr-x 0:0 0 B │ ├── blkid → bin/[ Count Total Space Path -rwxr-xr-x 0:0 0 B │ ├── blockdev → bin/[ -rwxr-xr-x 0:0 0 B │ ├── bootchartd → bin/ -rwxr-xr-x 0:0 0 B │ ├── brctl → bin/[ -rwxr-xr-x 0:0 0 B │ ├── bunzip2 → bin/[ -rwxr-xr-x 0:0 0 B │ ├── busybox → bin/[ -rwxr-xr-x 0:0 0 B │ ├── bzcat → bin/[ -rwxr-xr-x 0:0 0 B │ ├── bzip2 → bin/[ -rwxr-xr-x 0:0 0 B │ ├── cal → bin/[ 可以非常清晰的看到每一层添加的镜像大小以及文件的变化，通过右边的Content可以观察到文件夹的变化。\n各种基础镜像的构建 # 各类基础镜像分析 # 常用的基础镜像CentOS，Debian，Fedora，Ubuntu，Alpine镜像：\n类别 版本 镜像大小(MB) 描述 包管理 CentOS latest 69.84 适用于正式的生产环境镜像制作，但是构建出来的镜像大小会很大，可以来考虑分步构建 yum，rpm - centos8 69.84 - - - centos7 72.15 - - - centos6 66.83 - - Debian buster-slim 26.46 当前稳定版本的体积更小版本（slim） apt-get, dpkg - stretch 43.69 旧的稳定版 - - jessie 52.08 测试版本 - - stable 48.78 稳定版本 - - sid 50.54 不稳定版本 - - wheezy 38.66 Debian 7,被淘汰的稳定版 - Fedora 33 67.21 稳定版本 dpkg/apt，pacman - rawhide 67.21 永远不会被冻结, 也永远不会被正式发布. 对稳定性没有任何保证. 主要用于最新代码的初步测试 - Ubuntu latest 25.9 适用于正式的生产环境镜像制作，但是构建出来的镜像大小会很大，可以来考虑分步构建 apt-get - 18.04 25.9 - - - 16.04 42.13 - - Alpine latest 2.68 面向安全的、轻量级的Linux系统，基于musl libc和busybox，使用glibc库的大型c语言可能会遇到很多坑 apk, lbu busybox latest 1 包含了基本的linux命令 apk - glibc 5 GNU C library版本 - scratch latest 0 空白镜像，sh工具也没有 无 也可以使用编程语言对应的基础镜像，适合分步构建完成之后在其上运行或者在对应的基础镜像中编译。\n各个基础镜像换源 # CentOS yum源\nmv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backup wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-6.repo Ubuntu apt源 清华源：\nsed -i \u0026#39;s http://.*.ubuntu.com http://mirrors.tuna.tsinghua.edu.cn g\u0026#39; /etc/apt/sources.list 阿里云源：\nsed -i \u0026#39;s http://.*.ubuntu.com http://mirrors.aliyun.com g\u0026#39; /etc/apt/sources.list Debian apt源\nsed -i \u0026#39;s http://.*.debian.org http://mirrors.aliyun.com g\u0026#39; /etc/apt/sources.list Alphine apk源\n阿里源：\nsed -i \u0026#39;s/dl-cdn.alpinelinux.org/mirrors.aliyun.com/g\u0026#39; /etc/apk/repositories 科大源：\nsed -i \u0026#39;s/dl-cdn.alpinelinux.org/mirrors.ustc.edu.cn/g\u0026#39; /etc/apk/repositories 各个基础镜像设置时区方法 # Ubuntu\nFROM ubuntu:16.04 ENV TZ=Asia/Shanghai RUN apt-get update \\ \u0026amp;\u0026amp; ln -snf /usr/share/zoneinfo/$TZ /etc/localtime \u0026amp;\u0026amp; echo $TZ \u0026gt; /etc/timezone \\ \u0026amp;\u0026amp; apt-get install tzdata \\ \u0026amp;\u0026amp; apt-get clean \\ \u0026amp;\u0026amp; apt-get autoclean \\ \u0026amp;\u0026amp; rm -rf /var/lib/apt/lists/* /tmp/* /var/tmp/* CentOS\nENV TimeZone=Asia/Shanghai RUN ln -snf /usr/share/zoneinfo/$TimeZone /etc/localtime \u0026amp;\u0026amp; echo $TimeZone \u0026gt; /etc/timezone Debian\nENV TZ=Asia/Shanghai RUN ln -snf /usr/share/zoneinfo/$TZ /etc/localtime \u0026amp;\u0026amp; echo $TZ \u0026gt; /etc/timezone Alphine\nRUN apk add tzdata \u0026amp;\u0026amp; cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime \\ \u0026amp;\u0026amp; echo \u0026#34;Asia/Shanghai\u0026#34; \u0026gt; /etc/timezone \\ \u0026amp;\u0026amp; apk del tzdata 把日志文件输出到标准输出流 # 有时候我们写的程序不是以标准输出到控制台的方式来打印日志，而是存在某个日志文件，这就造成容器跑起来之后docker logs命令查看不到日志，这是因为docker容器只接管标准输出流和标准错误流，因此还需要重定向到stdout和stderr：\nRUN ln -sf /dev/stdout /var/log/nginx/access.log \\ \u0026amp;\u0026amp; ln -sf /dev/stderr /var/log/nginx/error.log "},{"id":22,"href":"/posts/1/","title":"Golang-interface的底层原理浅析","section":"Posts","content":" 前言 # Go语言在语法上相对C/C++来说，是比较简单的，基本语法多刷刷题目，然后工程的架构、目录规则等多看看其他开源项目，就应该能比较熟悉了。Go语言比较核心的设计 包括interface、内存模型、defer机制、goroutine实现与调度、cgo、数组与切片、Go编译器和连接器、GC实现这几大块。\n注：所有源码基于 go version go1.13.5 windows/amd64\n本篇笔记目的是了解interface的特性，并知道如何用好它。\nInterface定义 # 是一种类型 可以定义0个或多个方法（一组行为） 可以嵌入其他接口（目标类型方法集中必须拥有包含嵌入接口方法在内的全部方法才算实现了该接口） 如：\ntype Notifier interface { notify() } 这就定义了一个名为Notifier的interface，实现这个interface很简单，实现notify方法即可：\ntype User struct { name　string } func (u *User) notify() { fmt.Printf(\u0026#34;Notify user name %s\\n\u0026#34;, u.name) } 其他结构体也可以实现这个interface：\ntype Admin struct { name　string } func (a *Admin) notify() { fmt.Printf(\u0026#34;Sending admin name %s\\n\u0026#34;, a.name) } 这种实现是DuckType：类型不需要显式声明它实现了某个接口：接口被隐式地实现。多个类型可以实现同一个接。\n在调用notify的地方实现如下方法，即可实现多态性，即面向接口编程：\nfunc sendNotify(n Notifier) { n.notify() } 函数sendNotify接受一个实现了Notifier接口的值作为参数。 既然任意一个实体类型都能实现该接口，那么这个函数可以针对任意实体类型的值来执行notify方法，调用notify时， 会根据对象的实际定义来实现不同的行为，从而实现多态行为。\n这里需要注意的地方是，Notifier接口只有一个方法，并且*Admin 和 *User类型都实现了notify方法，这就说明*Admin和*User类型实现了Notifier接口。如果Notifier有多个方法时，情况可能就会不一样：\ntype Person interface { job() growUp() } type Student struct { age int } func (p Student) job() { // Student类型实现了job方法 fmt.Println(\u0026#34;I am a student.\u0026#34;) return } func (p *Student) growUp() { // *Student类型实现了growUp方法（注意这里的区别） p.age += 1 return } type Programmer struct { age int } func (p Programmer) job() { // Programmer类型实现了job方法 fmt.Println(\u0026#34;I am a programmer.\u0026#34;) return } func (p Programmer) growUp() { // Programmer类型实现了growUp方法 p.age += 10 return } *Student和Programmer类型实现了Person接口，但是Student类型却没用，因为Student类型没有实现Person接口，执行以下程序时就会报错：\nvar s Person = Student{9} // 报错 s.job() s.growUp() // 改成如下会成功 var s Person = \u0026amp;Student{9} s.job() s.growUp() *Student类型为什么会实现了Person接口呢？是因为Student类型实现了job方法，所以让 *Student类型自动拥有了job方法。也就是：实现了接收者是值类型的方法，相当于自动实现了接收者是指针类型的方法；而实现了接收者是指针类型的方法，不会自动生成对应接收者是值类型的方法。\n空interface # 在Go中，有种空的interface类型，即没有任何方法的interface：interface{}。\ntype Any interface {} 对空接口类型来说，我们可以将任意一种类型的值赋值给空接口类型（就好比java的最高级父类）：\nvar any interface {} any = true any = 14.5 any = \u0026#34;hello\u0026#34; ... 类型断言 # 在上面的多态函数的实现中，我们如何去判断传进来的n是User还是Admin呢？使用类型断言可以解决：\nfunc sendNotify(n Notifier) { n.notify() switch v:= n.(type) { case *User: //is User role case *Admin: //is Admin role default: fmt.Println(\u0026#34;don\u0026#39;t know the type\u0026#34;) } } Interface的实现 # 任何interface类型，在内存中都是2个字长，32位机器上是8Byte，64位机器上是16Byte。\n空interface的源码(src\\runtime\\runtime2.go line 197左右)：\ntype eface struct { _type *_type // 类型指针 data unsafe.Pointer // 数据区域指针 } 里面就两个指针，_type类型表示了类型的基本信息，类型大小，对齐信息，类型编号等，源码如下(src\\runtime\\type.go line 28左右)：\ntype _type struct { size uintptr // 类型大小 ptrdata uintptr // size of memory prefix holding all pointers hash uint32 // 哈希值 tflag tflag // 类型的flag，与反射相关 align uint8 // 内存对齐相关 fieldalign uint8 // 内存对齐相关 kind uint8 // 类型的编号 alg *typeAlg // 类型的编号相关 // gcdata stores the GC type data for the garbage collector. // If the KindGCProg bit is set in kind, gcdata is a GC program. // Otherwise it is a ptrmask bitmap. See mbitmap.go for details. gcdata *byte // 以下就是gc相关 str nameOff ptrToThis typeOff } Go语言各种数据类型都是在 _type 字段的基础上，增加一些额外的字段来进行管理的。\n非空interface的实现(src\\runtime\\runtime2.go line 192左右):\ntype iface struct { tab *itab data unsafe.Pointer } type itab struct { inter *interfacetype _type *_type hash uint32 // copy of _type.hash. Used for type switches. _ [4]byte fun [1]uintptr // variable sized. fun[0]==0 means _type does not implement inter. } 第一个itab中存放了类型信息，还有一个fun表示方法表。fun 数组的大小为 1，这里存储的是第一个方法的函数指针， 如果有更多的方法，在它之后的内存空间里继续存储。 从汇编角度来看，通过增加地址就能获取到这些函数指针，没什么影响。顺便提一句，这些方法是按照函数名称的字典序进行排列的。\ninterfacetype类型，src\\runtime\\type.go line 390左右：\ntype interfacetype struct { typ _type // 包装了 _type 类型 pkgpath name // 接口所定义的函数列表 mhdr []imethod // 记录定义了接口的包名 } Interface的构造过程 # 先来看看这个例子（方便观察加上了行号）：\n1 package main 2 3 import ( 4 \u0026#34;strconv\u0026#34; 5 \u0026#34;fmt\u0026#34; 6 ) 7 8 type Stringer interface { 9 String() string 10 } 11 12 type Binary uint64 13 14 func (i Binary) String() string { 15 return strconv.FormatUint(i.Get(), 2) 16 } 17 18 func (i Binary) Get() uint64 { 19 return uint64(i) 20 } 21 22 func main() { 23 b := Binary(200) 24 s := Stringer(b) 25 fmt.Println(s.String()) // 输出11001000 26 } 执行命令： go tool compile -S gotest.go \u0026gt; main.txt\n其中一段main函数的汇编代码如下：\n\u0026#34;\u0026#34;.main STEXT size=210 args=0x0 locals=0x58 0x0000 00000 (gotest.go:22)\tTEXT\t\u0026#34;\u0026#34;.main(SB), ABIInternal, $88-0 0x0000 00000 (gotest.go:22)\tMOVQ\tTLS, CX 0x0009 00009 (gotest.go:22)\tMOVQ\t(CX)(TLS*2), CX 0x0010 00016 (gotest.go:22)\tCMPQ\tSP, 16(CX) 0x0014 00020 (gotest.go:22)\tJLS\t200 0x001a 00026 (gotest.go:22)\tSUBQ\t$88, SP 0x001e 00030 (gotest.go:22)\tMOVQ\tBP, 80(SP) 0x0023 00035 (gotest.go:22)\tLEAQ\t80(SP), BP 0x0028 00040 (gotest.go:22)\tFUNCDATA\t$0, gclocals·69c1753bd5f81501d95132d08af04464(SB) 0x0028 00040 (gotest.go:22)\tFUNCDATA\t$1, gclocals·568470801006e5c0dc3947ea998fe279(SB) 0x0028 00040 (gotest.go:22)\tFUNCDATA\t$2, gclocals·bfec7e55b3f043d1941c093912808913(SB) 0x0028 00040 (gotest.go:22)\tFUNCDATA\t$3, \u0026#34;\u0026#34;.main.stkobj(SB) 0x0028 00040 (gotest.go:24)\tPCDATA\t$0, $0 0x0028 00040 (gotest.go:24)\tPCDATA\t$1, $0 0x0028 00040 (gotest.go:24)\tMOVQ\t$200, (SP) 0x0030 00048 (gotest.go:24)\tCALL\truntime.convT64(SB) // 首先将200转换为int64类型，这里会构造出一个inteface 0x0035 00053 (gotest.go:25)\tPCDATA\t$0, $1 0x0035 00053 (gotest.go:25)\tLEAQ\tgo.itab.\u0026#34;\u0026#34;.Binary,\u0026#34;\u0026#34;.Stringer(SB), AX // 0x003c 00060 (gotest.go:25)\tPCDATA\t$0, $0 0x003c 00060 (gotest.go:25)\tTESTB\tAL, (AX) 0x003e 00062 (gotest.go:24)\tPCDATA\t$0, $1 0x003e 00062 (gotest.go:24)\tMOVQ\t8(SP), AX 0x0043 00067 (gotest.go:25)\tMOVQ\tgo.itab.\u0026#34;\u0026#34;.Binary,\u0026#34;\u0026#34;.Stringer+24(SB), CX // 将Stringer.String函数地址放进 CX 0x004a 00074 (gotest.go:25)\tPCDATA\t$0, $0 0x004a 00074 (gotest.go:25)\tMOVQ\tAX, (SP) 0x004e 00078 (gotest.go:25)\tCALL\tCX // 调用Stringer.String 0x0050 00080 (gotest.go:25)\tPCDATA\t$0, $1 0x0050 00080 (gotest.go:25)\tMOVQ\t8(SP), AX 0x0055 00085 (gotest.go:25)\tMOVQ\t16(SP), CX 0x005a 00090 (gotest.go:25)\tPCDATA\t$0, $0 0x005a 00090 (gotest.go:25)\tMOVQ\tAX, (SP) 0x005e 00094 (gotest.go:25)\tMOVQ\tCX, 8(SP) 0x0063 00099 (gotest.go:25)\tCALL\truntime.convTstring(SB) // 函数strconv.FormatUint内部的转换 0x0068 00104 (gotest.go:25)\tPCDATA\t$0, $1 0x0068 00104 (gotest.go:25)\tMOVQ\t16(SP), AX 0x006d 00109 (gotest.go:25)\tPCDATA\t$1, $1 0x006d 00109 (gotest.go:25)\tXORPS\tX0, X0 0x0070 00112 (gotest.go:25)\tMOVUPS\tX0, \u0026#34;\u0026#34;..autotmp_16+64(SP) 0x0075 00117 (gotest.go:25)\tPCDATA\t$0, $2 0x0075 00117 (gotest.go:25)\tLEAQ\ttype.string(SB), CX 0x007c 00124 (gotest.go:25)\tPCDATA\t$0, $1 0x007c 00124 (gotest.go:25)\tMOVQ\tCX, \u0026#34;\u0026#34;..autotmp_16+64(SP) 0x0081 00129 (gotest.go:25)\tPCDATA\t$0, $0 0x0081 00129 (gotest.go:25)\tMOVQ\tAX, \u0026#34;\u0026#34;..autotmp_16+72(SP) 查看go.itab.””.Binary,””.Stringer(SB)这个地方：\ngo.itab.\u0026#34;\u0026#34;.Binary,\u0026#34;\u0026#34;.Stringer SRODATA dupok size=32 0x0000 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................ 0x0010 3b 3d 72 44 00 00 00 00 00 00 00 00 00 00 00 00 ;=rD............ rel 0+8 t=1 type.\u0026#34;\u0026#34;.Stringer+0 rel 8+8 t=1 type.\u0026#34;\u0026#34;.Binary+0 rel 24+8 t=1 \u0026#34;\u0026#34;.(*Binary).String+0 size大小为32Byte：\ntype itab struct { inter *interfacetype // 8 Byte (64位机子，指针) _type *_type // 8 Byte (64位机子，指针) hash uint32 // 4 Byte _ [4]byte // 4 Byte fun [1]uintptr // 8 Byte } 每个字段相加，就是itab结构体的大小32字节，那串数字是itab序列化后的内容，可以对应找出hash值，在判断两个类型是否相同的时候会用这个值比较。\n对于Binary，作为一个64位整数，可以这么表示:\nb := Binary(200) +==========+ | 200 | +==========+ int64 对于s := Stringer(b)，可以如下表示：\ns := Stringer(b) +========+ itab | tab | ----\u0026gt; +=======+ +========+ | inter | | data |---\u0026gt;200 +=======+ +========+ | type | ---\u0026gt; Stringer.Binary +=======+ | hash | +=======+ | fun | ---\u0026gt; *Binary.String +=======+ 那么对于s来说 itab中的inter表示的是Stringer这个接口，type表示的是Binary这个动态类型，fun函数表中存放的就是Binary中实现了String而接口的方法地址。\n对于接口的type-switch，返回的就是静态类型 对于反射里面的TypeOf，返回的是动态类型，也就是数据真实的类型\n对于调用s.String()方法，其实就是 s.itab-\u0026gt;fun[0]。\n这里就引出一个需要注意的地方：，var a interface{} 这个地方用if a == nil是可以判断的， 但是如果使用其他类型的nil指针赋给interface：\nvar b *Binary = nil var a interface{} = b 这时候if a == nil就不会成立的，即使b为nil，这是因为这个时候a的结构如下：\na +========+ itab | tab | -------\u0026gt; +========+ +========+ |inter | | data | ---\u0026gt; nil +========+ +========+ | type | +========+ | ... | 所以这个时候你把一个其他类型的nil指针赋值给interface{}的时候，interface并不是空，而是对interface进行了初始化，只不过data是nil而已。所有如果一个参数的返回值是interface{}或者其他有方法的interface，比如error等，所以一旦函数返回的是某种interface的时候，就需要注意，不要直接返回某种类型的空指针，需要转换成直接的nil进行赋值。如：\nfunc doSomething() (interface{}) { var a *Binary = nil //do something return a // 这边应该判断a是nil然后直接返回nil } 总结 # 本片笔记主要记录一些interface的原理，若有什么不对的地方欢迎指正。 iface与eface的区别以及convT2I、convT2E函数的源码也没深入去了解，希望以后有时间可以看一看。\n参考：\n深度解密Go语言之关于 interface 的10个问题\n深度剖析interface "},{"id":23,"href":"/posts/0/","title":"部落格修改记录","section":"Posts","content":" TODO List # 部落格-侧边栏 下拉固定 已完成👌 2020.08.22 📅 🎉 大海 增加搜索功能 修改后端读取Markdown格式 已完成👌 2020.08.16 📅 🎉 修复前端点击回退时Panic的bug 已完成👌 2020.08.15📅 😁🎉 添加文章TOC功能 已完成 2020.09.20📅 使用GithubFlows实现CICD 已完成 2020.10.02📅 🎉 使用对象存储，实现媒体内容分离，提升网站加载速度 🚮🚮废弃，由于文章目前很少采用图片的形式，后续假如有需求如“添加照片墙”或添加个性页面，类Tumblr等再重启该需求。 深入了解Go内存模块，输出博客 深入了解Goroutine，输出博客 了解常用的Go内置包，总结输出博客 深入了解Go的context，并区分channel的使用场景，输出博客 深入了解锁，并发等，输出博客 深入了解golang runtime机制 深入了解部分K8s组件源码，了解informer机制，watch sync设计哲学，输出博客 备考CKA，总结输出博客 计划5月22号前考试完成 已获得CKA证书🎉🎉 2021.04.09📅 备考软考高级，总结输出博客 暂时放弃🚮 复习网络知识，输出博客 保持刷题，有必要输出题解以及形成类似于答题模板的代码片段，记录博客 💪💪持续进行。。。 文章TOC功能优化，类似掘金平台一样的效果 已完成👌 2021.04.09📅🎉 Kube Source Code Plan （docker和k8s源代码阅读计划） 文章数据持久化，例如文章阅读量、点赞量、有用统计等等，初步方案是gorm+sqlite3实现 eBPF相关知识的研究 。。。。 Change List # 2020.07.20 # 框架形成 发布第一篇Blog 2020.07.23 # 修改了一些前端样式 增加博文 2020.08.07 # 添加SSL证书，启用https 部署方式改成dockers-compose 2020.08.08 # 启用hindung.cn域名 修改前端样式 2020.08.15 # 修改前端退回Panic 2020.08.16 # 使用viper包读取markdown自定义配置 2020.08.19 # 修改代码显示的格式，嘻嘻更好看了呢😄 2020.08.22 # 左侧标签栏下拉时固定 添加两篇博文 2020.09.20 # 文章TOC简单实现 添加若干篇博文 2020.10.02 # GithubFlows实现CICD功能 "}]