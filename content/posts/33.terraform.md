---
title: Terraform技术分享
date: 2025-03-15
tags:
  - terraform
---

## Terraform 介绍
Terraform是一个IT基础架构**自动化编排工具**，可以用代码来管理维护IT资源。并对配置文件进行版本控制。代码描述了云资源拓扑的基础结构，例如虚拟机、存储账户和网络接口。

Terraform通过插件的机制，将各个云厂商的OpenAPI抽象为Provider，通过实现这个Provider插件来实现对新基础架构的支持；Terraform使用HCL语言来定义、预览和部署云基础结构。
用户只需要编写HCL，然后执行Plan预览更改，最后执行Apply部署即可。

![](https://hindung.oss-cn-beijing.aliyuncs.com/img/20250315123445.png)


### 简单的使用场景

某应用，为了增大吞吐率，需要对其做一个流量均衡处理，以扩大并发数、缩短延迟，所以需要使用一个负载均衡和云主机的组合，其架构如图所示，一个负载均衡，下面挂载两台云主机。

![](https://hindung.oss-cn-beijing.aliyuncs.com/img/20250315123640.png)

手动方式：
- 创建负载均衡器
- 创建虚拟机
- 加安全组
- 配置安全组规则，挂载LB
- B端口配置、会话保持、健康检查配置

使用 Terraform 的方式：
- 编写tf，引用LB、VM模板
- 执行apply部署

### 基本使用方法
基本命令：
- terraform plan（预览）
- terraform apply （创建/更新）
- terraform destroy （销毁）

使用 plan 命令可以展示当前环境的资源状态，以及将要执行的操作，如：

![](https://hindung.oss-cn-beijing.aliyuncs.com/img/20250315124005.png)

优点：
高度可扩展的自动化编排工具，通过Provider来支持新的基础架构。目前支持200多个基础设施提供商。
声明式编程，使用简单的模板语言（HCL）来定义、预览和部署云基础结构。
多云统一管理，开发者可同时管理不同云厂商的资源，也可快速方便地迁移到另外一个云厂商。

## 架构及原理
### HCL
HCL(HashiCorp Configuration Language)是HashiCorp公司构建的一种配置语言，用于编写Terraform的配置文件，也称为Terraform语言，它描述了如何管理给定的基础设施集合，具有以下特性：
- 基于人的可读性设计
- 声明式
- 兼容json格式输入，对机器友好
- 支持运算操作
- 数据结构丰富

语法开起来和NGINX的配置差不多。它以.tf文件名为结尾。
有良好的可读性，比如右边的配置，这个resource表示一个aws vpc资源，并给他设置一个地址块；

![](https://hindung.oss-cn-beijing.aliyuncs.com/img/20250315124504.png)

*Block代表某种对象的配置，如资源。Argument为一个名称分配一个值。Expresssion表示一个值，可以是字面意思，也可以是通过引用和组合其他值。*

数据结构丰富：原始类型分三类：`string、number、bool`。
Terraform支持三种集合：
`list(...)`：列表是一组值的连续集合，可以用下标访问内部元素，下标从0开始。
`map(...)`：字典类型(或者叫映射类型)，代表一组键唯一的键值对，键类型必须是string，值类型任意。
`set(...)`：集合类型，代表一组不重复的值。
`object(...)`：对象是指一组由具有名称和类型的属性所构成的符合类型，它的schema信息由`{ \=\, \=\,...}`的形式描述。

一个完整的例子：
![](https://hindung.oss-cn-beijing.aliyuncs.com/img/20250315124633.png)

### Terraform Flow

Terraform 核心的工作流包含三个步骤：
- Write：将基础设施写成HCL代码
- Plan：应用前预览更改
- Apply：应用到对应的基础设施

抽象概念：
- Config：声明期望的资源状态集合，即用户编写HCL文件
- State：当前的资源状态集合
- Diff：期望状态与当前状态的差异

![](https://hindung.oss-cn-beijing.aliyuncs.com/img/20250315124736.png)

*执行计划（Plan）本质上就是 Diff 格式化输出的结果，而执行编排（Apply）就是应用这个 Diff 的过程。*

当执行操作时，Terraform会解析校验HCL文件，并构建资源的依赖关系图，也就是构建一个有向无环图（DAG，Directed Acyclic Graph），并行地去创建和修改相互间没有依赖的那些资源。

![](https://hindung.oss-cn-beijing.aliyuncs.com/img/20250315124835.png)

Terraform通过遍历该有向无环图，直到所有资源都被成功编排，并执行清理操作。
在创建资源的过程中，存在局部并行的操作，因而可以减少了编排的时间。

依赖解析的关键：
- 显式声明：可以使用`depend_on`语句嵌入hcl语句中
- 隐式依赖：例如，表达式`aws_instance.example[1]`引用`resource “aws_instance” “example”`配置中的块创建的实例之一

在图构建的过程中，Terraform 需要对 DAG 进行若干次变换操作，进行图化简操作，例如做`Transitive Reduction`简化多余的边，减少编排成本。

![](https://hindung.oss-cn-beijing.aliyuncs.com/img/20250315124956.png)

总体编排流程：

当执行Terraform命令首次编排云上资源时：
- Terraform 首先唤醒核心进程，初始化 Backend（即状态管理组件）
- 解析用户编写的资源定义文件，同步最新的资源状态，并与当前的资源定义作对比
- 初次构建DAG时，资源尚未被初始化，所以资源状态为空，用户的资源实例都将作为 DAG中新增的节点被创建

在并行构建资源时：
- 并行遍历DAG
- 当遇到Provider节点时，Terraform核心进程唤醒Provider进程
- 将所有的编排动作依次发给Provider
- Provider调用OpenAPI 管理云上资源
- 返回的结果由Terraform核心进程写回状态存储

![](https://hindung.oss-cn-beijing.aliyuncs.com/img/20250315125139.png)

从宏观角度来看，Terraform分为：
- Terraform CLI：Terraform命令行工具
- Provider： Terraform的插件，用于管理云上资源
- Cloud APIs： 云上的OpenAPI

从进程的角度看，Terraform可以分为：
- Terraform Core进程，是整个程序的主进程，创建和销毁各个Provider进程
- Provider进程，即提供资源编排能力的进程，包括由云厂商实现的能力，和应用程序提供的能力
- Provisioner进程，即提供资源编排后处理操作的进程，比如执行 Shell 命令，上传文件等

![](https://hindung.oss-cn-beijing.aliyuncs.com/img/20250315125256.png)

### 插件机制

Terraform使用`go-plugin`这个工具来管理各个provider插件的生命周期：https://github.com/hashicorp/go-plugin
本代码以GRPCPlugin为例:

![](https://hindung.oss-cn-beijing.aliyuncs.com/img/20250315125344.png)

Terraform采用插件机制来实现对Provider的可插拔的效果，其主要使用了go-plugin这个插件来编写。这个代码也是HashiCorp公司开源的工具，在各个产品中都有应用到这个插件的能力。
这个插件定义了两个接口Plugin和GRPC Plugin，定义了服务端和客户端的RPC方法，插件的提供者需要实现Server方法，而插件的使用者需要实现Client方法。
Terraform实现的是基于GRPC的插件接口。

#### 关键结构体

Plugin.ClientConfig结构体用于舒适化一个插件客户端所需的配置信息，包含了与服务端链接的握手信息，命令行等信息。
包含了插件路径，端口范围等等，一旦插件Client被创建这些信息都不可修改。
Cmd结构体用于启动二进制插件的命令行，里面记录了该进程的信息。
同时，插件的Server端也有类似的结构体用于初始化一个插件服务端进程，

![](https://hindung.oss-cn-beijing.aliyuncs.com/img/20250315125550.png)

Plugin.Client结构体用于负责管理一个插件应用（进程）的完整生命周期，包括创建插件进程、连接到插件进程、Dispense业务接口的实现、最后杀死进程。
对于每个插件（二进制文件），宿主进程需要创建一个Plugin.Client实例。

![](https://hindung.oss-cn-beijing.aliyuncs.com/img/20250315125609.png)

插件主函数必须使用plugin.Serve方法来启动一个RPC服务。

![](https://hindung.oss-cn-beijing.aliyuncs.com/img/20250315125715.png)

ServeConfig与ClientConfig结构类似，共同拥有HandshakeConfig这个结构体，用于两端的连接前握手配置。

![](https://hindung.oss-cn-beijing.aliyuncs.com/img/20250315125658.png)

握手的过程，其实就是对环境变量设置魔法数字：
TF_PLUGIN_MAGIC_COOKIE=d602bf8f19cb4ca9872b2

#### 进程间通信

RPC是远程过程调用的别名，即一个主机上的进程调用另一个主机上的进程的方法。gRPC是由Google公司开发的一套RPC框架，
通过ProtoBuf来约定服务之间的传输信息，并支持跨语言的实现调用。

定义好proto文件之后，使用命令行生成对应的代码文件：
```
protoc --go_out=. --go-grpc_out=. tfplugin6.proto
```

在代码中引入生成的代码并实现对应的接口，既可以实现一个gRPC的服务端和客户端，
在服务端，服务端实现这个接口并运行一个 gRPC 服务器来处理客户端调用。
在客户端，客户端有一个存根(stub)它提供与服务器相同的方法。
客户端应用程序可以直接调用不同机器上的服务器应用程序上的方法，就像本地调用一样。

Terraform目前使用gRPC作为插件的通信协议。通过查看协议文件，可以看到Provider需要提供一些方法。
通过实现这些方法存根，使得Terraform core能够直接调用对应的业务方法，执行插件提供的方法。
比如校验配置信息，对资源进行增删改等操作。

![](https://hindung.oss-cn-beijing.aliyuncs.com/img/20250315130123.png)

Terraform插件是普通的可执行程序，启动时会通过本地接口上启动gRPC服务。 Terraform Core启动插件，进行握手，然后作为 gRPC 客户端连接到指定的端口号。

![](https://hindung.oss-cn-beijing.aliyuncs.com/img/20250315125832.png)

整个过程中，Terraform Core本身称为*插件客户端*，将插件程序本身称为*插件服务器*。这两个进程都在本地运行，服务器进程显示为客户端的子进程。 Terraform Core控制这些服务器进程的生命周期，并在不再需要它们时回收掉。

一个完整的apply的生命流程:

![](https://hindung.oss-cn-beijing.aliyuncs.com/img/20250315130149.png)

## 应用

### 实现一个Provider

通过对go-plugin工具以及Terraform源码的了解，我们可以简单实现一个Provider。
主程序只需plugin.Serve方法即可：
```golang
package main
import (
	"github.com/hashicorp/terraform-plugin-sdk/v2/helper/schema"
	"github.com/hashicorp/terraform-plugin-sdk/v2/plugin"
	"github.com/hindungWang/terraform-provider-wincloud/wincloud"
)
func main() {
	plugin.Serve(&plugin.ServeOpts{
		ProviderFunc: func() *schema.Provider {
			return wincloud.Provider()
		},
	})
}
```
data_source用于检索资源，同步云上的资源状态到本地并作为数据源，以供其他资源引用。
通过定义data_source的Schema来定义、识别、引用和存储云上数据资源的属性。
dataSourceVirtualMachineRead方法则是我们要实现的查询改资源的方法
```go
package wincloud
import (
	"context"
	"github.com/hashicorp/terraform-plugin-sdk/v2/diag"
	"github.com/hashicorp/terraform-plugin-sdk/v2/helper/schema"
	"github.com/hindungWang/terraform-provider-wincloud/pkg/clients"
	"github.com/hindungWang/terraform-provider-wincloud/pkg/utils"
)
func dataSourceVirtualMachine() *schema.Resource {
	return &schema.Resource{
		ReadContext: dataSourceVirtualMachineRead, // 查询
		Schema: map[string]*schema.Schema{
			"uuid": &schema.Schema{
				Type:     schema.TypeString,
				Required: true,
			},
			"name": &schema.Schema{
				Type:     schema.TypeString,
				Computed: true,
			},
			"user_uuid": &schema.Schema{
				Type:     schema.TypeString,
				Computed: true,
			},
      ...

func dataSourceVirtualMachineRead(ctx context.Context, d *schema.ResourceData, m interface{}) diag.Diagnostics {
	var diags diag.Diagnostics
	c := m.(*clients.Client)
	vmUuid := d.Get("uuid").(string)
	vm, err := c.GetVirtualMachine(vmUuid)
	if err != nil {
		return diag.FromErr(err)
	}
	data, err := utils.ToMap(vm, "schema")
	if err != nil {
		diags = append(diags, diag.Diagnostic{
			Severity: diag.Error,
			Summary:  "Unable to set virtual machine values",
			Detail:   err.Error(),
		})
		return diags
	}
	for k, v := range data {
		if err := d.Set(k, v); err != nil {
			return diag.FromErr(err)
		}
	}
	d.SetId(vmUuid)
	return diags
}
```

对应的 tf 代码为：

![](https://hindung.oss-cn-beijing.aliyuncs.com/img/20250315131633.png)

resource则是我们要创建的资源，通过定义resource的Schema来定义、识别、引用和存储云上资源的属性。

```go
package wincloud
import (
	"context"
	"strings"
	"time"
	"github.com/hashicorp/terraform-plugin-sdk/v2/diag"
	"github.com/hashicorp/terraform-plugin-sdk/v2/helper/schema"
	"github.com/hindungWang/terraform-provider-wincloud/pkg/clients"
	"github.com/hindungWang/terraform-provider-wincloud/pkg/types"
	"github.com/hindungWang/terraform-provider-wincloud/pkg/utils"
)
func resourceVirtualMachine() *schema.Resource {
	return &schema.Resource{
		CreateContext: resourceVirtualMachineCreate, // 创建
		ReadContext:   resourceVirtualMachineRead,  // 读取
		UpdateContext: resourceVirtualMachineUpdate, // 更新
		DeleteContext: resourceVirtualMachineDelete, // 删除
		Schema: map[string]*schema.Schema{
			"last_updated": &schema.Schema{
				Type:     schema.TypeString,
				Optional: true,
				Computed: true,
			},
			"uuid": &schema.Schema{
				Type:     schema.TypeString,
				Computed: true,
			},
			"name": &schema.Schema{
				Type:     schema.TypeString,
				Required: true,
			},
			"auto_start": &schema.Schema{
				Type:     schema.TypeBool,
				Optional: true,
			},
			"host_name": &schema.Schema{
				Type:     schema.TypeString,
				Required: true,
			},
      ...
}
func resourceVirtualMachineCreate(ctx context.Context, d *schema.ResourceData, m interface{}) diag.Diagnostics {
	c := m.(*clients.Client)
	vm := &types.CreateVirtualMachineRequest{}
	vm.Name = d.Get("name").(string)
	vm.AutoStart = d.Get("auto_start").(bool)
	vm.StoragePoolID = d.Get("storage_pool_id").(string)
	vm.NetworkAreaUUID = d.Get("network_area_uuid").(string)
	vm.CallSource = d.Get("call_source").(string)
	vm.MetaData = types.MetaData{
		NetworkType:  d.Get("meta_data_network_type").(string),
		TempleteUUID: d.Get("meta_data_templete_uuid").(string),
		TempleteName: d.Get("meta_data_templete_name").(string),
	}
	pas := make([]types.PrivateNetworksArray, 0)
	ns := make([]types.Networks, 0)
	if d.Get("private_networks_array") != nil {
		private_networks_array := d.Get("private_networks_array").([]interface{})
		for _, item := range private_networks_array {
			i := item.(map[string]interface{})
			pas = append(pas, types.PrivateNetworksArray{
				VpcNetworkUUID: i["vpc_network_uuid"].(string),
			})
		}
	}
	if d.Get("networks") != nil {
		networks := d.Get("networks").([]interface{})
		for _, item := range networks {
			i := item.(map[string]interface{})
			ns = append(ns, types.Networks{
				IP:          i["ip"].(string),
				NetworkID:   i["network_id"].(string),
				NetworkUUID: i["network_uuid"].(string),
			})
		}
	}
	vm.PrivateNetworksArray = pas
	vm.Networks = ns
	uuid, err := c.CreateVirtualMachines(vm)
	if err != nil {
		return diag.FromErr(err)
	}
	d.SetId(uuid)
	return resourceVirtualMachineRead(ctx, d, m)
}

func resourceVirtualMachineRead(ctx context.Context, d *schema.ResourceData, m interface{}) diag.Diagnostics {
	var diags diag.Diagnostics
	c := m.(*clients.Client)
	vmUuid := d.Id()
	var loop = 0
	vm, err := c.GetVirtualMachine(vmUuid)
	for err != nil && loop < 10 {
		if strings.Contains(err.Error(), "20002") {
			vm, err = c.GetVirtualMachine(vmUuid)
			time.Sleep(1 * time.Minute)
		} else {
			return diag.FromErr(err)
		}
		loop++
	}
	data, err := utils.ToMap(vm, "schema")
	if err != nil {
		diags = append(diags, diag.Diagnostic{
			Severity: diag.Error,
			Summary:  "Unable to set virtual machine values",
			Detail:   err.Error(),
		})
		return diags
	}
	for k, v := range data {
		if err := d.Set(k, v); err != nil {
			return diag.FromErr(err)
		}
	}
	return diags
}

```

定义好data_source和resource之后需要组合为Provider对象，提供给plugin.Serve。
至此，Terraform core会帮我们执行从.tf语句解析到RPC调用再到Cloud API调用的完整调用链，并形成一个State用于保存当前的资源状态。

```go
func Provider() *schema.Provider {
	return &schema.Provider{
		Schema: map[string]*schema.Schema{
			"username": &schema.Schema{
				Type:        schema.TypeString,
				Optional:    true,
				DefaultFunc: schema.EnvDefaultFunc("WINCLOUD_USERNAME", nil),
			},
			"password": &schema.Schema{
				Type:        schema.TypeString,
				Optional:    true,
				Sensitive:   true,
				DefaultFunc: schema.EnvDefaultFunc("WINCLOUD_PASSWORD", nil),
			},
			"token": &schema.Schema{
				Type:        schema.TypeString,
				Optional:    true,
				Sensitive:   true,
				DefaultFunc: schema.EnvDefaultFunc("WINCLOUD_TOKEN", nil),
			},
		},
		ResourcesMap: map[string]*schema.Resource{
			"wincloud_virtualmachine": resourceVirtualMachine(),
			"wincloud_objectstorage":  resourceObjectStorage(),
		},
		DataSourcesMap: map[string]*schema.Resource{
			"wincloud_virtualmachine": dataSourceVirtualMachine(),
			"wincloud_objectstorage":  dataSourceObjectStorage(),
		},
		ConfigureContextFunc: providerConfigure,
	}
}
func providerConfigure(ctx context.Context, d *schema.ResourceData) (interface{}, diag.Diagnostics) {
	username := d.Get("username").(string)
	password := d.Get("password").(string)
	token := d.Get("token").(string)
	// Warning or errors can be collected in a slice type
	var diags diag.Diagnostics
	if token != "" {
		return clients.NewClientWithToken(token), diags
	}
	if username == "" || password == "" {
		diags = append(diags, diag.Diagnostic{
			Severity: diag.Error,
			Summary:  "Unable to create Wincloud client",
			Detail:   "No username or password",
		})
		return nil, diags
	}
	c, err := clients.NewClient(username, password)
	if err != nil {
		diags = append(diags, diag.Diagnostic{
			Severity: diag.Error,
			Summary:  "Unable to create Wincloud client",
			Detail:   fmt.Sprintf("Unable to auth user for authenticated Wincloud client: %s", err.Error()),
		})
		return nil, diags
	}
	return c, diags
}
```

整个过程就是将 tf 代码翻译为 cloud api 调用：
![](https://hindung.oss-cn-beijing.aliyuncs.com/img/20250315131922.png)

### tf项目格式

一般来说tf项目格式按照这种方式组织：
```bash
.
└── tf/
        ├── versions.tf   存放版本相关的变量
        ├── variables.tf  定义的变量
        ├── provider.tf   依赖的Provider的信息
        ├── vm.tf            Resource信息
        ├── dns.tf           Resource信息
        ├── data-sources.tf   DataSource信息
        ├── main.tf         入口文件
        ├── outputs.tf    输出信息
        └── external/           脚本文件
                 └── name-generator.py

```

Terraform会遍历当前目录下所有以.tf为结尾的文件并解析，而.var结尾的文件会被当做是变量的赋值文件（类似于helm chart的Value.yaml文件）。

Modle 模块是包含一组Terraform代码的文件夹。为了更好的重用我们的代码，可以把这些tf文件打包成一个模块。
Root Model：即是执行Terraform plan/apply命令的文件夹。
如果模块含有多个嵌入模块，那么应避免它们彼此之间的引用，由根模块负责组合它们。一个examples文件夹用来给出一个调用样例。

![](https://hindung.oss-cn-beijing.aliyuncs.com/img/20250315132154.png)

使用模块只需要在tf文件中添加model代码块：
module块定义了一个source参数，指定了模块的源；Terraform目前支持如下模块源：
- 本地路径
- Terraform Registry
- Git仓库
- HTTP地址
- S3 buckets
- GCS buckets

使用时执行：`terraform apply -target=module.e2_instance`

![](https://hindung.oss-cn-beijing.aliyuncs.com/img/20250315132237.png)

### 多人协作

由于Terraform State文件一般是明文存储在本地，因此当多人共同修改一个基础架构时就会存在资源状态的缺失等，导致生产资源泄露。为了解决状态文件的存储和共享问题，Terraform引入了远程状态存储机制： `Terraform Remote Backend`

分为两种：
- 标准：支持远程状态存储与状态锁
- 增强：在标准的基础上支持远程操作(在远程服务器上执行plan、apply等操作)

目前增强型Backend只有Terraform Cloud云服务一种。

![](https://hindung.oss-cn-beijing.aliyuncs.com/img/20250315132354.png)

## 总结

Terraform可以自动化和管理基础架构即服务 (IaaS)、平台即服务 (PaaS)，甚至软件即服务 (SaaS) 级别的功能，并在所有Provider之间并行构建所有此类资源。

Terraform提供了一个插件化的方式来对接和管理不同云上的资源。具有执行计划与过程分离、统一的资源状态管理等功能，使得在编排资源的过程中具有很好的拓展性。

| 类别 | Terraform | Crossplane | Pulumi |
|------|-----------|------------|---------|
| 介绍 | 是一个命令行工具，使用HCL语言定义云厂商的资源 | 是一个控制平面，利用k8s CRD定义各个云厂商的资源，并通过controller去实现对云厂商资源的修改 | 可以使用熟悉的通用语言，如 Python、Go来编排基础架构，相当于把云厂商的API包装起来 |
| Github Star | 31.7k | 4.8k | 11.8k |
| 优点 | 可以管理所有的基础设施包括k8s | 使用kubectl和yaml管理云基础设施，更符合使用k8s作为devops的场景 | 可以使用各种编程语言实现 |
| 缺点 | 依赖单一的状态文件，多人协作不友好 | 依赖k8s集群的状态存储 | 目前只支持公有云厂商sdk |


## 参考资料

- [Terraform 官方文档](https://www.terraform.io/)
- [Crossplane 官方网站](https://crossplane.io/) 
- [Pulumi 官方网站](https://www.pulumi.com/)
- [Terraform Provider Development](https://developer.hashicorp.com/terraform/plugin)
- [HashiCorp Go-plugin](https://github.com/hashicorp/go-plugin)
